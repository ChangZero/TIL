{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A6000'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"  # Set the GPU 0 to use\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "\n",
    "def seed_fix(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "SEED = 23\n",
    "seed_fix(SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.524668\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.680984\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.534977\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.349719\n",
      "[1] Test Loss: 1.2886, Accuracy: 52.31%\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.320876\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.947261\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.234880\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.080698\n",
      "[2] Test Loss: 1.0673, Accuracy: 62.28%\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.126044\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.846868\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.949789\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.149731\n",
      "[3] Test Loss: 0.8661, Accuracy: 70.29%\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.934555\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.638121\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.904433\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.126322\n",
      "[4] Test Loss: 0.9477, Accuracy: 67.73%\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.150672\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.665924\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.874589\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.585901\n",
      "[5] Test Loss: 1.0116, Accuracy: 67.21%\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.691307\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.559248\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.569439\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.600716\n",
      "[6] Test Loss: 0.6907, Accuracy: 75.85%\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.604493\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.767349\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.725904\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.726618\n",
      "[7] Test Loss: 0.6482, Accuracy: 77.57%\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.457245\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.512460\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.517097\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.665895\n",
      "[8] Test Loss: 0.5970, Accuracy: 79.95%\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.623572\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.568553\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.684090\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.673895\n",
      "[9] Test Loss: 0.6028, Accuracy: 80.02%\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.407900\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.432586\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.354758\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.433134\n",
      "[10] Test Loss: 0.6449, Accuracy: 78.44%\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.498918\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.532390\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.499613\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.376545\n",
      "[11] Test Loss: 0.5506, Accuracy: 81.51%\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.327288\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.435456\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.701791\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.530460\n",
      "[12] Test Loss: 0.6403, Accuracy: 79.28%\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.426348\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.513386\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.401035\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.615380\n",
      "[13] Test Loss: 0.5748, Accuracy: 80.82%\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.607840\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.361663\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.488830\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.461426\n",
      "[14] Test Loss: 0.5230, Accuracy: 81.66%\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.527118\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.401133\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.296876\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.439983\n",
      "[15] Test Loss: 0.5405, Accuracy: 81.96%\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.448779\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.410539\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.301423\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.512052\n",
      "[16] Test Loss: 0.5114, Accuracy: 82.78%\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.362895\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.530468\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.551657\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.391282\n",
      "[17] Test Loss: 0.5233, Accuracy: 82.65%\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.484073\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.437163\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.445314\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.296960\n",
      "[18] Test Loss: 0.5521, Accuracy: 81.41%\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.238209\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.304847\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.464623\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.469225\n",
      "[19] Test Loss: 0.4858, Accuracy: 83.43%\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.390150\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.253113\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.569619\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.392997\n",
      "[20] Test Loss: 0.5878, Accuracy: 81.48%\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.523384\n",
      "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.365000\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.299904\n",
      "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.390937\n",
      "[21] Test Loss: 0.5771, Accuracy: 80.12%\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.280794\n",
      "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.429598\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.521875\n",
      "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.253549\n",
      "[22] Test Loss: 0.5520, Accuracy: 81.87%\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.296905\n",
      "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.517897\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.537902\n",
      "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.400403\n",
      "[23] Test Loss: 0.4593, Accuracy: 84.21%\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.386298\n",
      "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.280860\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.372940\n",
      "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.405244\n",
      "[24] Test Loss: 0.4595, Accuracy: 84.54%\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.303675\n",
      "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.255284\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.241131\n",
      "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.361228\n",
      "[25] Test Loss: 0.4958, Accuracy: 82.94%\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.468918\n",
      "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.313231\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.263888\n",
      "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.530816\n",
      "[26] Test Loss: 0.5195, Accuracy: 83.11%\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.355419\n",
      "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.210741\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.417753\n",
      "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.380823\n",
      "[27] Test Loss: 0.5938, Accuracy: 80.65%\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.362398\n",
      "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.254775\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.438855\n",
      "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.365691\n",
      "[28] Test Loss: 0.5497, Accuracy: 82.58%\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.400235\n",
      "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.276804\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.509498\n",
      "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.411366\n",
      "[29] Test Loss: 0.4522, Accuracy: 85.03%\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.219939\n",
      "Train Epoch: 30 [12800/50000 (26%)]\tLoss: 0.246713\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.367810\n",
      "Train Epoch: 30 [38400/50000 (77%)]\tLoss: 0.441323\n",
      "[30] Test Loss: 0.4753, Accuracy: 83.92%\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.319129\n",
      "Train Epoch: 31 [12800/50000 (26%)]\tLoss: 0.313719\n",
      "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.469268\n",
      "Train Epoch: 31 [38400/50000 (77%)]\tLoss: 0.420748\n",
      "[31] Test Loss: 0.4765, Accuracy: 84.33%\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.460937\n",
      "Train Epoch: 32 [12800/50000 (26%)]\tLoss: 0.215465\n",
      "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.566152\n",
      "Train Epoch: 32 [38400/50000 (77%)]\tLoss: 0.282498\n",
      "[32] Test Loss: 0.4954, Accuracy: 83.24%\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.293532\n",
      "Train Epoch: 33 [12800/50000 (26%)]\tLoss: 0.293535\n",
      "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.737945\n",
      "Train Epoch: 33 [38400/50000 (77%)]\tLoss: 0.336583\n",
      "[33] Test Loss: 0.4758, Accuracy: 84.40%\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.239529\n",
      "Train Epoch: 34 [12800/50000 (26%)]\tLoss: 0.502268\n",
      "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.506686\n",
      "Train Epoch: 34 [38400/50000 (77%)]\tLoss: 0.450301\n",
      "[34] Test Loss: 0.4427, Accuracy: 84.97%\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.431592\n",
      "Train Epoch: 35 [12800/50000 (26%)]\tLoss: 0.371548\n",
      "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.263646\n",
      "Train Epoch: 35 [38400/50000 (77%)]\tLoss: 0.338709\n",
      "[35] Test Loss: 0.4668, Accuracy: 83.79%\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.653607\n",
      "Train Epoch: 36 [12800/50000 (26%)]\tLoss: 0.261271\n",
      "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.269604\n",
      "Train Epoch: 36 [38400/50000 (77%)]\tLoss: 0.311379\n",
      "[36] Test Loss: 0.4669, Accuracy: 84.36%\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.230360\n",
      "Train Epoch: 37 [12800/50000 (26%)]\tLoss: 0.470980\n",
      "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.266905\n",
      "Train Epoch: 37 [38400/50000 (77%)]\tLoss: 0.404095\n",
      "[37] Test Loss: 0.4958, Accuracy: 83.86%\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.274240\n",
      "Train Epoch: 38 [12800/50000 (26%)]\tLoss: 0.377541\n",
      "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.341449\n",
      "Train Epoch: 38 [38400/50000 (77%)]\tLoss: 0.328647\n",
      "[38] Test Loss: 0.4552, Accuracy: 84.99%\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.331079\n",
      "Train Epoch: 39 [12800/50000 (26%)]\tLoss: 0.322986\n",
      "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.338536\n",
      "Train Epoch: 39 [38400/50000 (77%)]\tLoss: 0.382475\n",
      "[39] Test Loss: 0.4968, Accuracy: 83.63%\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.479074\n",
      "Train Epoch: 40 [12800/50000 (26%)]\tLoss: 0.491300\n",
      "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.279414\n",
      "Train Epoch: 40 [38400/50000 (77%)]\tLoss: 0.341384\n",
      "[40] Test Loss: 0.5289, Accuracy: 82.12%\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.458009\n",
      "Train Epoch: 41 [12800/50000 (26%)]\tLoss: 0.156288\n",
      "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.212766\n",
      "Train Epoch: 41 [38400/50000 (77%)]\tLoss: 0.358507\n",
      "[41] Test Loss: 0.4299, Accuracy: 85.68%\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.331924\n",
      "Train Epoch: 42 [12800/50000 (26%)]\tLoss: 0.385172\n",
      "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.249696\n",
      "Train Epoch: 42 [38400/50000 (77%)]\tLoss: 0.254647\n",
      "[42] Test Loss: 0.5033, Accuracy: 83.99%\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.486583\n",
      "Train Epoch: 43 [12800/50000 (26%)]\tLoss: 0.093330\n",
      "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.338662\n",
      "Train Epoch: 43 [38400/50000 (77%)]\tLoss: 0.306392\n",
      "[43] Test Loss: 0.4350, Accuracy: 85.51%\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.265644\n",
      "Train Epoch: 44 [12800/50000 (26%)]\tLoss: 0.293824\n",
      "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.330715\n",
      "Train Epoch: 44 [38400/50000 (77%)]\tLoss: 0.298554\n",
      "[44] Test Loss: 0.4119, Accuracy: 86.12%\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.168786\n",
      "Train Epoch: 45 [12800/50000 (26%)]\tLoss: 0.301113\n",
      "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.296418\n",
      "Train Epoch: 45 [38400/50000 (77%)]\tLoss: 0.336588\n",
      "[45] Test Loss: 0.4468, Accuracy: 85.47%\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.335478\n",
      "Train Epoch: 46 [12800/50000 (26%)]\tLoss: 0.236849\n",
      "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.394278\n",
      "Train Epoch: 46 [38400/50000 (77%)]\tLoss: 0.357140\n",
      "[46] Test Loss: 0.4998, Accuracy: 83.79%\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.315572\n",
      "Train Epoch: 47 [12800/50000 (26%)]\tLoss: 0.306146\n",
      "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.474319\n",
      "Train Epoch: 47 [38400/50000 (77%)]\tLoss: 0.296385\n",
      "[47] Test Loss: 0.4497, Accuracy: 85.25%\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.204873\n",
      "Train Epoch: 48 [12800/50000 (26%)]\tLoss: 0.356338\n",
      "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.356923\n",
      "Train Epoch: 48 [38400/50000 (77%)]\tLoss: 0.241842\n",
      "[48] Test Loss: 0.4024, Accuracy: 86.32%\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.197369\n",
      "Train Epoch: 49 [12800/50000 (26%)]\tLoss: 0.249134\n",
      "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.354097\n",
      "Train Epoch: 49 [38400/50000 (77%)]\tLoss: 0.396096\n",
      "[49] Test Loss: 0.4146, Accuracy: 86.07%\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.228044\n",
      "Train Epoch: 50 [12800/50000 (26%)]\tLoss: 0.367135\n",
      "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.224199\n",
      "Train Epoch: 50 [38400/50000 (77%)]\tLoss: 0.299287\n",
      "[50] Test Loss: 0.4291, Accuracy: 85.79%\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLoss: 0.149578\n",
      "Train Epoch: 51 [12800/50000 (26%)]\tLoss: 0.304873\n",
      "Train Epoch: 51 [25600/50000 (51%)]\tLoss: 0.352519\n",
      "Train Epoch: 51 [38400/50000 (77%)]\tLoss: 0.495575\n",
      "[51] Test Loss: 0.4334, Accuracy: 85.66%\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLoss: 0.306324\n",
      "Train Epoch: 52 [12800/50000 (26%)]\tLoss: 0.125023\n",
      "Train Epoch: 52 [25600/50000 (51%)]\tLoss: 0.294185\n",
      "Train Epoch: 52 [38400/50000 (77%)]\tLoss: 0.331532\n",
      "[52] Test Loss: 0.4580, Accuracy: 85.02%\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLoss: 0.267581\n",
      "Train Epoch: 53 [12800/50000 (26%)]\tLoss: 0.218067\n",
      "Train Epoch: 53 [25600/50000 (51%)]\tLoss: 0.218809\n",
      "Train Epoch: 53 [38400/50000 (77%)]\tLoss: 0.436380\n",
      "[53] Test Loss: 0.4153, Accuracy: 86.04%\n",
      "Train Epoch: 54 [0/50000 (0%)]\tLoss: 0.223773\n",
      "Train Epoch: 54 [12800/50000 (26%)]\tLoss: 0.430849\n",
      "Train Epoch: 54 [25600/50000 (51%)]\tLoss: 0.311558\n",
      "Train Epoch: 54 [38400/50000 (77%)]\tLoss: 0.302562\n",
      "[54] Test Loss: 0.4397, Accuracy: 85.61%\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLoss: 0.311720\n",
      "Train Epoch: 55 [12800/50000 (26%)]\tLoss: 0.420897\n",
      "Train Epoch: 55 [25600/50000 (51%)]\tLoss: 0.432961\n",
      "Train Epoch: 55 [38400/50000 (77%)]\tLoss: 0.528288\n",
      "[55] Test Loss: 0.4604, Accuracy: 85.44%\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLoss: 0.196884\n",
      "Train Epoch: 56 [12800/50000 (26%)]\tLoss: 0.220132\n",
      "Train Epoch: 56 [25600/50000 (51%)]\tLoss: 0.237192\n",
      "Train Epoch: 56 [38400/50000 (77%)]\tLoss: 0.425122\n",
      "[56] Test Loss: 0.4464, Accuracy: 85.05%\n",
      "Train Epoch: 57 [0/50000 (0%)]\tLoss: 0.328878\n",
      "Train Epoch: 57 [12800/50000 (26%)]\tLoss: 0.450006\n",
      "Train Epoch: 57 [25600/50000 (51%)]\tLoss: 0.349798\n",
      "Train Epoch: 57 [38400/50000 (77%)]\tLoss: 0.278233\n",
      "[57] Test Loss: 0.5489, Accuracy: 82.94%\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLoss: 0.382586\n",
      "Train Epoch: 58 [12800/50000 (26%)]\tLoss: 0.329138\n",
      "Train Epoch: 58 [25600/50000 (51%)]\tLoss: 0.232189\n",
      "Train Epoch: 58 [38400/50000 (77%)]\tLoss: 0.229169\n",
      "[58] Test Loss: 0.4743, Accuracy: 84.25%\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLoss: 0.229533\n",
      "Train Epoch: 59 [12800/50000 (26%)]\tLoss: 0.380749\n",
      "Train Epoch: 59 [25600/50000 (51%)]\tLoss: 0.275059\n",
      "Train Epoch: 59 [38400/50000 (77%)]\tLoss: 0.206049\n",
      "[59] Test Loss: 0.4923, Accuracy: 84.33%\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLoss: 0.343637\n",
      "Train Epoch: 60 [12800/50000 (26%)]\tLoss: 0.252912\n",
      "Train Epoch: 60 [25600/50000 (51%)]\tLoss: 0.274644\n",
      "Train Epoch: 60 [38400/50000 (77%)]\tLoss: 0.385599\n",
      "[60] Test Loss: 0.4936, Accuracy: 83.60%\n",
      "Train Epoch: 61 [0/50000 (0%)]\tLoss: 0.355189\n",
      "Train Epoch: 61 [12800/50000 (26%)]\tLoss: 0.294685\n",
      "Train Epoch: 61 [25600/50000 (51%)]\tLoss: 0.342986\n",
      "Train Epoch: 61 [38400/50000 (77%)]\tLoss: 0.327775\n",
      "[61] Test Loss: 0.4239, Accuracy: 86.21%\n",
      "Train Epoch: 62 [0/50000 (0%)]\tLoss: 0.314126\n",
      "Train Epoch: 62 [12800/50000 (26%)]\tLoss: 0.331022\n",
      "Train Epoch: 62 [25600/50000 (51%)]\tLoss: 0.619698\n",
      "Train Epoch: 62 [38400/50000 (77%)]\tLoss: 0.391606\n",
      "[62] Test Loss: 0.4491, Accuracy: 85.39%\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLoss: 0.341594\n",
      "Train Epoch: 63 [12800/50000 (26%)]\tLoss: 0.241297\n",
      "Train Epoch: 63 [25600/50000 (51%)]\tLoss: 0.257706\n",
      "Train Epoch: 63 [38400/50000 (77%)]\tLoss: 0.378014\n",
      "[63] Test Loss: 0.4012, Accuracy: 86.77%\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLoss: 0.381808\n",
      "Train Epoch: 64 [12800/50000 (26%)]\tLoss: 0.290989\n",
      "Train Epoch: 64 [25600/50000 (51%)]\tLoss: 0.338336\n",
      "Train Epoch: 64 [38400/50000 (77%)]\tLoss: 0.246044\n",
      "[64] Test Loss: 0.4382, Accuracy: 85.30%\n",
      "Train Epoch: 65 [0/50000 (0%)]\tLoss: 0.230844\n",
      "Train Epoch: 65 [12800/50000 (26%)]\tLoss: 0.356868\n",
      "Train Epoch: 65 [25600/50000 (51%)]\tLoss: 0.331095\n",
      "Train Epoch: 65 [38400/50000 (77%)]\tLoss: 0.492145\n",
      "[65] Test Loss: 0.4595, Accuracy: 84.77%\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLoss: 0.299037\n",
      "Train Epoch: 66 [12800/50000 (26%)]\tLoss: 0.258604\n",
      "Train Epoch: 66 [25600/50000 (51%)]\tLoss: 0.340593\n",
      "Train Epoch: 66 [38400/50000 (77%)]\tLoss: 0.262570\n",
      "[66] Test Loss: 0.4141, Accuracy: 86.33%\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLoss: 0.378568\n",
      "Train Epoch: 67 [12800/50000 (26%)]\tLoss: 0.256173\n",
      "Train Epoch: 67 [25600/50000 (51%)]\tLoss: 0.470388\n",
      "Train Epoch: 67 [38400/50000 (77%)]\tLoss: 0.340570\n",
      "[67] Test Loss: 0.4109, Accuracy: 86.31%\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLoss: 0.264828\n",
      "Train Epoch: 68 [12800/50000 (26%)]\tLoss: 0.398572\n",
      "Train Epoch: 68 [25600/50000 (51%)]\tLoss: 0.289014\n",
      "Train Epoch: 68 [38400/50000 (77%)]\tLoss: 0.210670\n",
      "[68] Test Loss: 0.4462, Accuracy: 85.35%\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLoss: 0.300593\n",
      "Train Epoch: 69 [12800/50000 (26%)]\tLoss: 0.201802\n",
      "Train Epoch: 69 [25600/50000 (51%)]\tLoss: 0.333310\n",
      "Train Epoch: 69 [38400/50000 (77%)]\tLoss: 0.245712\n",
      "[69] Test Loss: 0.4133, Accuracy: 86.46%\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLoss: 0.395291\n",
      "Train Epoch: 70 [12800/50000 (26%)]\tLoss: 0.178320\n",
      "Train Epoch: 70 [25600/50000 (51%)]\tLoss: 0.400001\n",
      "Train Epoch: 70 [38400/50000 (77%)]\tLoss: 0.212565\n",
      "[70] Test Loss: 0.4503, Accuracy: 85.51%\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLoss: 0.497353\n",
      "Train Epoch: 71 [12800/50000 (26%)]\tLoss: 0.321831\n",
      "Train Epoch: 71 [25600/50000 (51%)]\tLoss: 0.324331\n",
      "Train Epoch: 71 [38400/50000 (77%)]\tLoss: 0.299100\n",
      "[71] Test Loss: 0.4953, Accuracy: 84.06%\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLoss: 0.140791\n",
      "Train Epoch: 72 [12800/50000 (26%)]\tLoss: 0.196040\n",
      "Train Epoch: 72 [25600/50000 (51%)]\tLoss: 0.212624\n",
      "Train Epoch: 72 [38400/50000 (77%)]\tLoss: 0.382331\n",
      "[72] Test Loss: 0.4498, Accuracy: 85.50%\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLoss: 0.421385\n",
      "Train Epoch: 73 [12800/50000 (26%)]\tLoss: 0.321712\n",
      "Train Epoch: 73 [25600/50000 (51%)]\tLoss: 0.369355\n",
      "Train Epoch: 73 [38400/50000 (77%)]\tLoss: 0.146778\n",
      "[73] Test Loss: 0.4241, Accuracy: 86.00%\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLoss: 0.227103\n",
      "Train Epoch: 74 [12800/50000 (26%)]\tLoss: 0.241663\n",
      "Train Epoch: 74 [25600/50000 (51%)]\tLoss: 0.257604\n",
      "Train Epoch: 74 [38400/50000 (77%)]\tLoss: 0.395673\n",
      "[74] Test Loss: 0.4134, Accuracy: 86.03%\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLoss: 0.246862\n",
      "Train Epoch: 75 [12800/50000 (26%)]\tLoss: 0.290761\n",
      "Train Epoch: 75 [25600/50000 (51%)]\tLoss: 0.245794\n",
      "Train Epoch: 75 [38400/50000 (77%)]\tLoss: 0.276898\n",
      "[75] Test Loss: 0.4015, Accuracy: 86.91%\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLoss: 0.232447\n",
      "Train Epoch: 76 [12800/50000 (26%)]\tLoss: 0.306538\n",
      "Train Epoch: 76 [25600/50000 (51%)]\tLoss: 0.189921\n",
      "Train Epoch: 76 [38400/50000 (77%)]\tLoss: 0.413454\n",
      "[76] Test Loss: 0.4171, Accuracy: 86.69%\n",
      "Train Epoch: 77 [0/50000 (0%)]\tLoss: 0.173337\n",
      "Train Epoch: 77 [12800/50000 (26%)]\tLoss: 0.515386\n",
      "Train Epoch: 77 [25600/50000 (51%)]\tLoss: 0.280826\n",
      "Train Epoch: 77 [38400/50000 (77%)]\tLoss: 0.326976\n",
      "[77] Test Loss: 0.5066, Accuracy: 84.10%\n",
      "Train Epoch: 78 [0/50000 (0%)]\tLoss: 0.239986\n",
      "Train Epoch: 78 [12800/50000 (26%)]\tLoss: 0.304541\n",
      "Train Epoch: 78 [25600/50000 (51%)]\tLoss: 0.377622\n",
      "Train Epoch: 78 [38400/50000 (77%)]\tLoss: 0.173842\n",
      "[78] Test Loss: 0.4335, Accuracy: 85.66%\n",
      "Train Epoch: 79 [0/50000 (0%)]\tLoss: 0.288486\n",
      "Train Epoch: 79 [12800/50000 (26%)]\tLoss: 0.304365\n",
      "Train Epoch: 79 [25600/50000 (51%)]\tLoss: 0.191221\n",
      "Train Epoch: 79 [38400/50000 (77%)]\tLoss: 0.455695\n",
      "[79] Test Loss: 0.4182, Accuracy: 86.74%\n",
      "Train Epoch: 80 [0/50000 (0%)]\tLoss: 0.355929\n",
      "Train Epoch: 80 [12800/50000 (26%)]\tLoss: 0.267620\n",
      "Train Epoch: 80 [25600/50000 (51%)]\tLoss: 0.203601\n",
      "Train Epoch: 80 [38400/50000 (77%)]\tLoss: 0.364871\n",
      "[80] Test Loss: 0.5405, Accuracy: 83.37%\n",
      "Train Epoch: 81 [0/50000 (0%)]\tLoss: 0.159531\n",
      "Train Epoch: 81 [12800/50000 (26%)]\tLoss: 0.208772\n",
      "Train Epoch: 81 [25600/50000 (51%)]\tLoss: 0.300061\n",
      "Train Epoch: 81 [38400/50000 (77%)]\tLoss: 0.339642\n",
      "[81] Test Loss: 0.4515, Accuracy: 85.35%\n",
      "Train Epoch: 82 [0/50000 (0%)]\tLoss: 0.240631\n",
      "Train Epoch: 82 [12800/50000 (26%)]\tLoss: 0.281571\n",
      "Train Epoch: 82 [25600/50000 (51%)]\tLoss: 0.243546\n",
      "Train Epoch: 82 [38400/50000 (77%)]\tLoss: 0.279987\n",
      "[82] Test Loss: 0.4705, Accuracy: 84.81%\n",
      "Train Epoch: 83 [0/50000 (0%)]\tLoss: 0.179187\n",
      "Train Epoch: 83 [12800/50000 (26%)]\tLoss: 0.229044\n",
      "Train Epoch: 83 [25600/50000 (51%)]\tLoss: 0.220511\n",
      "Train Epoch: 83 [38400/50000 (77%)]\tLoss: 0.245438\n",
      "[83] Test Loss: 0.4208, Accuracy: 86.06%\n",
      "Train Epoch: 84 [0/50000 (0%)]\tLoss: 0.290695\n",
      "Train Epoch: 84 [12800/50000 (26%)]\tLoss: 0.175929\n",
      "Train Epoch: 84 [25600/50000 (51%)]\tLoss: 0.378364\n",
      "Train Epoch: 84 [38400/50000 (77%)]\tLoss: 0.187808\n",
      "[84] Test Loss: 0.4677, Accuracy: 84.49%\n",
      "Train Epoch: 85 [0/50000 (0%)]\tLoss: 0.301519\n",
      "Train Epoch: 85 [12800/50000 (26%)]\tLoss: 0.309761\n",
      "Train Epoch: 85 [25600/50000 (51%)]\tLoss: 0.146833\n",
      "Train Epoch: 85 [38400/50000 (77%)]\tLoss: 0.256680\n",
      "[85] Test Loss: 0.4294, Accuracy: 86.35%\n",
      "Train Epoch: 86 [0/50000 (0%)]\tLoss: 0.371375\n",
      "Train Epoch: 86 [12800/50000 (26%)]\tLoss: 0.317198\n",
      "Train Epoch: 86 [25600/50000 (51%)]\tLoss: 0.237185\n",
      "Train Epoch: 86 [38400/50000 (77%)]\tLoss: 0.318127\n",
      "[86] Test Loss: 0.3940, Accuracy: 86.91%\n",
      "Train Epoch: 87 [0/50000 (0%)]\tLoss: 0.288345\n",
      "Train Epoch: 87 [12800/50000 (26%)]\tLoss: 0.267966\n",
      "Train Epoch: 87 [25600/50000 (51%)]\tLoss: 0.345467\n",
      "Train Epoch: 87 [38400/50000 (77%)]\tLoss: 0.297010\n",
      "[87] Test Loss: 0.4460, Accuracy: 85.79%\n",
      "Train Epoch: 88 [0/50000 (0%)]\tLoss: 0.433837\n",
      "Train Epoch: 88 [12800/50000 (26%)]\tLoss: 0.110498\n",
      "Train Epoch: 88 [25600/50000 (51%)]\tLoss: 0.297913\n",
      "Train Epoch: 88 [38400/50000 (77%)]\tLoss: 0.311530\n",
      "[88] Test Loss: 0.4153, Accuracy: 86.68%\n",
      "Train Epoch: 89 [0/50000 (0%)]\tLoss: 0.324954\n",
      "Train Epoch: 89 [12800/50000 (26%)]\tLoss: 0.299155\n",
      "Train Epoch: 89 [25600/50000 (51%)]\tLoss: 0.304142\n",
      "Train Epoch: 89 [38400/50000 (77%)]\tLoss: 0.198161\n",
      "[89] Test Loss: 0.4012, Accuracy: 86.88%\n",
      "Train Epoch: 90 [0/50000 (0%)]\tLoss: 0.308581\n",
      "Train Epoch: 90 [12800/50000 (26%)]\tLoss: 0.327738\n",
      "Train Epoch: 90 [25600/50000 (51%)]\tLoss: 0.591821\n",
      "Train Epoch: 90 [38400/50000 (77%)]\tLoss: 0.498490\n",
      "[90] Test Loss: 0.4268, Accuracy: 86.12%\n",
      "Train Epoch: 91 [0/50000 (0%)]\tLoss: 0.185957\n",
      "Train Epoch: 91 [12800/50000 (26%)]\tLoss: 0.183783\n",
      "Train Epoch: 91 [25600/50000 (51%)]\tLoss: 0.381267\n",
      "Train Epoch: 91 [38400/50000 (77%)]\tLoss: 0.297883\n",
      "[91] Test Loss: 0.4227, Accuracy: 85.91%\n",
      "Train Epoch: 92 [0/50000 (0%)]\tLoss: 0.294644\n",
      "Train Epoch: 92 [12800/50000 (26%)]\tLoss: 0.376737\n",
      "Train Epoch: 92 [25600/50000 (51%)]\tLoss: 0.271361\n",
      "Train Epoch: 92 [38400/50000 (77%)]\tLoss: 0.373834\n",
      "[92] Test Loss: 0.4325, Accuracy: 85.87%\n",
      "Train Epoch: 93 [0/50000 (0%)]\tLoss: 0.271297\n",
      "Train Epoch: 93 [12800/50000 (26%)]\tLoss: 0.303211\n",
      "Train Epoch: 93 [25600/50000 (51%)]\tLoss: 0.316340\n",
      "Train Epoch: 93 [38400/50000 (77%)]\tLoss: 0.134180\n",
      "[93] Test Loss: 0.3937, Accuracy: 86.60%\n",
      "Train Epoch: 94 [0/50000 (0%)]\tLoss: 0.298543\n",
      "Train Epoch: 94 [12800/50000 (26%)]\tLoss: 0.199676\n",
      "Train Epoch: 94 [25600/50000 (51%)]\tLoss: 0.272361\n",
      "Train Epoch: 94 [38400/50000 (77%)]\tLoss: 0.366242\n",
      "[94] Test Loss: 0.4309, Accuracy: 86.18%\n",
      "Train Epoch: 95 [0/50000 (0%)]\tLoss: 0.218445\n",
      "Train Epoch: 95 [12800/50000 (26%)]\tLoss: 0.180285\n",
      "Train Epoch: 95 [25600/50000 (51%)]\tLoss: 0.426697\n",
      "Train Epoch: 95 [38400/50000 (77%)]\tLoss: 0.422765\n",
      "[95] Test Loss: 0.4150, Accuracy: 86.53%\n",
      "Train Epoch: 96 [0/50000 (0%)]\tLoss: 0.191670\n",
      "Train Epoch: 96 [12800/50000 (26%)]\tLoss: 0.126785\n",
      "Train Epoch: 96 [25600/50000 (51%)]\tLoss: 0.349523\n",
      "Train Epoch: 96 [38400/50000 (77%)]\tLoss: 0.211417\n",
      "[96] Test Loss: 0.4323, Accuracy: 85.60%\n",
      "Train Epoch: 97 [0/50000 (0%)]\tLoss: 0.341739\n",
      "Train Epoch: 97 [12800/50000 (26%)]\tLoss: 0.337214\n",
      "Train Epoch: 97 [25600/50000 (51%)]\tLoss: 0.260768\n",
      "Train Epoch: 97 [38400/50000 (77%)]\tLoss: 0.409001\n",
      "[97] Test Loss: 0.4016, Accuracy: 86.99%\n",
      "Train Epoch: 98 [0/50000 (0%)]\tLoss: 0.505227\n",
      "Train Epoch: 98 [12800/50000 (26%)]\tLoss: 0.302968\n",
      "Train Epoch: 98 [25600/50000 (51%)]\tLoss: 0.317599\n",
      "Train Epoch: 98 [38400/50000 (77%)]\tLoss: 0.247731\n",
      "[98] Test Loss: 0.4226, Accuracy: 85.96%\n",
      "Train Epoch: 99 [0/50000 (0%)]\tLoss: 0.223283\n",
      "Train Epoch: 99 [12800/50000 (26%)]\tLoss: 0.165189\n",
      "Train Epoch: 99 [25600/50000 (51%)]\tLoss: 0.317278\n",
      "Train Epoch: 99 [38400/50000 (77%)]\tLoss: 0.182831\n",
      "[99] Test Loss: 0.4378, Accuracy: 86.09%\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 0.272011\n",
      "Train Epoch: 100 [12800/50000 (26%)]\tLoss: 0.230019\n",
      "Train Epoch: 100 [25600/50000 (51%)]\tLoss: 0.286052\n",
      "Train Epoch: 100 [38400/50000 (77%)]\tLoss: 0.159668\n",
      "[100] Test Loss: 0.4376, Accuracy: 85.94%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 기존 코드와 동일한 부분\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# CIFAR-10 데이터셋을 불러옴\n",
    "trainset = datasets.CIFAR10(\n",
    "    root='./.data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    ")\n",
    "testset = datasets.CIFAR10(\n",
    "    root='./.data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        \n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=testset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(32, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 2, stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "model = ResNet().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "\n",
    "# 훈련 및 테스트 손실을 저장할 리스트 생성\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# train 및 evaluate 함수는 그대로 사용\n",
    "def train(model, train_loader, optimizer):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "        \n",
    "        \n",
    "        running_loss += loss.item() * data.size(0)\n",
    "    return running_loss\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            # 배치 오차를 합산\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        return test_loss, test_accuracy\n",
    "\n",
    "# Loss curve를 그리기 위한 리스트 생성\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# 에폭(epoch)별로 학습 및 테스트 수행\n",
    "best_acc = 0\n",
    "best_loss = 1e9\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    running_loss = train(model, train_loader, optimizer)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    # 훈련 및 테스트 손실 기록\n",
    "    train_losses.append(epoch_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        best_epoch = epoch\n",
    "        best_acc = test_accuracy\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Loss curve를 그림\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Loss가 가장 작은 지점에 빨간 점을 찍고 주석을 추가\n",
    "plt.scatter(best_epoch, best_loss, color='red', marker='o')\n",
    "plt.annotate(f'Loss: {best_loss:.4f}\\nAcc: {best_acc:.2f}%\\nEpoch: {best_epoch}', (best_epoch, best_loss), textcoords=\"offset points\", xytext=(0, -40), ha='right')\n",
    "\n",
    "plt.savefig('./plot/resnet_aug_loss_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict format of the model: OrderedDict([('conv1.weight', tensor([[[[ 2.0055e-01, -2.8637e-01,  1.9093e-01],\n",
      "          [ 4.6470e-02,  8.7387e-01, -4.2113e-01],\n",
      "          [-1.1741e-02, -9.7708e-02, -3.2144e-01]],\n",
      "\n",
      "         [[-1.6240e-01, -4.1165e-01,  1.8751e-01],\n",
      "          [-3.2234e-01,  8.3989e-01, -7.3537e-02],\n",
      "          [-1.9115e-01, -2.0962e-01,  7.1571e-02]],\n",
      "\n",
      "         [[ 2.0277e-01, -3.8527e-01,  3.1162e-02],\n",
      "          [-1.2029e-01,  3.8197e-01,  2.8191e-03],\n",
      "          [-2.7171e-03, -1.8532e-01,  6.4848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7758e-02,  9.7741e-02,  7.6446e-02],\n",
      "          [ 1.1004e-01,  2.9006e-01, -2.8850e-01],\n",
      "          [-3.7291e-02,  6.2652e-02,  1.1190e-01]],\n",
      "\n",
      "         [[-4.4733e-03, -1.1681e-01, -2.5967e-01],\n",
      "          [ 1.0281e-01,  4.3361e-02, -7.1064e-01],\n",
      "          [-3.9128e-02, -1.1995e-01, -2.3114e-01]],\n",
      "\n",
      "         [[-1.0651e-01,  1.8668e-01, -5.3837e-03],\n",
      "          [ 2.1266e-01,  5.8784e-01, -2.2525e-01],\n",
      "          [ 8.5693e-02,  3.1611e-01, -3.1733e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1516e-01, -8.2093e-02,  4.2185e-04],\n",
      "          [-2.7069e-01, -3.2284e-01, -1.5518e-01],\n",
      "          [-2.5753e-01, -3.2198e-01, -1.4526e-01]],\n",
      "\n",
      "         [[ 6.8865e-02,  3.7227e-01,  5.4632e-02],\n",
      "          [ 3.7763e-01,  8.0138e-01,  3.5861e-01],\n",
      "          [ 2.9841e-01,  6.8975e-01,  3.4349e-01]],\n",
      "\n",
      "         [[ 6.2285e-03, -2.1659e-01, -9.1715e-02],\n",
      "          [-2.1098e-01, -5.4512e-01, -4.5032e-01],\n",
      "          [ 8.7471e-02, -1.0406e-01, -7.4750e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0211e-01,  6.9454e-01,  2.8638e-01],\n",
      "          [-9.6175e-02,  2.4054e-01,  3.3658e-01],\n",
      "          [-3.5304e-01, -1.6300e-01,  2.9900e-02]],\n",
      "\n",
      "         [[-4.1220e-01, -4.8745e-01, -2.9882e-01],\n",
      "          [-2.3781e-01, -5.5648e-01, -1.6471e-01],\n",
      "          [ 1.0702e-01,  6.4882e-02,  2.2674e-01]],\n",
      "\n",
      "         [[ 1.1235e-01,  6.0378e-02, -7.2278e-02],\n",
      "          [ 2.3655e-01, -3.8759e-02, -1.7260e-01],\n",
      "          [ 2.3595e-01,  2.2059e-01,  2.5356e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4772e-01,  5.3112e-01,  2.2981e-01],\n",
      "          [-1.1203e-01,  2.8635e-02, -1.6324e-01],\n",
      "          [-8.6404e-02, -2.1180e-01, -2.9325e-01]],\n",
      "\n",
      "         [[ 2.1102e-01,  6.2764e-01,  2.7400e-01],\n",
      "          [-2.4486e-01, -8.7069e-03, -1.4150e-01],\n",
      "          [-1.7819e-01, -2.4238e-01, -2.4488e-01]],\n",
      "\n",
      "         [[ 1.0829e-01,  4.7131e-01,  2.1452e-01],\n",
      "          [-2.5859e-01, -1.4365e-02, -1.0750e-01],\n",
      "          [-2.3720e-01, -1.7535e-01, -1.9645e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6956e-03, -1.0540e-01,  1.2116e-01],\n",
      "          [-4.3463e-01, -5.3529e-01, -3.0563e-02],\n",
      "          [-2.1837e-02, -6.9754e-02,  3.9000e-02]],\n",
      "\n",
      "         [[ 1.2679e-01,  1.8911e-02,  1.6907e-01],\n",
      "          [-2.8089e-01, -3.6366e-01,  5.0120e-02],\n",
      "          [ 6.5515e-02,  2.8005e-03,  1.0472e-01]],\n",
      "\n",
      "         [[ 2.2472e-01,  4.2188e-02,  4.3615e-02],\n",
      "          [-9.6339e-02, -2.3154e-01,  1.9892e-02],\n",
      "          [ 7.0148e-02,  2.0253e-02,  5.9469e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2690e-01,  1.2000e-01,  6.2936e-02],\n",
      "          [-5.5365e-01,  3.8195e-01,  2.5845e-01],\n",
      "          [-8.3139e-02,  3.3321e-01, -9.2031e-02]],\n",
      "\n",
      "         [[-2.0818e-01,  1.3694e-01,  4.8600e-02],\n",
      "          [-6.8930e-01,  3.3196e-01,  1.9810e-01],\n",
      "          [-2.6764e-01,  1.9036e-01, -1.0976e-01]],\n",
      "\n",
      "         [[-1.3485e-01,  4.0278e-02, -3.3842e-02],\n",
      "          [-4.3809e-01,  3.7851e-01,  2.5390e-01],\n",
      "          [-9.7079e-02,  3.5178e-01,  1.6837e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3717e-01, -5.6474e-02,  1.3240e-01],\n",
      "          [ 1.6793e-01, -2.3733e-01, -5.0205e-02],\n",
      "          [ 1.0917e-02, -1.6205e-02,  1.4580e-02]],\n",
      "\n",
      "         [[-6.0842e-02, -4.1032e-01,  1.5605e-02],\n",
      "          [-6.2522e-02, -4.3006e-01, -7.9255e-02],\n",
      "          [ 1.0659e-01,  6.1040e-02,  1.7126e-01]],\n",
      "\n",
      "         [[ 6.6446e-02, -2.6009e-01,  4.3406e-02],\n",
      "          [-4.4381e-02, -3.9002e-01, -7.6460e-02],\n",
      "          [ 5.5955e-02, -3.1513e-02,  9.0019e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8373e-01,  5.6174e-01,  1.1998e-01],\n",
      "          [ 4.1427e-01, -4.5938e-01, -1.5123e-01],\n",
      "          [ 1.5441e-01, -4.0865e-01, -6.9186e-01]],\n",
      "\n",
      "         [[-1.3954e-01, -2.2167e-01, -1.5168e-02],\n",
      "          [ 2.2578e-02, -4.1295e-01,  3.4995e-01],\n",
      "          [ 2.4386e-01,  1.9102e-01, -7.5597e-03]],\n",
      "\n",
      "         [[-3.1556e-01, -3.1900e-01, -2.9143e-01],\n",
      "          [-1.0701e-01, -1.4018e-01,  5.3296e-01],\n",
      "          [-4.5901e-02,  2.5714e-01,  3.5917e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3367e-01, -1.8587e-01, -6.5315e-02],\n",
      "          [-2.2746e-01, -1.1594e-01,  1.2283e-02],\n",
      "          [ 7.7392e-02,  1.7729e-01,  1.1722e-01]],\n",
      "\n",
      "         [[-1.4318e-01, -9.0522e-02, -1.8175e-01],\n",
      "          [-3.0537e-01, -7.2207e-02, -1.8574e-01],\n",
      "          [-1.9475e-01, -8.7537e-02, -2.5580e-01]],\n",
      "\n",
      "         [[ 1.4513e-01,  3.4205e-01,  4.8528e-02],\n",
      "          [ 8.4613e-02,  3.8773e-01,  7.9554e-02],\n",
      "          [ 2.5962e-02,  1.5891e-01, -1.8512e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3306e-02,  4.9870e-02,  1.1611e-01],\n",
      "          [-4.1385e-02, -2.6702e-02,  1.7685e-01],\n",
      "          [-1.1943e-02, -1.3669e-01,  1.0332e-01]],\n",
      "\n",
      "         [[-2.8185e-01, -7.2003e-02,  2.1844e-01],\n",
      "          [-2.5509e-01, -1.8296e-01,  2.8183e-01],\n",
      "          [-7.3988e-02, -2.3305e-01,  1.4918e-01]],\n",
      "\n",
      "         [[-2.5426e-01,  6.3055e-02,  3.2531e-01],\n",
      "          [-2.5377e-01, -2.8683e-02,  4.4125e-01],\n",
      "          [-1.1022e-01, -1.3921e-01,  3.0630e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6401e-02,  1.6701e-01,  2.1357e-01],\n",
      "          [ 7.6601e-02,  3.6380e-01,  2.7928e-01],\n",
      "          [-8.4927e-02,  1.5584e-01,  5.1359e-02]],\n",
      "\n",
      "         [[-5.9395e-02, -7.3072e-02, -9.9727e-02],\n",
      "          [ 2.1142e-02,  5.9749e-02, -5.0887e-02],\n",
      "          [-1.1389e-01, -2.8458e-02, -7.2870e-02]],\n",
      "\n",
      "         [[ 1.1430e-01,  1.0555e-01,  3.7484e-02],\n",
      "          [ 1.1631e-01,  4.0616e-02, -1.0487e-01],\n",
      "          [-5.1089e-02, -1.0791e-01, -1.7586e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9862e-02,  2.8949e-01,  2.0658e-01],\n",
      "          [-8.1419e-02,  1.2239e-01,  2.4127e-01],\n",
      "          [-2.9888e-01, -1.4800e-01,  1.3158e-01]],\n",
      "\n",
      "         [[ 6.4789e-02, -1.1778e-02, -1.5313e-01],\n",
      "          [ 3.7193e-02, -1.1237e-04, -1.9785e-02],\n",
      "          [-4.4319e-02,  8.3746e-03,  9.0513e-02]],\n",
      "\n",
      "         [[-4.5194e-02, -2.9063e-02, -1.7582e-01],\n",
      "          [-4.5815e-02, -5.4896e-02, -1.0478e-01],\n",
      "          [-2.0187e-02,  1.7971e-02,  5.0982e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7062e-01, -2.4442e-01,  9.3001e-02],\n",
      "          [-3.2365e-01, -4.6672e-01, -8.2425e-02],\n",
      "          [-1.6243e-01, -3.3887e-01, -1.2429e-01]],\n",
      "\n",
      "         [[ 8.6328e-02,  3.8410e-02,  7.2812e-02],\n",
      "          [ 2.1538e-02,  4.2234e-02,  1.0963e-01],\n",
      "          [-3.8551e-02, -2.3127e-02,  2.3681e-02]],\n",
      "\n",
      "         [[ 2.1342e-01,  2.1710e-01,  2.2005e-03],\n",
      "          [ 3.8520e-01,  4.8390e-01,  2.3161e-01],\n",
      "          [ 1.6037e-01,  2.1768e-01,  2.4970e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0287e-03, -2.6541e-01, -2.4644e-01],\n",
      "          [ 8.4920e-02, -7.3154e-02, -1.3663e-01],\n",
      "          [ 2.6672e-01,  4.3374e-01,  2.2845e-01]],\n",
      "\n",
      "         [[-2.0847e-02, -1.7517e-01, -7.9057e-02],\n",
      "          [-5.4477e-02, -1.5945e-01, -8.5802e-02],\n",
      "          [ 1.3273e-01,  3.0262e-01,  1.9607e-01]],\n",
      "\n",
      "         [[ 1.0105e-02, -8.5987e-02,  5.0585e-04],\n",
      "          [-1.0568e-01, -1.8208e-01, -8.8263e-02],\n",
      "          [ 2.5870e-02,  1.7428e-01,  1.1210e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.5475e-02, -4.2649e-01, -4.4394e-01],\n",
      "          [ 2.7092e-01, -7.5703e-02, -3.5732e-01],\n",
      "          [ 4.7964e-01,  3.7036e-01,  8.0881e-02]],\n",
      "\n",
      "         [[-1.3611e-01,  9.8845e-02,  6.4582e-02],\n",
      "          [ 6.3826e-02,  2.6741e-01,  1.2704e-01],\n",
      "          [ 8.9830e-03,  1.0442e-01, -1.6196e-02]],\n",
      "\n",
      "         [[-1.0487e-01,  2.3226e-01,  2.5040e-01],\n",
      "          [-2.5607e-01,  1.5941e-01,  3.1267e-01],\n",
      "          [-4.6079e-01, -2.4385e-01, -1.9577e-02]]]], device='cuda:0')), ('bn1.weight', tensor([0.4197, 0.4000, 0.3561, 0.2734, 0.4095, 0.5303, 0.4696, 0.6729, 0.2970,\n",
      "        0.1827, 0.3311, 0.2750, 0.2590, 0.2798, 0.4127, 0.2552],\n",
      "       device='cuda:0')), ('bn1.bias', tensor([ 0.8009,  0.2364,  0.2299,  0.2241,  0.2074, -0.0761,  0.3577, -0.0909,\n",
      "         0.4645,  0.1270,  0.1200, -0.0880, -0.0994,  0.1811,  0.0314,  0.4073],\n",
      "       device='cuda:0')), ('bn1.running_mean', tensor([-0.0191, -0.1011,  0.0339,  0.0036,  0.0172,  0.1290, -0.0687,  0.2194,\n",
      "         0.0180,  0.0144, -0.0164, -0.0962,  0.0174, -0.2248, -0.0089, -0.0101],\n",
      "       device='cuda:0')), ('bn1.running_var', tensor([0.1046, 0.2618, 0.1662, 0.0794, 0.9892, 0.4586, 0.5865, 0.4649, 0.0886,\n",
      "        0.1796, 0.4341, 0.2428, 0.0554, 0.3874, 0.3433, 0.0782],\n",
      "       device='cuda:0')), ('bn1.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer1.0.conv1.weight', tensor([[[[ 2.4061e-02,  6.7323e-02,  5.6313e-02],\n",
      "          [-4.7700e-02, -5.7878e-01,  1.8077e-02],\n",
      "          [-2.8871e-01,  3.7971e-01,  8.3386e-02]],\n",
      "\n",
      "         [[-9.5303e-02, -5.8326e-02, -3.2799e-02],\n",
      "          [ 4.6605e-02, -5.4284e-02, -6.0816e-03],\n",
      "          [-1.2363e-01,  1.2242e-01,  7.2542e-02]],\n",
      "\n",
      "         [[ 1.5586e-01, -1.0196e-01, -2.1703e-01],\n",
      "          [ 1.8805e-01, -2.3178e-02, -9.4696e-02],\n",
      "          [ 9.8094e-02,  4.9381e-02, -5.8869e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4016e-02,  1.1763e-02, -5.3586e-02],\n",
      "          [ 2.5693e-02,  5.7982e-03, -1.5740e-01],\n",
      "          [ 1.0287e-01,  1.0193e-01, -1.3051e-02]],\n",
      "\n",
      "         [[-1.4865e-01, -1.0417e-01, -1.1337e-01],\n",
      "          [-1.2434e-01, -9.6661e-02, -8.7227e-02],\n",
      "          [-3.7513e-02, -9.7278e-02, -7.3400e-02]],\n",
      "\n",
      "         [[-1.3225e-01, -1.6416e-01,  5.0321e-02],\n",
      "          [ 4.5540e-02, -1.2880e-01, -5.7030e-02],\n",
      "          [ 1.0434e-01, -1.0269e-01, -8.7032e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2989e-03,  4.8145e-02, -7.1435e-02],\n",
      "          [-8.0779e-02, -2.0656e-02,  2.4997e-02],\n",
      "          [-3.4582e-02,  1.5797e-01, -4.0306e-02]],\n",
      "\n",
      "         [[-3.9444e-03, -6.6421e-02,  1.3810e-01],\n",
      "          [-8.1213e-02, -9.2419e-02,  6.4140e-02],\n",
      "          [-4.5432e-02, -2.6042e-02,  4.3947e-02]],\n",
      "\n",
      "         [[ 1.5365e-01, -5.6029e-02, -1.1258e-01],\n",
      "          [ 2.2401e-01, -7.9539e-03, -1.7490e-01],\n",
      "          [-1.7208e-02, -1.2373e-01, -2.2829e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.4454e-02, -1.2705e-01, -1.0757e-01],\n",
      "          [-8.9807e-02, -2.1319e-01, -1.8393e-01],\n",
      "          [-3.5791e-02, -1.4470e-01, -1.2191e-01]],\n",
      "\n",
      "         [[-1.9890e-02, -5.8659e-02, -4.6341e-02],\n",
      "          [-2.3900e-02,  2.7981e-02,  5.1151e-02],\n",
      "          [-4.2646e-02, -5.8678e-02, -1.8359e-02]],\n",
      "\n",
      "         [[ 7.8723e-02,  1.8156e-01,  7.5663e-02],\n",
      "          [-9.2191e-02,  1.2180e-01,  2.3314e-01],\n",
      "          [-3.0343e-01, -1.6234e-01,  1.0052e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7970e-02,  5.9693e-02, -9.1231e-02],\n",
      "          [-4.0070e-03,  7.5055e-02,  1.6213e-03],\n",
      "          [-7.4099e-02, -5.6376e-02, -2.1496e-02]],\n",
      "\n",
      "         [[ 3.3566e-03,  6.1366e-02,  2.0688e-02],\n",
      "          [-7.9430e-02,  6.1304e-02,  1.0144e-01],\n",
      "          [-1.0252e-01, -1.1417e-02,  6.1206e-02]],\n",
      "\n",
      "         [[ 6.8469e-02,  1.5589e-01,  8.3925e-02],\n",
      "          [ 8.1407e-02,  1.5758e-01,  7.1770e-02],\n",
      "          [ 2.4086e-04,  4.3072e-02, -5.6175e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.8213e-02,  1.4371e-01,  1.3067e-01],\n",
      "          [ 5.3704e-02,  1.0403e-01,  6.9597e-02],\n",
      "          [-3.4244e-02,  1.6532e-02, -1.4267e-02]],\n",
      "\n",
      "         [[ 4.2379e-03,  2.6616e-02, -5.4489e-02],\n",
      "          [-7.1645e-02, -8.5212e-02, -9.4023e-02],\n",
      "          [-2.7756e-02, -4.2467e-02, -1.0614e-01]],\n",
      "\n",
      "         [[ 5.0259e-02,  5.4694e-02,  2.5969e-02],\n",
      "          [ 1.0924e-01,  1.2552e-01,  5.7852e-02],\n",
      "          [-5.9752e-02, -1.4109e-02, -5.7377e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.6882e-02,  1.3848e-01,  5.1770e-02],\n",
      "          [ 1.9040e-01, -5.9007e-01,  2.1177e-01],\n",
      "          [-8.2968e-02,  2.9555e-01, -1.4768e-01]],\n",
      "\n",
      "         [[ 8.7431e-02, -7.1312e-02,  1.9093e-02],\n",
      "          [ 3.6008e-01, -2.3130e-01, -4.8798e-03],\n",
      "          [ 9.9330e-02, -1.1189e-01, -2.0355e-02]],\n",
      "\n",
      "         [[-3.7301e-02, -1.1858e-01, -9.9770e-02],\n",
      "          [ 5.2515e-02, -3.9824e-02,  2.4522e-02],\n",
      "          [ 9.3689e-03,  4.5764e-02,  8.6493e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2605e-02,  7.8947e-02,  1.7215e-02],\n",
      "          [-1.1418e-02,  6.4418e-02, -1.8728e-02],\n",
      "          [-1.4710e-02,  1.1208e-02, -3.7734e-02]],\n",
      "\n",
      "         [[-1.2731e-02,  5.2918e-02, -4.7645e-03],\n",
      "          [-1.0713e-02,  1.1140e-01,  9.9228e-03],\n",
      "          [-4.5847e-02,  2.1474e-02, -6.2834e-02]],\n",
      "\n",
      "         [[ 2.9617e-02, -1.3757e-02,  2.8658e-02],\n",
      "          [ 4.2897e-02, -5.3810e-02, -6.1387e-02],\n",
      "          [-4.5756e-02, -2.6736e-02,  4.0155e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.4200e-02, -1.4925e-02, -4.1913e-02],\n",
      "          [-5.1907e-02,  1.1545e-01,  4.8692e-02],\n",
      "          [-7.2569e-02, -1.4462e-02,  6.1013e-02]],\n",
      "\n",
      "         [[ 1.1181e-01,  4.7684e-02,  7.9591e-04],\n",
      "          [ 9.8801e-02,  6.2771e-02,  2.4720e-02],\n",
      "          [ 6.0993e-02,  8.6002e-03,  4.2481e-04]],\n",
      "\n",
      "         [[-6.5582e-02, -8.3117e-02, -2.7078e-02],\n",
      "          [-1.2862e-01, -1.5836e-01, -1.1457e-01],\n",
      "          [-1.2566e-01, -1.5721e-01, -1.0298e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6134e-02,  3.0356e-02,  5.0139e-02],\n",
      "          [-1.9230e-02, -3.1939e-02, -1.5358e-02],\n",
      "          [-6.6711e-02, -5.8428e-02, -4.8036e-02]],\n",
      "\n",
      "         [[-8.9774e-02, -8.9282e-02, -6.1518e-02],\n",
      "          [-2.8268e-02, -4.9507e-02, -3.4678e-02],\n",
      "          [-7.5983e-02, -1.0750e-01, -1.2264e-01]],\n",
      "\n",
      "         [[-4.4752e-02,  2.6340e-02,  9.8847e-03],\n",
      "          [-7.0128e-02, -3.9888e-02,  4.2930e-02],\n",
      "          [-9.2488e-02, -1.3174e-01, -2.5591e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0564e-02, -6.5737e-02, -1.2000e-01],\n",
      "          [ 1.2294e-01,  1.6291e-02,  1.8900e-02],\n",
      "          [-1.0927e-02,  5.7833e-02, -7.1487e-02]],\n",
      "\n",
      "         [[-8.4299e-02, -4.9131e-02,  1.9343e-02],\n",
      "          [ 3.9503e-02, -7.5919e-02, -9.4649e-02],\n",
      "          [ 3.9257e-04,  9.9159e-03, -2.1284e-02]],\n",
      "\n",
      "         [[ 1.3542e-02, -1.1401e-02, -3.8289e-02],\n",
      "          [-1.4392e-02, -3.1779e-02, -4.6823e-02],\n",
      "          [-5.2780e-02, -2.5974e-02, -2.2781e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8397e-03,  1.0069e-02, -3.3036e-02],\n",
      "          [-4.2196e-02, -1.3797e-02, -1.3513e-02],\n",
      "          [-2.3232e-02, -1.9909e-02, -1.1579e-02]],\n",
      "\n",
      "         [[ 6.5186e-02,  6.3930e-02,  1.3022e-01],\n",
      "          [ 8.2003e-02,  6.0076e-02,  4.1387e-02],\n",
      "          [-1.5285e-02,  4.0746e-02, -3.9037e-02]],\n",
      "\n",
      "         [[-3.6784e-02, -8.5578e-02, -1.2553e-01],\n",
      "          [ 1.9061e-01,  1.4401e-01,  5.1568e-02],\n",
      "          [ 2.1836e-03,  2.9062e-02, -6.5153e-02]]]], device='cuda:0')), ('layer1.0.bn1.weight', tensor([0.4641, 0.4024, 0.3691, 0.3430, 0.3824, 0.3041, 0.4173, 0.3821, 0.2591,\n",
      "        0.4297, 0.4438, 0.3843, 0.5457, 0.4881, 0.3532, 0.4315],\n",
      "       device='cuda:0')), ('layer1.0.bn1.bias', tensor([ 0.2822,  0.0492, -0.2451,  0.1084, -0.1702,  0.0441,  0.1770,  0.1359,\n",
      "         0.1250,  0.2466, -0.3695,  0.0431,  0.2009,  0.2543, -0.1227, -0.1458],\n",
      "       device='cuda:0')), ('layer1.0.bn1.running_mean', tensor([-0.8451, -0.8244,  0.3020, -0.9384, -0.5993, -0.6048, -0.5952,  0.0600,\n",
      "        -0.3622, -0.0822,  0.6745, -0.3590, -0.5343, -0.0746, -0.1649,  0.2185],\n",
      "       device='cuda:0')), ('layer1.0.bn1.running_var', tensor([0.2001, 0.2180, 0.1028, 0.2083, 0.0774, 0.1568, 0.3891, 0.2187, 0.1129,\n",
      "        0.1970, 0.1474, 0.3058, 0.2837, 0.3632, 0.2086, 0.2295],\n",
      "       device='cuda:0')), ('layer1.0.bn1.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer1.0.conv2.weight', tensor([[[[-0.1905,  0.2074, -0.0596],\n",
      "          [ 0.1726, -0.0499,  0.1066],\n",
      "          [-0.0891,  0.0755,  0.0452]],\n",
      "\n",
      "         [[ 0.0454, -0.0328, -0.0217],\n",
      "          [ 0.1108, -0.0505, -0.0362],\n",
      "          [ 0.0242,  0.0251, -0.0008]],\n",
      "\n",
      "         [[ 0.0265,  0.0528,  0.0067],\n",
      "          [-0.1401,  0.2104, -0.0065],\n",
      "          [-0.0420,  0.0297,  0.0041]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1282,  0.0055, -0.0384],\n",
      "          [ 0.4259, -0.4064,  0.2263],\n",
      "          [ 0.0156, -0.2316,  0.0146]],\n",
      "\n",
      "         [[ 0.0842, -0.0316,  0.0964],\n",
      "          [-0.0242, -0.0810,  0.0412],\n",
      "          [-0.0116, -0.1016, -0.0383]],\n",
      "\n",
      "         [[-0.0297,  0.0347, -0.0283],\n",
      "          [ 0.0580, -0.0677, -0.0274],\n",
      "          [ 0.0304,  0.0187, -0.0342]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0163,  0.0419, -0.0358],\n",
      "          [-0.0813, -0.0878,  0.3320],\n",
      "          [ 0.0900, -0.0091, -0.1038]],\n",
      "\n",
      "         [[-0.0209,  0.0220, -0.0061],\n",
      "          [ 0.0418, -0.0464, -0.0134],\n",
      "          [ 0.0192, -0.0329,  0.0277]],\n",
      "\n",
      "         [[-0.0172,  0.0195, -0.1149],\n",
      "          [ 0.0464,  0.1002, -0.0519],\n",
      "          [-0.0041, -0.0246,  0.0497]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0223, -0.0641, -0.0309],\n",
      "          [-0.0823, -0.3820,  0.3924],\n",
      "          [ 0.0239, -0.1441, -0.1828]],\n",
      "\n",
      "         [[-0.0453, -0.1348, -0.1259],\n",
      "          [-0.0013, -0.0063, -0.0377],\n",
      "          [-0.0696,  0.0358,  0.0621]],\n",
      "\n",
      "         [[ 0.0538,  0.1263, -0.0270],\n",
      "          [-0.0462, -0.0394,  0.0827],\n",
      "          [-0.0809, -0.0693, -0.0565]]],\n",
      "\n",
      "\n",
      "        [[[-0.0876,  0.0115,  0.1627],\n",
      "          [-0.1306, -0.0725,  0.1296],\n",
      "          [-0.0290, -0.0274,  0.1008]],\n",
      "\n",
      "         [[-0.2416,  0.0069,  0.1043],\n",
      "          [-0.1917,  0.0687,  0.2730],\n",
      "          [-0.0493,  0.0931,  0.2194]],\n",
      "\n",
      "         [[-0.1093,  0.0460,  0.0593],\n",
      "          [-0.1420, -0.0323, -0.0225],\n",
      "          [-0.1081, -0.1123, -0.1453]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0162,  0.0680,  0.0980],\n",
      "          [ 0.0354,  0.0497,  0.0846],\n",
      "          [-0.0158,  0.0288, -0.0233]],\n",
      "\n",
      "         [[-0.0458, -0.1806, -0.1116],\n",
      "          [-0.0440, -0.1307, -0.1173],\n",
      "          [ 0.0957,  0.0037, -0.0169]],\n",
      "\n",
      "         [[-0.0244, -0.0474,  0.0274],\n",
      "          [-0.0140, -0.0327,  0.0531],\n",
      "          [-0.0314, -0.0748, -0.0064]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0652,  0.0267,  0.1111],\n",
      "          [-0.1092, -0.0897,  0.1380],\n",
      "          [-0.0871, -0.1986,  0.0123]],\n",
      "\n",
      "         [[-0.0565, -0.0446, -0.0564],\n",
      "          [ 0.0341,  0.0054, -0.0567],\n",
      "          [ 0.0724,  0.1126,  0.0551]],\n",
      "\n",
      "         [[-0.1671, -0.1839, -0.2029],\n",
      "          [-0.0624, -0.0643, -0.0802],\n",
      "          [-0.0054, -0.0238, -0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0483, -0.0141, -0.0245],\n",
      "          [-0.0579, -0.0512, -0.0121],\n",
      "          [-0.0155,  0.0658,  0.1380]],\n",
      "\n",
      "         [[-0.1120, -0.0793, -0.0248],\n",
      "          [-0.0766, -0.1233, -0.1145],\n",
      "          [ 0.0973,  0.0436, -0.0469]],\n",
      "\n",
      "         [[ 0.0165,  0.0600,  0.0943],\n",
      "          [ 0.0228,  0.0294,  0.0724],\n",
      "          [-0.0140,  0.0021,  0.0057]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1343,  0.1732, -0.0984],\n",
      "          [ 0.1606,  0.0013, -0.0130],\n",
      "          [ 0.0359, -0.0582, -0.1344]],\n",
      "\n",
      "         [[ 0.0611,  0.1270,  0.0712],\n",
      "          [ 0.0611,  0.1149,  0.0635],\n",
      "          [-0.1049, -0.0038, -0.0349]],\n",
      "\n",
      "         [[-0.1389, -0.0995, -0.0733],\n",
      "          [-0.0054,  0.0065, -0.0195],\n",
      "          [ 0.0815,  0.1356,  0.1112]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0847,  0.0600,  0.0005],\n",
      "          [-0.0299, -0.0868,  0.0633],\n",
      "          [ 0.0295, -0.1263, -0.1237]],\n",
      "\n",
      "         [[-0.0499, -0.1145, -0.0605],\n",
      "          [ 0.0647,  0.0353, -0.0168],\n",
      "          [ 0.0098,  0.0637, -0.0068]],\n",
      "\n",
      "         [[-0.0574, -0.0006, -0.0177],\n",
      "          [-0.1908, -0.1384, -0.0630],\n",
      "          [-0.0852, -0.1092,  0.0129]]],\n",
      "\n",
      "\n",
      "        [[[-0.0403,  0.2277,  0.1365],\n",
      "          [-0.1324, -0.1172,  0.0395],\n",
      "          [ 0.1051,  0.1683,  0.0252]],\n",
      "\n",
      "         [[-0.0327, -0.1529, -0.1273],\n",
      "          [ 0.0033, -0.0880, -0.1067],\n",
      "          [ 0.0456,  0.1061,  0.0705]],\n",
      "\n",
      "         [[-0.1559, -0.1828, -0.1509],\n",
      "          [ 0.0118,  0.0148,  0.0339],\n",
      "          [ 0.0631,  0.0724,  0.0979]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0013,  0.1950, -0.0586],\n",
      "          [-0.0175, -0.0687,  0.0187],\n",
      "          [-0.1453,  0.0580,  0.0784]],\n",
      "\n",
      "         [[-0.0130, -0.0760,  0.0290],\n",
      "          [-0.0031, -0.0343,  0.0362],\n",
      "          [ 0.0868,  0.1258,  0.0842]],\n",
      "\n",
      "         [[-0.0088,  0.0422, -0.0029],\n",
      "          [-0.0563, -0.0763, -0.0673],\n",
      "          [-0.1152, -0.0517,  0.0609]]]], device='cuda:0')), ('layer1.0.bn2.weight', tensor([0.7567, 0.5889, 0.4632, 0.4856, 0.3933, 0.4784, 0.5211, 0.3576, 0.3407,\n",
      "        0.5507, 0.4750, 0.3672, 0.7680, 0.2610, 0.4122, 0.4544],\n",
      "       device='cuda:0')), ('layer1.0.bn2.bias', tensor([-0.1273,  0.2355, -0.3700, -0.0569, -0.2170,  0.2391,  0.0867, -0.0559,\n",
      "         0.1772,  0.3718, -0.2481,  0.2337,  0.3520,  0.0069,  0.1791,  0.1964],\n",
      "       device='cuda:0')), ('layer1.0.bn2.running_mean', tensor([-0.0874, -0.0679,  0.2189,  0.0282,  0.0704, -0.0425, -0.5792,  0.2313,\n",
      "        -0.0260, -0.3266, -0.2156, -0.5554, -0.5271, -0.2822,  0.2280,  0.1380],\n",
      "       device='cuda:0')), ('layer1.0.bn2.running_var', tensor([0.2387, 0.3112, 0.0976, 0.1431, 0.2071, 0.1846, 0.3542, 0.1569, 0.1342,\n",
      "        0.1808, 0.1081, 0.1278, 0.3151, 0.1079, 0.2290, 0.1573],\n",
      "       device='cuda:0')), ('layer1.0.bn2.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer1.1.conv1.weight', tensor([[[[-0.1787,  0.1065,  0.0626],\n",
      "          [-0.1301,  0.3464, -0.3056],\n",
      "          [ 0.0436, -0.0144, -0.1319]],\n",
      "\n",
      "         [[-0.2346,  0.1417,  0.0578],\n",
      "          [-0.1980,  0.2829, -0.0088],\n",
      "          [-0.1617,  0.2076, -0.1000]],\n",
      "\n",
      "         [[ 0.0720, -0.0218, -0.0422],\n",
      "          [ 0.0759, -0.0478, -0.0194],\n",
      "          [ 0.0666, -0.0502,  0.0643]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0791,  0.0346,  0.0443],\n",
      "          [ 0.0951, -0.0041, -0.0019],\n",
      "          [ 0.0676, -0.0190,  0.0218]],\n",
      "\n",
      "         [[-0.0225, -0.0721, -0.0693],\n",
      "          [ 0.0091,  0.0261,  0.0056],\n",
      "          [ 0.0596,  0.0431,  0.1133]],\n",
      "\n",
      "         [[ 0.0877, -0.0532, -0.0558],\n",
      "          [ 0.1005, -0.0809, -0.1163],\n",
      "          [ 0.1080, -0.1311, -0.0614]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0100,  0.0281, -0.0068],\n",
      "          [-0.0451, -0.0019, -0.0409],\n",
      "          [ 0.0013,  0.0209, -0.0349]],\n",
      "\n",
      "         [[ 0.1576,  0.0941,  0.0343],\n",
      "          [ 0.0238, -0.0377, -0.0513],\n",
      "          [ 0.0115,  0.0060, -0.0282]],\n",
      "\n",
      "         [[-0.0537, -0.0100,  0.0056],\n",
      "          [-0.0460, -0.0342, -0.0297],\n",
      "          [ 0.0392,  0.0575,  0.0545]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1198,  0.1955,  0.1346],\n",
      "          [-0.0812,  0.0547,  0.0825],\n",
      "          [-0.3156, -0.2490, -0.1896]],\n",
      "\n",
      "         [[-0.2038, -0.2006, -0.2198],\n",
      "          [-0.0174, -0.0265, -0.2112],\n",
      "          [ 0.0988,  0.1117, -0.0152]],\n",
      "\n",
      "         [[ 0.0781,  0.0404, -0.0033],\n",
      "          [ 0.1276,  0.2414,  0.0758],\n",
      "          [-0.1270, -0.0499, -0.0375]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0297, -0.0258,  0.0669],\n",
      "          [ 0.0099, -0.0262, -0.0044],\n",
      "          [ 0.0040, -0.0262,  0.0723]],\n",
      "\n",
      "         [[ 0.0626,  0.1501,  0.0427],\n",
      "          [ 0.0379,  0.0839, -0.0630],\n",
      "          [ 0.1171,  0.0246, -0.0691]],\n",
      "\n",
      "         [[ 0.0276, -0.0265,  0.0614],\n",
      "          [-0.0058, -0.0175,  0.0412],\n",
      "          [-0.0329,  0.0456,  0.0571]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1049,  0.0483, -0.0761],\n",
      "          [ 0.0988, -0.0034, -0.1561],\n",
      "          [ 0.0604, -0.0891, -0.1807]],\n",
      "\n",
      "         [[ 0.0633, -0.0430, -0.0583],\n",
      "          [-0.0718, -0.0831, -0.0132],\n",
      "          [ 0.0087,  0.0478,  0.1096]],\n",
      "\n",
      "         [[ 0.0296,  0.0025, -0.0625],\n",
      "          [ 0.0809,  0.0388, -0.0475],\n",
      "          [ 0.1597, -0.0495, -0.0958]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0315, -0.0162,  0.0336],\n",
      "          [ 0.0927, -0.0294, -0.0590],\n",
      "          [ 0.0480,  0.0878, -0.1677]],\n",
      "\n",
      "         [[ 0.0211, -0.0219, -0.0010],\n",
      "          [ 0.0684,  0.0377,  0.2089],\n",
      "          [-0.1190, -0.0666, -0.1143]],\n",
      "\n",
      "         [[ 0.0088,  0.0186,  0.0986],\n",
      "          [-0.0017,  0.0222,  0.0105],\n",
      "          [ 0.0443,  0.0126, -0.0663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0545, -0.0094, -0.1189],\n",
      "          [ 0.1230,  0.0635, -0.1015],\n",
      "          [ 0.0967,  0.0882, -0.0458]],\n",
      "\n",
      "         [[ 0.0614,  0.0295, -0.0326],\n",
      "          [-0.0721, -0.0934, -0.0672],\n",
      "          [-0.1992, -0.1975, -0.1603]],\n",
      "\n",
      "         [[-0.0159, -0.0107, -0.1303],\n",
      "          [ 0.0052, -0.0267, -0.1381],\n",
      "          [-0.0879, -0.0093, -0.0981]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0338, -0.0790,  0.0732],\n",
      "          [ 0.0128, -0.1403, -0.0250],\n",
      "          [-0.0162, -0.1260, -0.0994]],\n",
      "\n",
      "         [[ 0.0921, -0.0833, -0.1618],\n",
      "          [ 0.1923,  0.0474, -0.2809],\n",
      "          [ 0.0560,  0.1182, -0.1645]],\n",
      "\n",
      "         [[ 0.0600, -0.0024, -0.0888],\n",
      "          [ 0.1277,  0.0318, -0.1047],\n",
      "          [ 0.0647,  0.0843, -0.1123]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0945,  0.0420, -0.0852],\n",
      "          [ 0.0819,  0.0727, -0.0708],\n",
      "          [ 0.0118,  0.0826, -0.0257]],\n",
      "\n",
      "         [[-0.0348,  0.0826,  0.0666],\n",
      "          [-0.0795, -0.0105, -0.0752],\n",
      "          [-0.0774,  0.0275, -0.0918]],\n",
      "\n",
      "         [[ 0.1034, -0.0028, -0.1823],\n",
      "          [ 0.0878,  0.0069, -0.1278],\n",
      "          [-0.0410,  0.0065, -0.1031]]],\n",
      "\n",
      "\n",
      "        [[[-0.1544,  0.0034,  0.0664],\n",
      "          [-0.1898,  0.1941, -0.2009],\n",
      "          [ 0.3555, -0.6186,  0.2483]],\n",
      "\n",
      "         [[-0.3134,  0.0305,  0.0121],\n",
      "          [-0.4515,  0.2828, -0.1112],\n",
      "          [ 0.3652, -0.2738, -0.1388]],\n",
      "\n",
      "         [[ 0.0436,  0.0546, -0.1030],\n",
      "          [-0.0175,  0.0095, -0.0271],\n",
      "          [-0.1192, -0.1473,  0.0347]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0137,  0.1114,  0.0298],\n",
      "          [-0.0076,  0.0059,  0.0663],\n",
      "          [-0.0109, -0.0424,  0.1223]],\n",
      "\n",
      "         [[-0.0016, -0.0827, -0.0198],\n",
      "          [-0.0235, -0.0671, -0.0314],\n",
      "          [ 0.0252, -0.1621,  0.0225]],\n",
      "\n",
      "         [[ 0.0442, -0.0613,  0.0640],\n",
      "          [ 0.0680,  0.1053, -0.0441],\n",
      "          [ 0.0616, -0.0899,  0.1307]]]], device='cuda:0')), ('layer1.1.bn1.weight', tensor([0.6086, 0.3864, 0.4446, 0.4981, 0.6872, 0.5732, 0.4651, 0.3622, 0.4478,\n",
      "        0.3673, 0.6308, 0.3559, 0.4544, 0.3699, 0.4753, 0.5799],\n",
      "       device='cuda:0')), ('layer1.1.bn1.bias', tensor([-0.0797, -0.1584, -0.2279, -0.1601, -0.1280, -0.1238, -0.3060,  0.0213,\n",
      "        -0.1282, -0.1019, -0.0959, -0.1253, -0.0824,  0.0659, -0.1173, -0.1145],\n",
      "       device='cuda:0')), ('layer1.1.bn1.running_mean', tensor([-0.5346, -0.7044, -0.3759, -0.2170,  0.0243, -0.5863,  1.0381, -1.1737,\n",
      "        -0.0078,  0.2803, -0.2066,  0.2591, -0.9362, -1.9068, -0.5195, -0.8456],\n",
      "       device='cuda:0')), ('layer1.1.bn1.running_var', tensor([2.5090, 0.4657, 0.3536, 1.0448, 4.4303, 1.8316, 0.5301, 0.5663, 1.0361,\n",
      "        0.6090, 3.0494, 0.2564, 0.6529, 0.6391, 1.1314, 1.6762],\n",
      "       device='cuda:0')), ('layer1.1.bn1.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer1.1.conv2.weight', tensor([[[[ 3.9673e-02, -1.2200e-03, -1.1980e-01],\n",
      "          [ 1.3675e-01, -9.0670e-03,  1.1260e-01],\n",
      "          [ 7.2771e-02,  8.6567e-02,  7.6586e-02]],\n",
      "\n",
      "         [[ 2.0850e-02, -6.7489e-03, -9.5331e-03],\n",
      "          [-9.8163e-02, -1.2596e-03,  1.5868e-02],\n",
      "          [-6.8135e-02,  7.4773e-03,  1.6991e-02]],\n",
      "\n",
      "         [[-8.7148e-02, -3.4601e-02, -6.5162e-02],\n",
      "          [-4.8610e-02,  3.0866e-02, -2.2153e-02],\n",
      "          [-6.9819e-02,  1.6415e-02, -1.8362e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.5619e-02, -1.0777e-01, -1.8086e-02],\n",
      "          [-4.5570e-02, -5.3598e-02,  1.3169e-02],\n",
      "          [-2.9003e-02, -5.1393e-02,  4.7894e-02]],\n",
      "\n",
      "         [[-1.0631e-01,  5.3785e-04, -6.8947e-03],\n",
      "          [ 6.4178e-02,  1.3049e-01,  9.6329e-03],\n",
      "          [ 3.9301e-03,  4.0586e-02, -6.1794e-02]],\n",
      "\n",
      "         [[-1.0105e-01,  8.1044e-02, -5.8475e-02],\n",
      "          [ 1.2088e-01, -8.4868e-03,  1.1010e-01],\n",
      "          [-9.6833e-02,  3.3190e-02,  9.6479e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.9998e-02, -1.8794e-01, -1.3838e-02],\n",
      "          [-4.1247e-02, -1.0016e-01,  6.9693e-02],\n",
      "          [-3.6779e-02,  2.1456e-02,  8.4758e-02]],\n",
      "\n",
      "         [[ 2.2452e-02, -4.2382e-02, -5.7394e-02],\n",
      "          [-5.3449e-02, -7.0741e-02, -9.5715e-02],\n",
      "          [-2.7142e-02, -2.4111e-02, -3.9015e-02]],\n",
      "\n",
      "         [[-9.3981e-02, -4.0863e-02,  2.5435e-02],\n",
      "          [-3.7169e-02, -8.4889e-04,  5.7780e-03],\n",
      "          [-2.8086e-02, -2.6938e-02, -5.6718e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2637e-03, -7.4309e-02,  8.1495e-03],\n",
      "          [ 1.2358e-01,  1.2610e-01,  6.7089e-02],\n",
      "          [ 1.4713e-01,  1.4547e-01,  9.2076e-02]],\n",
      "\n",
      "         [[-9.3039e-03,  1.7051e-01,  1.1159e-01],\n",
      "          [ 1.4157e-02,  9.0035e-02,  1.4060e-02],\n",
      "          [ 5.2660e-03, -8.3728e-03, -3.4638e-02]],\n",
      "\n",
      "         [[ 1.6826e-01,  2.4348e-01,  9.6789e-02],\n",
      "          [ 1.8461e-01,  2.1731e-01,  2.6813e-01],\n",
      "          [ 1.0543e-01,  2.6674e-01,  1.7704e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.6248e-02, -1.2394e-01, -6.9443e-02],\n",
      "          [-1.2689e-01, -1.6301e-01, -1.6145e-01],\n",
      "          [-6.2915e-02, -1.9511e-01, -1.0904e-01]],\n",
      "\n",
      "         [[-6.3360e-02, -2.7438e-02,  2.4801e-02],\n",
      "          [-9.3373e-02, -6.3128e-02,  1.9167e-02],\n",
      "          [-1.3895e-01, -8.5391e-02, -9.7638e-03]],\n",
      "\n",
      "         [[-4.2399e-02, -9.4294e-02, -4.3612e-02],\n",
      "          [-5.4131e-02, -1.3212e-01, -9.3472e-02],\n",
      "          [-1.0294e-02, -9.4601e-02, -7.2311e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6190e-02, -1.1726e-02,  3.8276e-04],\n",
      "          [-1.3299e-01, -9.1544e-02, -4.0565e-02],\n",
      "          [-1.3059e-01, -7.1320e-02,  1.4272e-02]],\n",
      "\n",
      "         [[-1.2661e-01, -1.1325e-01,  3.9994e-02],\n",
      "          [-9.0111e-02, -8.5403e-02, -1.6987e-02],\n",
      "          [-7.0062e-02, -3.6782e-02, -3.1130e-02]],\n",
      "\n",
      "         [[ 4.1294e-02,  6.0805e-02,  6.8863e-02],\n",
      "          [ 2.0195e-02,  9.7693e-02,  5.8356e-02],\n",
      "          [-6.4067e-02,  2.0432e-02,  3.0453e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3356e-01, -2.0962e-01, -9.3997e-02],\n",
      "          [-2.1675e-01, -3.5555e-01, -2.0211e-01],\n",
      "          [-9.2399e-02, -2.6148e-01, -1.1630e-01]],\n",
      "\n",
      "         [[ 1.4166e-01, -1.5132e-02, -9.2842e-02],\n",
      "          [ 1.1600e-01,  5.0137e-02, -2.6608e-02],\n",
      "          [ 4.4057e-02,  1.0387e-01,  9.0361e-02]],\n",
      "\n",
      "         [[-6.1084e-02, -8.2812e-02, -7.0940e-02],\n",
      "          [-1.3198e-01, -1.6313e-01, -4.9208e-02],\n",
      "          [-6.7699e-02, -4.2751e-02,  3.5585e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0562e-01, -7.9313e-02,  4.7069e-02],\n",
      "          [-8.7681e-02,  1.2041e-02,  8.0891e-02],\n",
      "          [-2.6864e-02,  2.5190e-02,  2.2359e-02]],\n",
      "\n",
      "         [[-7.9610e-02, -9.0821e-02, -6.0211e-02],\n",
      "          [-1.8790e-01, -1.7765e-01, -3.6833e-02],\n",
      "          [-8.6055e-02, -7.7750e-02, -2.3722e-02]],\n",
      "\n",
      "         [[-7.2871e-03,  2.3615e-02, -2.0892e-02],\n",
      "          [-3.0775e-02, -6.8112e-02, -3.7680e-02],\n",
      "          [ 9.7494e-02,  2.6060e-02, -4.8313e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9074e-02, -9.9893e-02, -1.3298e-02],\n",
      "          [-1.4714e-01, -1.7006e-01, -6.7562e-02],\n",
      "          [-8.0563e-02, -1.0294e-01, -1.2341e-01]],\n",
      "\n",
      "         [[ 1.2307e-01,  1.9958e-01,  1.1068e-01],\n",
      "          [ 9.3253e-02,  1.9805e-01,  1.6916e-01],\n",
      "          [-4.7384e-02,  2.1061e-02,  7.8784e-02]],\n",
      "\n",
      "         [[-3.6221e-02,  1.0110e-02,  5.1588e-02],\n",
      "          [ 1.5199e-02,  4.2586e-02,  2.4226e-02],\n",
      "          [-2.3537e-03, -4.4750e-02, -1.4530e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.3278e-02, -5.0150e-02, -8.6463e-02],\n",
      "          [-1.5237e-03, -1.4778e-01, -1.0665e-01],\n",
      "          [-1.4428e-02, -3.1088e-04,  1.3049e-02]],\n",
      "\n",
      "         [[ 1.1390e-02, -8.2448e-02, -3.6647e-02],\n",
      "          [-8.4689e-02, -1.2268e-01, -4.8344e-02],\n",
      "          [-3.1844e-02, -1.4552e-01, -5.6306e-03]],\n",
      "\n",
      "         [[-6.9338e-02,  3.0868e-02,  9.6394e-03],\n",
      "          [-2.7652e-02, -6.9143e-02,  8.6878e-02],\n",
      "          [-1.2879e-02, -2.9926e-03, -4.9771e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1191e-02,  1.0686e-01,  5.4349e-02],\n",
      "          [ 2.7336e-02,  1.3301e-01,  1.2035e-01],\n",
      "          [ 5.5732e-02,  1.5523e-01,  1.3776e-01]],\n",
      "\n",
      "         [[-1.6638e-01, -1.1574e-01, -2.9981e-02],\n",
      "          [-1.5056e-01, -7.6149e-02, -4.3635e-03],\n",
      "          [ 4.9752e-04,  4.7076e-02,  4.7275e-02]],\n",
      "\n",
      "         [[-1.3947e-01, -4.6992e-02, -4.7222e-03],\n",
      "          [ 5.2323e-03,  1.7380e-01,  1.5383e-01],\n",
      "          [ 1.2948e-01,  1.6619e-01,  1.1123e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2413e-02, -8.1050e-03, -5.6628e-02],\n",
      "          [ 2.8258e-02,  7.3098e-02,  1.5013e-02],\n",
      "          [ 3.8880e-02,  1.3299e-01,  1.0926e-01]],\n",
      "\n",
      "         [[ 1.0254e-01,  8.0593e-02,  4.6904e-02],\n",
      "          [ 5.0204e-02,  6.8372e-02,  8.7585e-02],\n",
      "          [ 1.8880e-02,  1.1800e-01,  3.6073e-02]],\n",
      "\n",
      "         [[-8.1315e-02, -6.1548e-02, -6.1171e-02],\n",
      "          [-4.2729e-02, -9.7419e-02, -1.1315e-01],\n",
      "          [-1.1923e-01, -7.5111e-02, -8.3210e-02]]]], device='cuda:0')), ('layer1.1.bn2.weight', tensor([0.5635, 0.4580, 0.2816, 0.3349, 0.3934, 0.4358, 0.3469, 0.2612, 0.3370,\n",
      "        0.4093, 0.3497, 0.3703, 0.6867, 0.4410, 0.2934, 0.4366],\n",
      "       device='cuda:0')), ('layer1.1.bn2.bias', tensor([-0.0676,  0.1615,  0.2983,  0.2479,  0.1376,  0.0199,  0.0903,  0.0395,\n",
      "        -0.0687, -0.3152,  0.2939,  0.2136, -0.1686,  0.4042,  0.2266, -0.0361],\n",
      "       device='cuda:0')), ('layer1.1.bn2.running_mean', tensor([ 0.2364,  0.1232, -0.3459,  0.2046,  0.3183, -0.3254,  0.0216,  0.2411,\n",
      "        -0.1342, -0.0171,  0.0763, -0.5032, -0.3052, -0.6352, -0.2793,  0.3255],\n",
      "       device='cuda:0')), ('layer1.1.bn2.running_var', tensor([0.1941, 0.1668, 0.1095, 0.1187, 0.1973, 0.1154, 0.1460, 0.0815, 0.0847,\n",
      "        0.0955, 0.1333, 0.1763, 0.1877, 0.2524, 0.1402, 0.1193],\n",
      "       device='cuda:0')), ('layer1.1.bn2.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer2.0.conv1.weight', tensor([[[[-6.7541e-02,  3.4914e-02, -5.3495e-02],\n",
      "          [-1.0475e-02, -3.4360e-02,  3.3479e-02],\n",
      "          [-3.1352e-03,  2.4077e-03,  6.6968e-02]],\n",
      "\n",
      "         [[-2.4899e-02,  1.3961e-02, -2.7114e-02],\n",
      "          [ 8.5825e-02,  5.3604e-02,  7.2895e-02],\n",
      "          [ 6.9167e-02,  5.0140e-02,  3.1092e-02]],\n",
      "\n",
      "         [[-1.7521e-02,  4.5493e-02,  4.1404e-02],\n",
      "          [-3.4396e-02,  2.0342e-02,  9.0460e-02],\n",
      "          [-4.1536e-02, -4.7547e-02,  4.5166e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5708e-02, -1.3022e-03, -9.6410e-03],\n",
      "          [ 1.0906e-01,  4.5344e-02,  2.0044e-02],\n",
      "          [ 9.4139e-02,  5.5675e-02,  8.5656e-03]],\n",
      "\n",
      "         [[ 1.0863e-01,  1.2170e-01,  9.1136e-02],\n",
      "          [ 5.0582e-02,  4.8677e-02,  1.4882e-01],\n",
      "          [-4.1969e-02,  4.4326e-02,  6.0428e-02]],\n",
      "\n",
      "         [[-4.2819e-02, -1.6369e-01, -1.7522e-01],\n",
      "          [ 1.3961e-01,  1.4044e-02, -1.8190e-01],\n",
      "          [ 1.4092e-01,  9.1440e-02, -5.3276e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.1357e-02, -3.5106e-02, -5.7884e-02],\n",
      "          [-1.2782e-02,  4.8351e-02, -6.8344e-02],\n",
      "          [-9.7513e-02,  2.3474e-02,  3.2085e-02]],\n",
      "\n",
      "         [[ 1.3852e-01,  1.2582e-05, -5.1984e-02],\n",
      "          [ 8.3299e-02,  1.6820e-01,  1.2832e-01],\n",
      "          [-1.4905e-01, -4.9862e-03,  5.2807e-02]],\n",
      "\n",
      "         [[-1.0724e-02, -5.3638e-02, -4.4034e-02],\n",
      "          [ 3.2102e-02,  8.1352e-03, -3.8594e-02],\n",
      "          [ 1.2260e-01,  1.0972e-01,  3.7442e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0088e-02,  4.8906e-02,  1.4507e-02],\n",
      "          [-2.7074e-02,  3.1220e-02,  2.4007e-02],\n",
      "          [ 9.0112e-04,  4.7721e-02,  4.3965e-02]],\n",
      "\n",
      "         [[ 2.3126e-02,  8.5147e-02,  1.2890e-02],\n",
      "          [-6.0404e-02,  1.1160e-01,  1.3199e-01],\n",
      "          [-2.0051e-01, -1.2458e-01,  6.5628e-02]],\n",
      "\n",
      "         [[-4.1647e-02,  3.2422e-02,  3.5214e-02],\n",
      "          [-2.8266e-02, -3.5026e-02, -4.5057e-02],\n",
      "          [-7.0330e-02, -2.7104e-02,  6.5101e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7386e-03,  6.3951e-02,  5.5349e-02],\n",
      "          [-1.6685e-02, -1.1457e-01,  7.2302e-02],\n",
      "          [-1.5122e-02, -9.2420e-02,  1.1647e-02]],\n",
      "\n",
      "         [[-3.0204e-02, -1.2398e-02,  8.8783e-02],\n",
      "          [ 4.3533e-02, -1.6761e-01,  1.3114e-01],\n",
      "          [ 5.4025e-02, -8.2237e-02, -7.8986e-02]],\n",
      "\n",
      "         [[-1.0600e-01,  9.8944e-02,  1.2046e-01],\n",
      "          [-1.9102e-01,  4.1638e-02,  1.6347e-01],\n",
      "          [-1.1759e-01, -4.5169e-02,  1.1449e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.0994e-02,  3.8555e-02,  7.7717e-02],\n",
      "          [-7.5265e-02,  1.6308e-02,  6.5640e-02],\n",
      "          [-6.3177e-02, -5.2059e-02,  4.2154e-02]],\n",
      "\n",
      "         [[ 1.0672e-01, -2.7696e-02, -3.6779e-02],\n",
      "          [ 1.0556e-01,  1.3356e-02, -1.3509e-01],\n",
      "          [ 3.8003e-02,  4.8817e-02, -1.2885e-01]],\n",
      "\n",
      "         [[-2.0076e-02, -5.8844e-02, -6.4563e-02],\n",
      "          [-5.3307e-02, -3.6432e-02, -2.4325e-02],\n",
      "          [-3.3372e-02,  5.3947e-02, -2.7699e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.8585e-02,  2.2163e-02,  2.9402e-02],\n",
      "          [-4.9659e-03, -2.7872e-02,  4.0112e-02],\n",
      "          [-7.6394e-02,  2.4095e-02, -1.1567e-02]],\n",
      "\n",
      "         [[ 2.5151e-02,  1.2298e-01,  1.1516e-01],\n",
      "          [ 1.1850e-02,  1.8388e-02,  4.6235e-02],\n",
      "          [ 6.0032e-03,  1.0710e-01,  1.1651e-01]],\n",
      "\n",
      "         [[ 5.1517e-02, -4.8080e-03, -6.0007e-03],\n",
      "          [ 6.1071e-02, -3.1122e-02, -3.4668e-02],\n",
      "          [ 4.0052e-02, -2.8045e-02, -2.9987e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0463e-02,  4.1527e-02,  1.0998e-01],\n",
      "          [-9.8537e-02,  1.0955e-02,  1.2733e-01],\n",
      "          [-7.9986e-02, -2.1731e-02,  1.1561e-01]],\n",
      "\n",
      "         [[ 4.5813e-02,  5.5173e-02,  5.2140e-02],\n",
      "          [-8.0571e-03,  7.7350e-02,  6.6143e-04],\n",
      "          [ 2.9565e-02,  6.8161e-03,  4.4752e-02]],\n",
      "\n",
      "         [[-8.0339e-02,  1.5979e-03,  1.6616e-02],\n",
      "          [-1.0183e-01, -3.2934e-02,  1.5580e-03],\n",
      "          [-1.6003e-01, -6.0668e-02, -4.6084e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3247e-03,  4.3749e-02,  2.4468e-02],\n",
      "          [ 1.4779e-03,  7.2620e-02, -6.5771e-04],\n",
      "          [-1.3977e-02, -4.2409e-02, -6.1028e-02]],\n",
      "\n",
      "         [[-4.3134e-03, -6.8664e-02, -1.5288e-01],\n",
      "          [ 5.3038e-02, -1.6974e-02, -8.8231e-02],\n",
      "          [-3.9048e-02, -9.0828e-02, -9.6679e-02]],\n",
      "\n",
      "         [[ 3.3415e-02,  4.2245e-02,  3.0735e-02],\n",
      "          [-9.1016e-02, -4.7479e-02,  2.1363e-02],\n",
      "          [-1.9224e-01, -1.0979e-01, -2.1524e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8543e-02, -7.0625e-02, -5.7729e-02],\n",
      "          [-3.9120e-02, -1.4590e-02,  1.0111e-02],\n",
      "          [-2.9085e-02,  4.1553e-02,  1.0022e-01]],\n",
      "\n",
      "         [[-9.3118e-02, -8.0320e-02,  9.4330e-02],\n",
      "          [-1.2551e-01, -1.3384e-01,  5.7502e-03],\n",
      "          [-1.0190e-01, -1.1606e-01, -2.5528e-02]],\n",
      "\n",
      "         [[ 1.0076e-01,  8.3725e-02,  4.8339e-02],\n",
      "          [ 3.7594e-02,  7.4799e-02,  1.0974e-01],\n",
      "          [-1.2119e-01, -6.6360e-02, -2.1058e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1516e-02,  1.1322e-01,  7.2907e-03],\n",
      "          [ 2.2459e-02,  4.0187e-02, -1.3326e-03],\n",
      "          [ 4.8074e-02,  6.2031e-02,  6.5297e-02]],\n",
      "\n",
      "         [[ 9.9577e-03, -3.8097e-02, -1.0566e-02],\n",
      "          [ 4.3132e-02,  8.0673e-03, -1.6101e-02],\n",
      "          [-1.5069e-03,  2.6647e-02,  3.1851e-02]],\n",
      "\n",
      "         [[ 2.0369e-02,  4.5360e-02,  1.0727e-01],\n",
      "          [-1.2971e-01, -1.1288e-01, -4.5156e-02],\n",
      "          [-2.6918e-01, -2.8893e-01, -2.0207e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0528e-02,  6.0052e-02,  6.8415e-02],\n",
      "          [-9.8604e-02, -3.2700e-02,  1.0652e-02],\n",
      "          [-1.0965e-01, -8.4858e-02, -7.3218e-02]],\n",
      "\n",
      "         [[ 4.5523e-02,  9.2347e-02,  8.3459e-02],\n",
      "          [-5.6913e-04,  8.8525e-02,  9.0106e-02],\n",
      "          [-5.8893e-02,  4.5142e-02,  5.6288e-02]],\n",
      "\n",
      "         [[-4.5943e-02,  3.7379e-02,  2.6658e-02],\n",
      "          [ 6.8718e-02, -1.4352e-02,  1.1987e-02],\n",
      "          [-1.0153e-03, -2.7339e-02, -5.8428e-02]]]], device='cuda:0')), ('layer2.0.bn1.weight', tensor([0.4233, 0.3893, 0.3655, 0.4730, 0.4138, 0.4077, 0.3887, 0.4352, 0.3987,\n",
      "        0.4249, 0.4396, 0.4437, 0.4133, 0.4015, 0.3834, 0.4045, 0.4158, 0.4594,\n",
      "        0.4003, 0.3986, 0.4451, 0.4301, 0.3836, 0.4575, 0.5625, 0.3519, 0.3952,\n",
      "        0.4236, 0.4256, 0.4184, 0.4316, 0.3757], device='cuda:0')), ('layer2.0.bn1.bias', tensor([-0.0489, -0.0571, -0.0486,  0.0711,  0.0933, -0.1780, -0.0292, -0.0910,\n",
      "        -0.0057, -0.0266, -0.1981, -0.0546,  0.0293,  0.2029,  0.1205, -0.0587,\n",
      "        -0.2512, -0.1929, -0.0014, -0.1393, -0.0906,  0.0026, -0.1365, -0.2375,\n",
      "        -0.2175, -0.1573, -0.0733, -0.1236, -0.0139, -0.1421,  0.0347, -0.1072],\n",
      "       device='cuda:0')), ('layer2.0.bn1.running_mean', tensor([-0.4412,  0.2011, -0.3888, -0.0291, -1.7686, -1.1735,  1.2302, -1.0509,\n",
      "         1.1178,  0.9920, -0.9788, -0.4628, -0.2252, -0.5851,  0.7475,  0.5611,\n",
      "         0.8837,  0.0395, -1.5537, -0.8481,  0.2808, -0.5401,  1.2177, -1.6907,\n",
      "        -0.0851,  0.6054, -1.0462,  0.1182, -1.4545, -0.2334, -1.7977, -0.2781],\n",
      "       device='cuda:0')), ('layer2.0.bn1.running_var', tensor([0.8671, 0.8053, 0.4472, 2.2323, 0.8150, 0.7895, 0.8138, 0.6345, 0.7598,\n",
      "        0.7616, 0.9845, 0.6267, 0.5502, 1.7138, 0.7290, 0.6955, 0.8488, 0.6519,\n",
      "        1.3937, 0.6884, 0.7890, 0.6199, 0.4498, 0.6195, 0.9641, 0.4268, 0.6550,\n",
      "        0.7976, 0.9126, 0.7984, 1.3917, 0.6448], device='cuda:0')), ('layer2.0.bn1.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer2.0.conv2.weight', tensor([[[[-1.1912e-02,  1.3157e-02,  4.7839e-02],\n",
      "          [-7.5339e-02, -6.5415e-02, -7.6023e-02],\n",
      "          [-2.4323e-02, -7.7701e-02, -1.1625e-01]],\n",
      "\n",
      "         [[-5.5256e-02, -1.0662e-01,  3.9021e-02],\n",
      "          [-4.6065e-02,  1.3992e-02,  1.1212e-02],\n",
      "          [ 4.3180e-02,  8.4336e-02, -7.5662e-02]],\n",
      "\n",
      "         [[-8.7147e-02,  3.6029e-02,  1.7714e-02],\n",
      "          [-4.9614e-03,  4.5359e-02,  8.7350e-02],\n",
      "          [-5.1432e-03,  4.2350e-02, -5.4452e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0962e-02, -4.6257e-02,  2.6983e-02],\n",
      "          [ 5.3945e-02,  7.2094e-03, -2.8235e-02],\n",
      "          [ 4.8621e-02,  5.1886e-02, -3.8609e-02]],\n",
      "\n",
      "         [[ 3.3549e-02, -3.5340e-02, -2.9336e-02],\n",
      "          [-6.8900e-02, -4.2965e-02, -2.8495e-02],\n",
      "          [ 1.5501e-02, -5.4410e-02, -1.1842e-02]],\n",
      "\n",
      "         [[ 1.8983e-02,  1.0700e-01, -5.6028e-02],\n",
      "          [ 1.1638e-01,  1.9519e-01,  5.6231e-02],\n",
      "          [-6.4694e-02, -7.4835e-02, -2.6506e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2725e-02,  2.6527e-02, -9.3530e-07],\n",
      "          [ 5.7822e-02, -4.8927e-02, -2.2816e-03],\n",
      "          [ 1.0230e-01, -6.4203e-02, -8.1129e-02]],\n",
      "\n",
      "         [[ 2.7546e-02, -4.7357e-02, -2.3043e-02],\n",
      "          [ 5.6445e-03, -3.1925e-02, -2.6404e-02],\n",
      "          [-7.3641e-02, -2.9113e-02, -2.0142e-02]],\n",
      "\n",
      "         [[-3.3291e-02, -1.0412e-01,  5.0145e-02],\n",
      "          [-3.6071e-02, -8.7900e-02,  2.2057e-03],\n",
      "          [-5.1292e-02, -9.6579e-02, -5.5825e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0798e-02, -1.4562e-02,  6.8687e-02],\n",
      "          [-1.5544e-02,  2.5164e-02,  5.9337e-02],\n",
      "          [-1.8213e-03,  3.9843e-02, -2.5819e-03]],\n",
      "\n",
      "         [[ 6.0013e-02, -5.8603e-02, -1.1068e-01],\n",
      "          [ 7.3005e-02, -2.6858e-02, -4.8138e-02],\n",
      "          [-5.9850e-02, -9.2587e-02, -9.1176e-02]],\n",
      "\n",
      "         [[-3.2550e-02, -1.2163e-02,  3.2362e-02],\n",
      "          [-8.9254e-02, -6.8999e-02,  3.9801e-02],\n",
      "          [-1.4381e-02, -2.1610e-02,  1.9399e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2219e-03,  4.7637e-02,  5.4169e-02],\n",
      "          [ 2.2224e-02, -5.3867e-02,  6.8781e-02],\n",
      "          [ 3.8172e-02, -6.9974e-02,  6.1477e-02]],\n",
      "\n",
      "         [[ 1.9152e-02,  2.9667e-02, -1.3919e-02],\n",
      "          [ 5.7562e-02, -4.0610e-04,  1.8577e-02],\n",
      "          [-1.2242e-02, -2.6671e-02,  1.8578e-02]],\n",
      "\n",
      "         [[ 8.4720e-02,  2.0960e-02,  4.2007e-03],\n",
      "          [ 1.0319e-01,  4.7592e-02, -3.1854e-02],\n",
      "          [ 6.3936e-02,  8.0023e-02, -4.5576e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1211e-03,  7.5492e-02,  7.8925e-02],\n",
      "          [ 3.6612e-02,  3.5754e-02,  1.2569e-02],\n",
      "          [-2.9037e-02, -5.6387e-02, -3.5358e-02]],\n",
      "\n",
      "         [[-9.4317e-03,  1.0253e-01, -1.8848e-02],\n",
      "          [-7.8374e-02,  3.5965e-03, -3.1658e-02],\n",
      "          [-1.1047e-01, -1.5565e-01, -9.3141e-02]],\n",
      "\n",
      "         [[ 1.0372e-01,  4.5068e-02, -6.7673e-02],\n",
      "          [ 1.0963e-01,  4.4750e-02, -1.6219e-02],\n",
      "          [ 3.1376e-02,  5.8806e-02, -6.8154e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.6784e-01, -3.1504e-03,  2.1615e-02],\n",
      "          [-2.0699e-01, -3.7576e-02,  1.4606e-01],\n",
      "          [-1.1407e-03, -1.4540e-03, -3.7592e-02]],\n",
      "\n",
      "         [[-7.1424e-02,  1.6097e-02,  1.3843e-03],\n",
      "          [-6.9641e-02, -6.5184e-02,  7.9426e-02],\n",
      "          [ 7.5551e-02,  1.3322e-03, -1.5411e-02]],\n",
      "\n",
      "         [[ 5.1595e-02, -1.4521e-02,  1.0386e-01],\n",
      "          [-5.0006e-02, -8.1554e-02,  7.3975e-02],\n",
      "          [ 7.6731e-02,  9.9045e-03, -1.0492e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6840e-02, -9.9877e-02,  2.1822e-03],\n",
      "          [-6.6094e-02, -9.9996e-02, -1.0484e-02],\n",
      "          [-2.3144e-02,  1.1521e-02,  3.2595e-02]],\n",
      "\n",
      "         [[-1.3542e-01, -2.2798e-02, -5.1551e-02],\n",
      "          [-7.0685e-02,  1.5543e-01, -2.5634e-02],\n",
      "          [-5.6634e-02,  5.9946e-02, -4.9818e-02]],\n",
      "\n",
      "         [[ 2.1119e-02, -5.0873e-02, -3.1432e-02],\n",
      "          [-5.3974e-03,  2.2608e-02, -1.0844e-01],\n",
      "          [ 3.7260e-02,  5.3066e-02, -8.5429e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.3732e-02, -1.8416e-02,  1.2631e-02],\n",
      "          [-3.0129e-02, -8.0375e-02, -4.1991e-02],\n",
      "          [-8.8748e-02, -6.5034e-02, -2.3626e-02]],\n",
      "\n",
      "         [[-7.6952e-02,  1.4985e-02,  2.5621e-02],\n",
      "          [-1.1032e-01, -4.0348e-02,  9.9441e-02],\n",
      "          [-5.4811e-02, -2.6869e-03,  3.7733e-02]],\n",
      "\n",
      "         [[-5.5031e-02, -5.0482e-02,  4.5763e-02],\n",
      "          [-5.8710e-02, -2.7487e-02,  1.0507e-01],\n",
      "          [-4.6363e-02, -1.5447e-02,  6.1224e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4953e-01,  1.0756e-02,  3.9974e-03],\n",
      "          [-1.0831e-01,  6.3872e-02, -1.6108e-02],\n",
      "          [-7.2123e-02,  7.3749e-02,  2.1791e-02]],\n",
      "\n",
      "         [[ 3.9775e-02,  1.0638e-01, -1.2861e-01],\n",
      "          [ 1.0978e-01,  2.5833e-01, -6.5467e-02],\n",
      "          [-1.4509e-02,  1.4894e-01, -7.7455e-02]],\n",
      "\n",
      "         [[-1.0859e-01, -4.2633e-02,  4.8622e-02],\n",
      "          [-1.3879e-02, -4.5625e-02,  4.8238e-02],\n",
      "          [ 4.7308e-02,  2.0387e-02,  4.9220e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5651e-02, -3.4637e-02, -7.3533e-02],\n",
      "          [-1.9266e-01, -8.3296e-02, -1.7772e-02],\n",
      "          [-1.5987e-01, -9.2456e-02, -3.5085e-02]],\n",
      "\n",
      "         [[-2.2695e-02, -9.9636e-02, -1.3637e-01],\n",
      "          [-7.1603e-02, -1.8361e-01, -1.4391e-01],\n",
      "          [-3.6853e-02, -1.5346e-01, -5.9206e-02]],\n",
      "\n",
      "         [[-6.5195e-03,  3.4655e-02, -1.2297e-01],\n",
      "          [-5.2522e-02, -1.5905e-01, -1.3147e-01],\n",
      "          [-8.6065e-02, -1.0119e-01, -4.2506e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6939e-02,  1.3592e-01,  2.8751e-02],\n",
      "          [ 3.8348e-04,  1.0889e-01, -5.7648e-02],\n",
      "          [ 1.1643e-02,  1.8106e-02, -7.0005e-02]],\n",
      "\n",
      "         [[ 4.3628e-02,  5.1906e-02, -3.6918e-02],\n",
      "          [ 1.9877e-02, -2.3903e-02, -7.2719e-02],\n",
      "          [-1.3910e-01, -5.5897e-02, -3.0890e-02]],\n",
      "\n",
      "         [[ 7.0393e-02, -5.7422e-02, -8.0077e-03],\n",
      "          [-3.0716e-02, -1.6715e-02,  3.1547e-02],\n",
      "          [-4.5963e-02, -9.6136e-02, -3.9577e-02]]]], device='cuda:0')), ('layer2.0.bn2.weight', tensor([0.4534, 0.4961, 0.3527, 0.3856, 0.6153, 0.5171, 0.5236, 0.4041, 0.4323,\n",
      "        0.3633, 0.3445, 0.3327, 0.3041, 0.4375, 0.4824, 0.5352, 0.2833, 0.4286,\n",
      "        0.4467, 0.4487, 0.5535, 0.4479, 0.4224, 0.4674, 0.3058, 0.5903, 0.4679,\n",
      "        0.5536, 0.5169, 0.5375, 0.4308, 0.5983], device='cuda:0')), ('layer2.0.bn2.bias', tensor([-0.0911,  0.0426,  0.0700,  0.1048,  0.0093, -0.0706, -0.0680,  0.0853,\n",
      "        -0.0371,  0.1359,  0.0737,  0.1410,  0.0868,  0.0867, -0.1225, -0.0392,\n",
      "         0.1110,  0.1007,  0.1309, -0.0846,  0.0275,  0.0910,  0.0239,  0.0275,\n",
      "         0.0223, -0.0078, -0.0169,  0.0478, -0.0067,  0.0138, -0.0105, -0.0117],\n",
      "       device='cuda:0')), ('layer2.0.bn2.running_mean', tensor([-0.3325, -0.6056,  0.3182, -0.3738,  0.1841, -0.1045, -0.4787,  0.1435,\n",
      "         0.1194,  0.1231, -0.2759,  0.0009, -0.2472, -0.2311,  0.2902, -0.1114,\n",
      "        -0.3594, -0.7054,  0.1321, -0.0359, -0.4656,  0.1844, -0.3056, -0.1679,\n",
      "        -0.2996, -0.4666, -0.7189, -0.1963, -0.3891, -0.1476, -0.2342, -0.0765],\n",
      "       device='cuda:0')), ('layer2.0.bn2.running_var', tensor([0.1525, 0.1546, 0.1954, 0.1384, 0.2433, 0.1692, 0.1632, 0.1589, 0.1446,\n",
      "        0.2127, 0.1828, 0.2122, 0.1813, 0.1702, 0.1593, 0.1383, 0.1515, 0.1802,\n",
      "        0.1784, 0.1317, 0.2051, 0.1960, 0.1340, 0.1754, 0.1211, 0.1808, 0.1495,\n",
      "        0.2875, 0.2118, 0.2012, 0.1242, 0.3079], device='cuda:0')), ('layer2.0.bn2.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer2.0.shortcut.0.weight', tensor([[[[ 1.8554e-01]],\n",
      "\n",
      "         [[-1.0184e-01]],\n",
      "\n",
      "         [[-9.7583e-02]],\n",
      "\n",
      "         [[-7.6228e-02]],\n",
      "\n",
      "         [[ 1.4924e-01]],\n",
      "\n",
      "         [[-3.4651e-02]],\n",
      "\n",
      "         [[-2.5699e-02]],\n",
      "\n",
      "         [[-9.3280e-02]],\n",
      "\n",
      "         [[ 1.8513e-01]],\n",
      "\n",
      "         [[ 1.8770e-01]],\n",
      "\n",
      "         [[ 8.1239e-02]],\n",
      "\n",
      "         [[ 2.0150e-01]],\n",
      "\n",
      "         [[ 3.6621e-03]],\n",
      "\n",
      "         [[ 1.7308e-02]],\n",
      "\n",
      "         [[-1.8128e-01]],\n",
      "\n",
      "         [[-5.4743e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2412e-02]],\n",
      "\n",
      "         [[ 7.4083e-02]],\n",
      "\n",
      "         [[ 1.1703e-02]],\n",
      "\n",
      "         [[ 1.9463e-01]],\n",
      "\n",
      "         [[ 4.1565e-02]],\n",
      "\n",
      "         [[ 1.6844e-02]],\n",
      "\n",
      "         [[-1.1908e-01]],\n",
      "\n",
      "         [[-1.1745e-01]],\n",
      "\n",
      "         [[ 7.1933e-02]],\n",
      "\n",
      "         [[ 9.6460e-03]],\n",
      "\n",
      "         [[-6.5771e-02]],\n",
      "\n",
      "         [[-3.8657e-02]],\n",
      "\n",
      "         [[-1.1955e-01]],\n",
      "\n",
      "         [[-1.6611e-01]],\n",
      "\n",
      "         [[ 1.8619e-02]],\n",
      "\n",
      "         [[ 1.4055e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6022e-02]],\n",
      "\n",
      "         [[ 2.0280e-01]],\n",
      "\n",
      "         [[-2.6363e-01]],\n",
      "\n",
      "         [[-5.8481e-02]],\n",
      "\n",
      "         [[ 1.0353e-01]],\n",
      "\n",
      "         [[-3.1893e-03]],\n",
      "\n",
      "         [[ 1.2177e-01]],\n",
      "\n",
      "         [[-1.8693e-01]],\n",
      "\n",
      "         [[ 1.6664e-01]],\n",
      "\n",
      "         [[-1.1375e-01]],\n",
      "\n",
      "         [[-3.3505e-02]],\n",
      "\n",
      "         [[ 1.5815e-01]],\n",
      "\n",
      "         [[ 4.8187e-03]],\n",
      "\n",
      "         [[ 1.7075e-01]],\n",
      "\n",
      "         [[ 1.2703e-03]],\n",
      "\n",
      "         [[ 1.3903e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4482e-01]],\n",
      "\n",
      "         [[-1.3319e-01]],\n",
      "\n",
      "         [[-2.8033e-02]],\n",
      "\n",
      "         [[ 6.6119e-02]],\n",
      "\n",
      "         [[-8.9205e-02]],\n",
      "\n",
      "         [[ 9.2747e-02]],\n",
      "\n",
      "         [[-1.2080e-01]],\n",
      "\n",
      "         [[-1.5906e-02]],\n",
      "\n",
      "         [[-1.7598e-01]],\n",
      "\n",
      "         [[ 1.0415e-01]],\n",
      "\n",
      "         [[-4.6602e-02]],\n",
      "\n",
      "         [[ 6.3278e-03]],\n",
      "\n",
      "         [[-5.6072e-04]],\n",
      "\n",
      "         [[ 1.0172e-01]],\n",
      "\n",
      "         [[ 2.3589e-01]],\n",
      "\n",
      "         [[ 2.2033e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2798e-02]],\n",
      "\n",
      "         [[-7.0880e-02]],\n",
      "\n",
      "         [[-1.5867e-02]],\n",
      "\n",
      "         [[ 2.8233e-02]],\n",
      "\n",
      "         [[ 6.4571e-03]],\n",
      "\n",
      "         [[ 2.3435e-01]],\n",
      "\n",
      "         [[-2.0616e-02]],\n",
      "\n",
      "         [[ 4.1551e-02]],\n",
      "\n",
      "         [[-8.6804e-02]],\n",
      "\n",
      "         [[ 8.2869e-02]],\n",
      "\n",
      "         [[-2.2799e-01]],\n",
      "\n",
      "         [[ 7.0729e-02]],\n",
      "\n",
      "         [[ 2.0447e-03]],\n",
      "\n",
      "         [[-2.0490e-03]],\n",
      "\n",
      "         [[ 8.0884e-02]],\n",
      "\n",
      "         [[ 7.2265e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.1010e-02]],\n",
      "\n",
      "         [[ 5.0092e-02]],\n",
      "\n",
      "         [[ 1.0385e-02]],\n",
      "\n",
      "         [[-1.1063e-01]],\n",
      "\n",
      "         [[-3.6740e-02]],\n",
      "\n",
      "         [[-1.8127e-01]],\n",
      "\n",
      "         [[-5.8038e-02]],\n",
      "\n",
      "         [[ 2.4006e-01]],\n",
      "\n",
      "         [[ 3.7351e-02]],\n",
      "\n",
      "         [[-1.2168e-02]],\n",
      "\n",
      "         [[ 7.6814e-02]],\n",
      "\n",
      "         [[-1.0756e-01]],\n",
      "\n",
      "         [[ 8.5526e-02]],\n",
      "\n",
      "         [[-1.0799e-01]],\n",
      "\n",
      "         [[ 1.1651e-01]],\n",
      "\n",
      "         [[ 4.0126e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0027e-02]],\n",
      "\n",
      "         [[ 4.6273e-02]],\n",
      "\n",
      "         [[-9.6572e-02]],\n",
      "\n",
      "         [[-7.4056e-02]],\n",
      "\n",
      "         [[ 6.6651e-02]],\n",
      "\n",
      "         [[-6.5924e-02]],\n",
      "\n",
      "         [[ 1.1325e-01]],\n",
      "\n",
      "         [[-4.3876e-02]],\n",
      "\n",
      "         [[ 1.5650e-01]],\n",
      "\n",
      "         [[ 1.1638e-01]],\n",
      "\n",
      "         [[-7.2188e-02]],\n",
      "\n",
      "         [[ 4.0689e-05]],\n",
      "\n",
      "         [[ 3.9908e-02]],\n",
      "\n",
      "         [[-2.6813e-01]],\n",
      "\n",
      "         [[-1.5149e-01]],\n",
      "\n",
      "         [[ 1.8961e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.7165e-02]],\n",
      "\n",
      "         [[-1.8377e-02]],\n",
      "\n",
      "         [[-9.4335e-02]],\n",
      "\n",
      "         [[-1.4942e-01]],\n",
      "\n",
      "         [[-2.9536e-01]],\n",
      "\n",
      "         [[ 1.1373e-01]],\n",
      "\n",
      "         [[-9.5389e-03]],\n",
      "\n",
      "         [[-1.2945e-01]],\n",
      "\n",
      "         [[ 5.9479e-02]],\n",
      "\n",
      "         [[-5.7252e-02]],\n",
      "\n",
      "         [[-2.9326e-02]],\n",
      "\n",
      "         [[ 2.1290e-01]],\n",
      "\n",
      "         [[ 1.3851e-01]],\n",
      "\n",
      "         [[-9.4173e-02]],\n",
      "\n",
      "         [[-1.3627e-01]],\n",
      "\n",
      "         [[ 1.7128e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3503e-01]],\n",
      "\n",
      "         [[-2.2606e-01]],\n",
      "\n",
      "         [[ 1.2189e-01]],\n",
      "\n",
      "         [[-8.2704e-02]],\n",
      "\n",
      "         [[-1.1926e-01]],\n",
      "\n",
      "         [[-1.4063e-02]],\n",
      "\n",
      "         [[-1.8616e-01]],\n",
      "\n",
      "         [[-4.3533e-02]],\n",
      "\n",
      "         [[-1.4811e-02]],\n",
      "\n",
      "         [[-2.1069e-02]],\n",
      "\n",
      "         [[ 2.5240e-02]],\n",
      "\n",
      "         [[ 3.2310e-01]],\n",
      "\n",
      "         [[ 1.3785e-01]],\n",
      "\n",
      "         [[ 8.2115e-02]],\n",
      "\n",
      "         [[-2.0717e-02]],\n",
      "\n",
      "         [[-1.1784e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.0308e-02]],\n",
      "\n",
      "         [[-2.2158e-01]],\n",
      "\n",
      "         [[ 1.1742e-01]],\n",
      "\n",
      "         [[ 3.9281e-02]],\n",
      "\n",
      "         [[ 2.2378e-01]],\n",
      "\n",
      "         [[-3.9601e-02]],\n",
      "\n",
      "         [[-7.2936e-02]],\n",
      "\n",
      "         [[ 1.1260e-01]],\n",
      "\n",
      "         [[-6.9883e-02]],\n",
      "\n",
      "         [[-3.5999e-02]],\n",
      "\n",
      "         [[-2.5196e-02]],\n",
      "\n",
      "         [[-1.4823e-01]],\n",
      "\n",
      "         [[ 9.9419e-02]],\n",
      "\n",
      "         [[-7.8129e-02]],\n",
      "\n",
      "         [[ 1.1671e-01]],\n",
      "\n",
      "         [[-1.0641e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7455e-02]],\n",
      "\n",
      "         [[-7.7792e-03]],\n",
      "\n",
      "         [[ 4.4664e-01]],\n",
      "\n",
      "         [[-4.6143e-02]],\n",
      "\n",
      "         [[-1.1592e-01]],\n",
      "\n",
      "         [[ 2.5620e-01]],\n",
      "\n",
      "         [[-1.7552e-01]],\n",
      "\n",
      "         [[-2.6894e-01]],\n",
      "\n",
      "         [[ 1.3544e-02]],\n",
      "\n",
      "         [[ 1.4139e-01]],\n",
      "\n",
      "         [[ 1.0047e-02]],\n",
      "\n",
      "         [[-2.9023e-01]],\n",
      "\n",
      "         [[-3.2568e-02]],\n",
      "\n",
      "         [[ 1.5324e-01]],\n",
      "\n",
      "         [[ 6.7441e-02]],\n",
      "\n",
      "         [[ 1.8957e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2036e-01]],\n",
      "\n",
      "         [[ 9.6127e-02]],\n",
      "\n",
      "         [[-1.6695e-01]],\n",
      "\n",
      "         [[-1.6645e-01]],\n",
      "\n",
      "         [[-7.2510e-02]],\n",
      "\n",
      "         [[-8.2019e-02]],\n",
      "\n",
      "         [[ 1.9620e-01]],\n",
      "\n",
      "         [[ 5.5864e-02]],\n",
      "\n",
      "         [[ 1.7018e-01]],\n",
      "\n",
      "         [[ 2.1694e-02]],\n",
      "\n",
      "         [[ 3.1373e-02]],\n",
      "\n",
      "         [[-2.5834e-01]],\n",
      "\n",
      "         [[ 1.8959e-02]],\n",
      "\n",
      "         [[-3.0602e-01]],\n",
      "\n",
      "         [[-1.6638e-01]],\n",
      "\n",
      "         [[ 6.2409e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3768e-01]],\n",
      "\n",
      "         [[ 1.8926e-01]],\n",
      "\n",
      "         [[-2.8861e-01]],\n",
      "\n",
      "         [[ 2.2058e-01]],\n",
      "\n",
      "         [[ 2.5238e-01]],\n",
      "\n",
      "         [[-1.6015e-01]],\n",
      "\n",
      "         [[ 1.9369e-01]],\n",
      "\n",
      "         [[-6.1200e-02]],\n",
      "\n",
      "         [[-4.7424e-02]],\n",
      "\n",
      "         [[ 1.4646e-01]],\n",
      "\n",
      "         [[-6.2295e-02]],\n",
      "\n",
      "         [[-5.6663e-02]],\n",
      "\n",
      "         [[-2.2724e-01]],\n",
      "\n",
      "         [[-1.0274e-02]],\n",
      "\n",
      "         [[ 2.6969e-01]],\n",
      "\n",
      "         [[ 9.4494e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.4684e-02]],\n",
      "\n",
      "         [[-9.5924e-02]],\n",
      "\n",
      "         [[-4.2297e-02]],\n",
      "\n",
      "         [[ 7.9243e-02]],\n",
      "\n",
      "         [[ 2.2149e-01]],\n",
      "\n",
      "         [[-1.1068e-01]],\n",
      "\n",
      "         [[-1.1288e-01]],\n",
      "\n",
      "         [[ 1.8350e-01]],\n",
      "\n",
      "         [[-1.2523e-01]],\n",
      "\n",
      "         [[ 8.6618e-02]],\n",
      "\n",
      "         [[ 3.9983e-02]],\n",
      "\n",
      "         [[ 7.4375e-02]],\n",
      "\n",
      "         [[-1.4899e-01]],\n",
      "\n",
      "         [[ 2.3471e-02]],\n",
      "\n",
      "         [[ 1.2360e-01]],\n",
      "\n",
      "         [[-6.2089e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1461e-02]],\n",
      "\n",
      "         [[ 7.5301e-02]],\n",
      "\n",
      "         [[ 6.0491e-03]],\n",
      "\n",
      "         [[ 3.3260e-02]],\n",
      "\n",
      "         [[-7.3180e-02]],\n",
      "\n",
      "         [[ 1.6241e-02]],\n",
      "\n",
      "         [[ 1.9081e-01]],\n",
      "\n",
      "         [[ 2.1984e-01]],\n",
      "\n",
      "         [[-1.5982e-03]],\n",
      "\n",
      "         [[-3.3865e-02]],\n",
      "\n",
      "         [[-7.1456e-02]],\n",
      "\n",
      "         [[-2.4148e-02]],\n",
      "\n",
      "         [[ 6.3366e-02]],\n",
      "\n",
      "         [[ 6.0493e-02]],\n",
      "\n",
      "         [[ 1.4665e-01]],\n",
      "\n",
      "         [[ 5.8318e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4565e-02]],\n",
      "\n",
      "         [[-7.5889e-02]],\n",
      "\n",
      "         [[ 8.7668e-02]],\n",
      "\n",
      "         [[ 2.5698e-01]],\n",
      "\n",
      "         [[-1.1225e-01]],\n",
      "\n",
      "         [[ 1.5339e-01]],\n",
      "\n",
      "         [[ 8.8284e-02]],\n",
      "\n",
      "         [[-2.3318e-01]],\n",
      "\n",
      "         [[ 1.2400e-02]],\n",
      "\n",
      "         [[-8.3324e-02]],\n",
      "\n",
      "         [[ 1.5475e-01]],\n",
      "\n",
      "         [[ 5.4264e-03]],\n",
      "\n",
      "         [[ 8.2539e-02]],\n",
      "\n",
      "         [[ 3.0197e-02]],\n",
      "\n",
      "         [[ 4.9250e-02]],\n",
      "\n",
      "         [[ 5.6499e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7761e-03]],\n",
      "\n",
      "         [[-3.7815e-02]],\n",
      "\n",
      "         [[ 2.9388e-01]],\n",
      "\n",
      "         [[-2.6035e-01]],\n",
      "\n",
      "         [[ 4.4122e-02]],\n",
      "\n",
      "         [[-2.7481e-01]],\n",
      "\n",
      "         [[ 3.1173e-02]],\n",
      "\n",
      "         [[-2.5346e-01]],\n",
      "\n",
      "         [[-5.0343e-02]],\n",
      "\n",
      "         [[-5.6225e-02]],\n",
      "\n",
      "         [[ 7.3225e-02]],\n",
      "\n",
      "         [[ 6.0442e-02]],\n",
      "\n",
      "         [[-7.6970e-02]],\n",
      "\n",
      "         [[-3.4273e-01]],\n",
      "\n",
      "         [[ 2.2108e-01]],\n",
      "\n",
      "         [[-3.6697e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8130e-02]],\n",
      "\n",
      "         [[ 9.2513e-02]],\n",
      "\n",
      "         [[-1.0955e-01]],\n",
      "\n",
      "         [[-1.2163e-01]],\n",
      "\n",
      "         [[ 2.6819e-02]],\n",
      "\n",
      "         [[-2.0549e-01]],\n",
      "\n",
      "         [[ 1.0457e-01]],\n",
      "\n",
      "         [[-7.7873e-02]],\n",
      "\n",
      "         [[ 6.4988e-02]],\n",
      "\n",
      "         [[ 1.9338e-02]],\n",
      "\n",
      "         [[-1.8120e-02]],\n",
      "\n",
      "         [[-1.6811e-01]],\n",
      "\n",
      "         [[ 6.1631e-02]],\n",
      "\n",
      "         [[-1.1520e-01]],\n",
      "\n",
      "         [[-1.9715e-01]],\n",
      "\n",
      "         [[-3.1797e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2528e-02]],\n",
      "\n",
      "         [[-1.1264e-01]],\n",
      "\n",
      "         [[ 4.8920e-02]],\n",
      "\n",
      "         [[-1.2414e-01]],\n",
      "\n",
      "         [[-4.4199e-02]],\n",
      "\n",
      "         [[ 1.6352e-01]],\n",
      "\n",
      "         [[ 2.5615e-02]],\n",
      "\n",
      "         [[ 8.3423e-02]],\n",
      "\n",
      "         [[-2.5118e-02]],\n",
      "\n",
      "         [[-7.6239e-02]],\n",
      "\n",
      "         [[ 1.8708e-01]],\n",
      "\n",
      "         [[ 1.7559e-02]],\n",
      "\n",
      "         [[-8.3416e-03]],\n",
      "\n",
      "         [[ 5.0489e-03]],\n",
      "\n",
      "         [[-1.2795e-01]],\n",
      "\n",
      "         [[ 7.1054e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3413e-02]],\n",
      "\n",
      "         [[-1.3079e-01]],\n",
      "\n",
      "         [[ 1.1605e-02]],\n",
      "\n",
      "         [[-1.9773e-01]],\n",
      "\n",
      "         [[-1.7063e-01]],\n",
      "\n",
      "         [[ 6.2608e-02]],\n",
      "\n",
      "         [[ 2.8022e-01]],\n",
      "\n",
      "         [[-2.0647e-02]],\n",
      "\n",
      "         [[ 1.4778e-03]],\n",
      "\n",
      "         [[ 1.0665e-01]],\n",
      "\n",
      "         [[-1.6404e-01]],\n",
      "\n",
      "         [[ 1.3258e-01]],\n",
      "\n",
      "         [[ 6.1054e-02]],\n",
      "\n",
      "         [[-6.4358e-02]],\n",
      "\n",
      "         [[ 1.1350e-01]],\n",
      "\n",
      "         [[-6.5459e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0450e-02]],\n",
      "\n",
      "         [[-4.7768e-02]],\n",
      "\n",
      "         [[-1.2665e-01]],\n",
      "\n",
      "         [[-9.8859e-03]],\n",
      "\n",
      "         [[ 1.5785e-02]],\n",
      "\n",
      "         [[ 4.3104e-02]],\n",
      "\n",
      "         [[-9.4807e-02]],\n",
      "\n",
      "         [[ 1.2060e-01]],\n",
      "\n",
      "         [[-4.5216e-02]],\n",
      "\n",
      "         [[-1.1820e-01]],\n",
      "\n",
      "         [[ 5.7795e-04]],\n",
      "\n",
      "         [[ 2.3353e-02]],\n",
      "\n",
      "         [[-2.6103e-02]],\n",
      "\n",
      "         [[-2.6680e-02]],\n",
      "\n",
      "         [[-9.5199e-02]],\n",
      "\n",
      "         [[-2.0057e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1979e-01]],\n",
      "\n",
      "         [[ 2.0544e-01]],\n",
      "\n",
      "         [[ 9.7045e-02]],\n",
      "\n",
      "         [[-2.4501e-01]],\n",
      "\n",
      "         [[ 1.1373e-02]],\n",
      "\n",
      "         [[ 2.0960e-01]],\n",
      "\n",
      "         [[ 4.8036e-02]],\n",
      "\n",
      "         [[ 5.6290e-02]],\n",
      "\n",
      "         [[-2.9698e-02]],\n",
      "\n",
      "         [[-7.0933e-03]],\n",
      "\n",
      "         [[ 2.2300e-02]],\n",
      "\n",
      "         [[-2.0514e-02]],\n",
      "\n",
      "         [[ 2.0150e-02]],\n",
      "\n",
      "         [[-4.0578e-02]],\n",
      "\n",
      "         [[-1.2920e-01]],\n",
      "\n",
      "         [[ 1.5277e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2984e-01]],\n",
      "\n",
      "         [[ 3.7727e-02]],\n",
      "\n",
      "         [[-1.2673e-01]],\n",
      "\n",
      "         [[ 2.3259e-01]],\n",
      "\n",
      "         [[ 1.7826e-02]],\n",
      "\n",
      "         [[ 9.7369e-03]],\n",
      "\n",
      "         [[ 1.6635e-02]],\n",
      "\n",
      "         [[-7.9844e-02]],\n",
      "\n",
      "         [[ 1.3321e-01]],\n",
      "\n",
      "         [[ 8.0858e-02]],\n",
      "\n",
      "         [[ 2.1114e-01]],\n",
      "\n",
      "         [[-2.1050e-01]],\n",
      "\n",
      "         [[-1.3876e-01]],\n",
      "\n",
      "         [[ 1.3596e-01]],\n",
      "\n",
      "         [[ 2.5929e-02]],\n",
      "\n",
      "         [[ 2.8465e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1563e-01]],\n",
      "\n",
      "         [[ 1.3101e-03]],\n",
      "\n",
      "         [[ 8.2630e-03]],\n",
      "\n",
      "         [[-8.1488e-02]],\n",
      "\n",
      "         [[-1.6587e-01]],\n",
      "\n",
      "         [[-1.4308e-01]],\n",
      "\n",
      "         [[-7.8032e-02]],\n",
      "\n",
      "         [[ 1.1953e-01]],\n",
      "\n",
      "         [[ 1.3073e-01]],\n",
      "\n",
      "         [[ 5.2202e-02]],\n",
      "\n",
      "         [[-1.3481e-01]],\n",
      "\n",
      "         [[ 9.8240e-03]],\n",
      "\n",
      "         [[ 6.3366e-02]],\n",
      "\n",
      "         [[ 1.6472e-01]],\n",
      "\n",
      "         [[-3.3061e-03]],\n",
      "\n",
      "         [[-1.4652e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8350e-02]],\n",
      "\n",
      "         [[ 1.1295e-01]],\n",
      "\n",
      "         [[ 4.5073e-01]],\n",
      "\n",
      "         [[ 6.1388e-02]],\n",
      "\n",
      "         [[-4.7034e-02]],\n",
      "\n",
      "         [[-1.1756e-01]],\n",
      "\n",
      "         [[ 2.2370e-02]],\n",
      "\n",
      "         [[ 1.4461e-01]],\n",
      "\n",
      "         [[ 6.8461e-02]],\n",
      "\n",
      "         [[ 6.9269e-02]],\n",
      "\n",
      "         [[-7.4964e-02]],\n",
      "\n",
      "         [[-1.2929e-01]],\n",
      "\n",
      "         [[-1.1241e-01]],\n",
      "\n",
      "         [[-1.8475e-01]],\n",
      "\n",
      "         [[-1.9879e-01]],\n",
      "\n",
      "         [[ 2.6850e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0334e-01]],\n",
      "\n",
      "         [[ 8.2399e-02]],\n",
      "\n",
      "         [[ 2.6900e-02]],\n",
      "\n",
      "         [[-1.9797e-02]],\n",
      "\n",
      "         [[-1.4214e-01]],\n",
      "\n",
      "         [[-1.1488e-01]],\n",
      "\n",
      "         [[-5.7188e-03]],\n",
      "\n",
      "         [[-5.8774e-02]],\n",
      "\n",
      "         [[-4.8905e-02]],\n",
      "\n",
      "         [[-3.7795e-02]],\n",
      "\n",
      "         [[-5.7296e-02]],\n",
      "\n",
      "         [[ 1.5713e-02]],\n",
      "\n",
      "         [[-5.5862e-02]],\n",
      "\n",
      "         [[ 2.8235e-01]],\n",
      "\n",
      "         [[ 8.5692e-02]],\n",
      "\n",
      "         [[-7.1917e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2423e-03]],\n",
      "\n",
      "         [[-3.3228e-01]],\n",
      "\n",
      "         [[-8.6617e-02]],\n",
      "\n",
      "         [[ 1.7286e-01]],\n",
      "\n",
      "         [[ 4.8265e-02]],\n",
      "\n",
      "         [[-3.3894e-02]],\n",
      "\n",
      "         [[-1.6814e-01]],\n",
      "\n",
      "         [[-6.4280e-02]],\n",
      "\n",
      "         [[-6.9286e-02]],\n",
      "\n",
      "         [[ 1.9490e-02]],\n",
      "\n",
      "         [[-7.0808e-02]],\n",
      "\n",
      "         [[ 1.6253e-01]],\n",
      "\n",
      "         [[-5.4138e-02]],\n",
      "\n",
      "         [[ 5.3638e-02]],\n",
      "\n",
      "         [[ 5.4619e-02]],\n",
      "\n",
      "         [[-1.0041e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3709e-02]],\n",
      "\n",
      "         [[ 1.7577e-01]],\n",
      "\n",
      "         [[ 2.4422e-01]],\n",
      "\n",
      "         [[ 1.4752e-01]],\n",
      "\n",
      "         [[-8.8671e-02]],\n",
      "\n",
      "         [[ 1.2509e-02]],\n",
      "\n",
      "         [[-9.1714e-02]],\n",
      "\n",
      "         [[-1.1298e-01]],\n",
      "\n",
      "         [[-5.4654e-02]],\n",
      "\n",
      "         [[-2.7529e-01]],\n",
      "\n",
      "         [[ 2.0713e-01]],\n",
      "\n",
      "         [[ 4.4467e-02]],\n",
      "\n",
      "         [[ 6.6768e-02]],\n",
      "\n",
      "         [[ 2.9426e-01]],\n",
      "\n",
      "         [[ 1.4516e-01]],\n",
      "\n",
      "         [[-1.9459e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0012e-02]],\n",
      "\n",
      "         [[ 7.3471e-02]],\n",
      "\n",
      "         [[-1.0319e-01]],\n",
      "\n",
      "         [[ 5.2752e-02]],\n",
      "\n",
      "         [[-1.7064e-01]],\n",
      "\n",
      "         [[-1.1414e-01]],\n",
      "\n",
      "         [[-4.0060e-02]],\n",
      "\n",
      "         [[-2.0758e-01]],\n",
      "\n",
      "         [[-9.9260e-02]],\n",
      "\n",
      "         [[-1.2730e-01]],\n",
      "\n",
      "         [[ 1.3630e-01]],\n",
      "\n",
      "         [[-5.7226e-02]],\n",
      "\n",
      "         [[ 8.7880e-02]],\n",
      "\n",
      "         [[-2.2736e-01]],\n",
      "\n",
      "         [[ 3.0217e-02]],\n",
      "\n",
      "         [[-1.5788e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8475e-01]],\n",
      "\n",
      "         [[-2.0700e-01]],\n",
      "\n",
      "         [[ 4.6434e-02]],\n",
      "\n",
      "         [[ 9.9434e-02]],\n",
      "\n",
      "         [[ 2.5583e-03]],\n",
      "\n",
      "         [[-1.2688e-01]],\n",
      "\n",
      "         [[-8.5494e-02]],\n",
      "\n",
      "         [[-1.5752e-01]],\n",
      "\n",
      "         [[-7.4568e-02]],\n",
      "\n",
      "         [[ 3.5107e-02]],\n",
      "\n",
      "         [[ 3.0364e-02]],\n",
      "\n",
      "         [[ 2.0188e-01]],\n",
      "\n",
      "         [[-1.3545e-01]],\n",
      "\n",
      "         [[ 3.0083e-01]],\n",
      "\n",
      "         [[ 7.4238e-02]],\n",
      "\n",
      "         [[ 6.7172e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1199e-02]],\n",
      "\n",
      "         [[-5.2635e-02]],\n",
      "\n",
      "         [[ 3.4118e-02]],\n",
      "\n",
      "         [[-1.3405e-01]],\n",
      "\n",
      "         [[-2.6356e-01]],\n",
      "\n",
      "         [[-4.6739e-02]],\n",
      "\n",
      "         [[ 2.6137e-02]],\n",
      "\n",
      "         [[-1.4308e-01]],\n",
      "\n",
      "         [[ 7.1126e-03]],\n",
      "\n",
      "         [[-1.1087e-01]],\n",
      "\n",
      "         [[ 2.3804e-02]],\n",
      "\n",
      "         [[ 5.1796e-02]],\n",
      "\n",
      "         [[ 5.7931e-02]],\n",
      "\n",
      "         [[ 4.2005e-02]],\n",
      "\n",
      "         [[-1.5689e-01]],\n",
      "\n",
      "         [[ 1.2435e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.6948e-02]],\n",
      "\n",
      "         [[ 5.6609e-02]],\n",
      "\n",
      "         [[ 3.6213e-02]],\n",
      "\n",
      "         [[-1.2385e-01]],\n",
      "\n",
      "         [[ 7.3559e-02]],\n",
      "\n",
      "         [[ 2.5452e-01]],\n",
      "\n",
      "         [[ 9.5524e-02]],\n",
      "\n",
      "         [[ 2.6521e-02]],\n",
      "\n",
      "         [[ 1.6766e-01]],\n",
      "\n",
      "         [[ 1.4603e-01]],\n",
      "\n",
      "         [[-2.4861e-01]],\n",
      "\n",
      "         [[-5.0561e-02]],\n",
      "\n",
      "         [[ 5.4207e-02]],\n",
      "\n",
      "         [[-9.9942e-02]],\n",
      "\n",
      "         [[-1.1354e-01]],\n",
      "\n",
      "         [[ 1.9233e-02]]]], device='cuda:0')), ('layer2.0.shortcut.1.weight', tensor([0.2395, 0.2055, 0.2675, 0.1801, 0.2007, 0.1283, 0.1860, 0.2272, 0.3557,\n",
      "        0.2104, 0.3570, 0.3897, 0.3195, 0.1604, 0.1258, 0.2118, 0.2894, 0.2086,\n",
      "        0.1221, 0.2836, 0.0516, 0.1530, 0.2964, 0.1901, 0.2825, 0.2050, 0.2296,\n",
      "        0.2928, 0.2552, 0.3913, 0.2402, 0.2469], device='cuda:0')), ('layer2.0.shortcut.1.bias', tensor([-0.0911,  0.0426,  0.0700,  0.1048,  0.0093, -0.0706, -0.0680,  0.0853,\n",
      "        -0.0371,  0.1359,  0.0737,  0.1410,  0.0868,  0.0867, -0.1225, -0.0392,\n",
      "         0.1110,  0.1007,  0.1309, -0.0846,  0.0275,  0.0910,  0.0239,  0.0275,\n",
      "         0.0223, -0.0078, -0.0169,  0.0478, -0.0067,  0.0138, -0.0105, -0.0117],\n",
      "       device='cuda:0')), ('layer2.0.shortcut.1.running_mean', tensor([ 0.1788, -0.0278,  0.4460, -0.1196,  0.0360, -0.0899, -0.1515, -0.3029,\n",
      "        -0.2424, -0.2308,  0.1559, -0.1688,  0.2602, -0.0936,  0.4032,  0.3551,\n",
      "        -0.4034, -0.3067,  0.0094,  0.0306, -0.2302,  0.1164,  0.5272, -0.1828,\n",
      "        -0.0071, -0.0361, -0.3351,  0.3917, -0.4568, -0.0685, -0.2359,  0.1058],\n",
      "       device='cuda:0')), ('layer2.0.shortcut.1.running_var', tensor([0.0612, 0.0389, 0.1006, 0.0705, 0.0374, 0.0536, 0.0595, 0.0798, 0.0998,\n",
      "        0.0804, 0.1093, 0.2022, 0.1681, 0.0823, 0.0288, 0.0436, 0.1062, 0.0657,\n",
      "        0.0435, 0.0671, 0.0242, 0.0532, 0.0976, 0.0568, 0.0624, 0.0647, 0.0820,\n",
      "        0.1099, 0.0585, 0.1495, 0.0693, 0.0578], device='cuda:0')), ('layer2.0.shortcut.1.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer2.1.conv1.weight', tensor([[[[ 3.9155e-02,  2.5763e-02,  4.2741e-02],\n",
      "          [ 1.2614e-02,  5.2235e-02,  5.3712e-02],\n",
      "          [-1.5366e-02,  3.0269e-02,  1.2302e-01]],\n",
      "\n",
      "         [[-4.2655e-02,  3.5344e-02,  7.5049e-02],\n",
      "          [ 1.0415e-01,  8.7992e-02,  1.0347e-02],\n",
      "          [ 2.2949e-02, -4.8074e-02, -4.3405e-02]],\n",
      "\n",
      "         [[ 1.1538e-03,  5.6239e-02, -3.0650e-02],\n",
      "          [-1.6308e-02,  5.5022e-02,  6.6929e-02],\n",
      "          [-4.1529e-02, -1.0098e-02,  4.3391e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3257e-02,  9.5098e-02,  4.0774e-02],\n",
      "          [ 1.1477e-02, -4.8578e-02, -1.2121e-02],\n",
      "          [-6.4238e-02, -1.0165e-01, -8.9996e-02]],\n",
      "\n",
      "         [[-9.1175e-02, -1.1156e-01, -9.2362e-02],\n",
      "          [-7.0218e-02, -2.5590e-02, -2.8623e-02],\n",
      "          [-5.9308e-02, -2.1498e-02, -3.8881e-02]],\n",
      "\n",
      "         [[ 1.3331e-01,  1.2100e-01, -2.8590e-03],\n",
      "          [ 1.4710e-01,  1.6842e-01,  1.1812e-02],\n",
      "          [-9.3996e-03, -1.6903e-03, -5.3520e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6730e-02,  5.7746e-02, -2.6346e-03],\n",
      "          [-1.8256e-05, -4.3031e-02, -8.0572e-02],\n",
      "          [-1.9787e-03, -3.5993e-02, -6.8921e-02]],\n",
      "\n",
      "         [[-6.6633e-02, -6.0469e-02, -1.0761e-02],\n",
      "          [-1.0388e-02, -3.3021e-02,  5.6070e-02],\n",
      "          [ 1.8088e-02,  3.7994e-02,  9.4020e-02]],\n",
      "\n",
      "         [[ 4.8439e-02,  2.4160e-03, -3.8628e-02],\n",
      "          [ 4.9317e-02,  7.5850e-02, -8.9032e-04],\n",
      "          [ 9.3168e-03,  4.3039e-02, -3.9440e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2113e-02,  7.1462e-02, -1.6373e-02],\n",
      "          [-1.5725e-01,  2.8475e-02, -1.8924e-03],\n",
      "          [-8.7915e-02,  9.2520e-02,  3.3591e-02]],\n",
      "\n",
      "         [[ 7.6282e-04,  2.5530e-02,  5.7721e-02],\n",
      "          [ 2.7559e-02, -2.5735e-02,  5.2826e-02],\n",
      "          [-1.1968e-02, -9.8977e-02, -6.9449e-02]],\n",
      "\n",
      "         [[-4.4757e-02,  1.1650e-02,  1.7845e-01],\n",
      "          [-1.0048e-01, -9.9676e-02,  5.6769e-02],\n",
      "          [-3.1734e-02, -9.1275e-02, -1.2988e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1925e-01, -3.6991e-02, -3.8745e-02],\n",
      "          [ 3.9824e-02, -7.1774e-02,  7.9859e-02],\n",
      "          [-1.4155e-02,  9.0433e-03,  1.9848e-01]],\n",
      "\n",
      "         [[ 1.8247e-02,  7.2070e-02, -2.6640e-02],\n",
      "          [-4.9400e-02,  1.7649e-02,  2.2807e-02],\n",
      "          [-4.9034e-02, -4.0852e-02,  8.2875e-02]],\n",
      "\n",
      "         [[-1.3533e-01,  3.4559e-02, -9.2053e-02],\n",
      "          [-5.1969e-02,  1.1137e-01,  9.3114e-02],\n",
      "          [ 6.2525e-02,  7.3510e-02,  1.3562e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0473e-02,  2.2332e-02, -4.9410e-02],\n",
      "          [ 1.4066e-02, -5.2712e-02, -4.3930e-02],\n",
      "          [ 6.7250e-03, -6.3311e-02, -1.6666e-01]],\n",
      "\n",
      "         [[-5.9883e-02,  7.5652e-03,  1.6678e-02],\n",
      "          [-8.6914e-02, -4.4280e-02,  6.6642e-02],\n",
      "          [ 6.6362e-02, -1.2826e-01,  9.6245e-03]],\n",
      "\n",
      "         [[ 3.5916e-03,  6.6498e-02,  1.0173e-01],\n",
      "          [-1.1729e-01, -5.9760e-02,  1.4811e-01],\n",
      "          [-2.1002e-01, -1.7346e-01,  1.2255e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.5670e-02, -1.4851e-02, -5.8099e-02],\n",
      "          [-1.8850e-02,  5.1793e-02, -1.3941e-01],\n",
      "          [-5.3455e-02,  8.1373e-02, -1.0447e-01]],\n",
      "\n",
      "         [[-1.7142e-01, -3.0179e-02, -7.1211e-02],\n",
      "          [-5.3597e-02,  1.1845e-01,  7.9317e-03],\n",
      "          [-3.0995e-02,  7.4389e-02, -5.8772e-02]],\n",
      "\n",
      "         [[ 5.4908e-03, -1.0250e-01, -1.8485e-02],\n",
      "          [ 7.2019e-02, -2.9979e-02,  5.7726e-02],\n",
      "          [-6.8500e-02, -7.8217e-02,  1.1911e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.9286e-02,  1.0774e-01, -7.7430e-02],\n",
      "          [ 3.1478e-02,  1.5880e-01, -6.7545e-02],\n",
      "          [ 6.6626e-02,  8.9622e-02, -8.9315e-02]],\n",
      "\n",
      "         [[ 4.0536e-02, -7.7218e-02,  8.5537e-02],\n",
      "          [-1.5532e-02, -1.6043e-01,  7.7509e-02],\n",
      "          [-2.7387e-02, -9.0450e-02,  6.0386e-02]],\n",
      "\n",
      "         [[ 4.3898e-02, -1.2903e-01, -6.9877e-02],\n",
      "          [ 1.3955e-01, -6.3785e-02,  3.5027e-02],\n",
      "          [ 9.3833e-02, -7.7519e-02, -7.1093e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.3805e-02,  2.4310e-03,  4.7372e-02],\n",
      "          [-8.2500e-02, -9.8700e-02, -1.1507e-01],\n",
      "          [-3.3394e-02, -6.5592e-02, -1.0499e-01]],\n",
      "\n",
      "         [[ 1.1810e-02, -4.9565e-02, -1.9205e-02],\n",
      "          [-1.9976e-02, -5.0670e-02, -1.2696e-03],\n",
      "          [-1.0319e-03, -2.1498e-02,  1.6373e-02]],\n",
      "\n",
      "         [[-4.1004e-02,  7.3731e-03,  8.9461e-03],\n",
      "          [-7.2368e-06,  5.8691e-02, -5.4586e-02],\n",
      "          [-8.7309e-02, -1.7391e-02, -4.8560e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9167e-02, -4.5970e-02, -4.3369e-03],\n",
      "          [ 1.1447e-02,  1.2607e-01,  1.0170e-01],\n",
      "          [-1.2743e-01,  5.2905e-02,  2.0303e-01]],\n",
      "\n",
      "         [[ 1.7394e-02,  1.0938e-01,  7.5606e-03],\n",
      "          [ 2.5610e-02,  4.5759e-02, -3.8455e-02],\n",
      "          [-1.7046e-02, -6.3387e-02, -1.0386e-01]],\n",
      "\n",
      "         [[ 2.6540e-02,  2.0993e-02,  7.1008e-03],\n",
      "          [-5.2257e-02,  8.3582e-04,  4.9120e-03],\n",
      "          [-1.3054e-01, -2.3855e-02, -2.2797e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.3027e-02, -2.5568e-02, -5.1236e-02],\n",
      "          [ 5.4887e-03,  1.7994e-02,  3.7894e-02],\n",
      "          [ 1.6853e-02, -1.8729e-02,  1.4149e-02]],\n",
      "\n",
      "         [[ 7.1744e-02, -2.2170e-03, -3.2016e-02],\n",
      "          [-7.5344e-03, -5.5040e-02, -1.7354e-02],\n",
      "          [-8.9532e-02, -8.1180e-02, -7.6343e-02]],\n",
      "\n",
      "         [[-4.1348e-02, -1.0177e-01, -5.1865e-02],\n",
      "          [-6.3561e-02, -9.0337e-02, -6.2881e-02],\n",
      "          [-1.3322e-02,  2.0902e-02,  4.4841e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1038e-02, -6.5063e-02, -1.2628e-01],\n",
      "          [ 1.3006e-01, -1.1193e-02, -7.0413e-02],\n",
      "          [ 1.7698e-01, -6.6453e-02, -3.9058e-02]],\n",
      "\n",
      "         [[ 7.0705e-03, -8.7226e-03,  1.5761e-02],\n",
      "          [ 2.3459e-03,  6.3158e-02,  1.1688e-01],\n",
      "          [ 3.9382e-03,  1.1091e-01,  1.4385e-01]],\n",
      "\n",
      "         [[-7.8672e-02, -6.3514e-02,  5.7183e-02],\n",
      "          [-1.1508e-01, -3.4692e-02,  1.8457e-01],\n",
      "          [-9.9357e-02,  2.4903e-02,  1.7332e-01]]]], device='cuda:0')), ('layer2.1.bn1.weight', tensor([0.3798, 0.3613, 0.4587, 0.5944, 0.3629, 0.4252, 0.4486, 0.3962, 0.4178,\n",
      "        0.3747, 0.3643, 0.4798, 0.3947, 0.3428, 0.4462, 0.4846, 0.3427, 0.3518,\n",
      "        0.4937, 0.4586, 0.4904, 0.4693, 0.4533, 0.4066, 0.4541, 0.4624, 0.4373,\n",
      "        0.3597, 0.3838, 0.4560, 0.3217, 0.3557], device='cuda:0')), ('layer2.1.bn1.bias', tensor([-0.1808, -0.2102, -0.2460, -0.3299, -0.1971, -0.2781, -0.3005, -0.1990,\n",
      "        -0.2822, -0.2220, -0.1173, -0.1470, -0.1040, -0.1236, -0.2080, -0.3761,\n",
      "        -0.1176, -0.1830, -0.3558, -0.1185, -0.2739, -0.2861, -0.1298, -0.2641,\n",
      "        -0.2104, -0.4061, -0.2844, -0.1993, -0.2195, -0.1962, -0.2529, -0.0959],\n",
      "       device='cuda:0')), ('layer2.1.bn1.running_mean', tensor([-0.6364, -0.3500,  0.0938, -0.7022, -0.2882, -1.1083, -0.9750, -0.6784,\n",
      "        -0.2961, -0.0823, -0.4782,  0.0906, -0.5734, -0.3277,  0.2003, -0.8465,\n",
      "        -0.6578, -1.0793, -0.6014, -0.8936, -0.5428, -0.5002, -0.8454, -0.6618,\n",
      "        -0.6677, -0.3863, -0.3706, -1.6189,  0.1521, -0.3065,  0.0675, -0.6835],\n",
      "       device='cuda:0')), ('layer2.1.bn1.running_var', tensor([0.7053, 0.4842, 0.4551, 0.7422, 0.3685, 0.3987, 0.5237, 0.4920, 0.3904,\n",
      "        0.4774, 0.4058, 0.9869, 0.5718, 0.3692, 0.6667, 0.3881, 0.4431, 0.3178,\n",
      "        0.5005, 0.5077, 0.4056, 0.7784, 0.7082, 0.3740, 0.4515, 0.4008, 0.5455,\n",
      "        0.4849, 0.4931, 0.7129, 0.7089, 0.2959], device='cuda:0')), ('layer2.1.bn1.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer2.1.conv2.weight', tensor([[[[ 9.4787e-02,  3.6836e-02, -7.4617e-02],\n",
      "          [ 1.1243e-01,  2.7189e-02, -7.2176e-02],\n",
      "          [ 6.7699e-02,  9.7082e-03, -2.3423e-02]],\n",
      "\n",
      "         [[ 2.0024e-02, -5.4804e-02, -5.2462e-02],\n",
      "          [-5.5377e-02, -4.9914e-02, -5.8175e-02],\n",
      "          [-6.4402e-02, -6.8339e-02, -4.4640e-02]],\n",
      "\n",
      "         [[-1.4423e-01, -1.4708e-01, -2.0569e-02],\n",
      "          [-1.3614e-01, -1.2750e-01, -9.5942e-02],\n",
      "          [-9.5822e-02, -4.8554e-02, -1.3114e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.9607e-02,  1.0830e-02,  3.6309e-02],\n",
      "          [ 5.9249e-02, -7.9657e-02, -8.8560e-02],\n",
      "          [ 3.2044e-02, -4.2028e-02, -5.1831e-02]],\n",
      "\n",
      "         [[-1.0644e-01, -9.6598e-02, -1.7406e-02],\n",
      "          [-8.4293e-02, -5.7767e-02, -5.0375e-02],\n",
      "          [-8.4835e-02,  2.5565e-02,  7.2255e-02]],\n",
      "\n",
      "         [[ 1.0863e-02,  5.1863e-02,  1.3693e-01],\n",
      "          [-5.6954e-02, -9.8355e-04,  6.6295e-02],\n",
      "          [-8.4356e-03, -2.2281e-02, -3.1133e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6334e-02, -4.2243e-02, -1.1447e-01],\n",
      "          [ 5.5974e-02, -1.9695e-02, -1.4320e-01],\n",
      "          [ 4.2691e-02,  2.4294e-02, -1.0081e-01]],\n",
      "\n",
      "         [[-7.0788e-02, -1.0085e-01, -1.4012e-01],\n",
      "          [-7.5385e-02, -4.4843e-02, -8.6308e-02],\n",
      "          [-6.3016e-02, -2.2777e-02, -6.0490e-02]],\n",
      "\n",
      "         [[-3.1817e-02, -3.6266e-02, -1.0020e-01],\n",
      "          [ 4.4648e-03,  4.4775e-02, -5.7425e-02],\n",
      "          [ 2.7838e-03,  5.1282e-02,  7.3547e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3867e-01,  1.1585e-01,  3.1108e-02],\n",
      "          [ 8.1195e-02,  3.9036e-02,  1.4595e-02],\n",
      "          [ 3.8985e-02,  2.2516e-02,  4.2080e-02]],\n",
      "\n",
      "         [[-1.6258e-02,  4.4501e-02,  1.7739e-01],\n",
      "          [-1.1844e-01,  1.7981e-02,  1.3928e-01],\n",
      "          [-1.3955e-01, -1.5462e-02,  4.9264e-02]],\n",
      "\n",
      "         [[ 1.0910e-01,  1.4846e-01,  2.2377e-02],\n",
      "          [-2.5875e-02,  9.1459e-02,  2.0758e-02],\n",
      "          [-1.6208e-01, -1.5560e-02, -1.9004e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.8924e-02, -2.7306e-02,  6.3201e-02],\n",
      "          [-6.6343e-02, -7.1180e-02, -2.1489e-03],\n",
      "          [-7.7134e-02, -7.3499e-02, -1.4866e-02]],\n",
      "\n",
      "         [[-3.7076e-03, -6.9395e-02, -6.8433e-02],\n",
      "          [ 2.9725e-02, -2.5763e-02, -2.9265e-03],\n",
      "          [ 1.6481e-02,  7.9661e-02,  6.5030e-02]],\n",
      "\n",
      "         [[ 3.0923e-02,  9.1673e-02, -1.3394e-03],\n",
      "          [ 9.0815e-02,  4.5805e-02, -1.1892e-02],\n",
      "          [ 2.1780e-01,  1.2711e-01,  9.0930e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0462e-02,  7.4210e-02,  5.8086e-02],\n",
      "          [ 5.0656e-03, -2.7500e-02, -5.8727e-02],\n",
      "          [-3.2615e-02, -4.4441e-03, -7.3445e-02]],\n",
      "\n",
      "         [[ 2.7273e-02,  1.6325e-02,  7.9427e-02],\n",
      "          [ 2.6474e-02, -7.7612e-02, -6.5095e-02],\n",
      "          [ 6.0277e-02, -5.0775e-02, -5.3482e-02]],\n",
      "\n",
      "         [[-1.9471e-02, -4.5641e-03,  2.1855e-02],\n",
      "          [-1.3840e-02, -5.3562e-04,  2.1604e-02],\n",
      "          [-4.6256e-02, -4.4832e-02,  2.4235e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.5860e-02,  4.0040e-02, -6.1512e-02],\n",
      "          [ 8.1278e-02,  1.7566e-02, -7.7994e-02],\n",
      "          [-6.4163e-02, -1.0145e-01, -8.8152e-02]],\n",
      "\n",
      "         [[-1.8122e-02, -3.5572e-02,  1.1452e-02],\n",
      "          [ 2.2359e-02,  3.4982e-02, -1.1133e-02],\n",
      "          [ 1.0185e-01,  6.6152e-02,  3.0296e-02]],\n",
      "\n",
      "         [[ 6.7714e-02, -8.6069e-02, -7.0144e-02],\n",
      "          [-1.3238e-02, -3.9003e-02, -8.4736e-02],\n",
      "          [-4.5645e-02, -2.0378e-02, -1.1200e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.2440e-02,  2.4741e-03, -3.5767e-02],\n",
      "          [-3.7253e-02,  2.9474e-02,  6.5438e-02],\n",
      "          [-2.1010e-02, -3.5563e-02,  6.6596e-03]],\n",
      "\n",
      "         [[-1.4895e-01, -3.2765e-02, -6.2452e-02],\n",
      "          [-1.7139e-01, -5.2305e-02, -3.3976e-02],\n",
      "          [-8.2635e-02, -1.0406e-03, -2.7582e-02]],\n",
      "\n",
      "         [[-5.5978e-02, -4.0800e-03, -8.2713e-02],\n",
      "          [-1.4434e-02, -2.6384e-02, -9.8256e-02],\n",
      "          [-3.2208e-02,  2.6039e-02, -6.8191e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9257e-02, -2.7297e-02, -9.8630e-02],\n",
      "          [ 8.3336e-02, -2.0388e-02, -9.4245e-02],\n",
      "          [ 8.3305e-02, -2.3387e-02, -5.8583e-02]],\n",
      "\n",
      "         [[ 6.4459e-03,  1.1816e-01,  1.0401e-01],\n",
      "          [-3.3128e-02,  8.9243e-02,  1.1402e-01],\n",
      "          [-8.2220e-02,  3.3729e-02,  7.2402e-02]],\n",
      "\n",
      "         [[-5.8615e-02, -5.7495e-02, -6.1465e-02],\n",
      "          [-6.6454e-02, -1.9146e-04,  8.2795e-02],\n",
      "          [-9.0550e-02,  1.7118e-03,  1.2106e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9538e-02,  1.0986e-01,  2.7503e-02],\n",
      "          [-1.9282e-02,  1.7293e-01,  8.6365e-02],\n",
      "          [-6.7689e-03,  1.5038e-01,  8.3339e-02]],\n",
      "\n",
      "         [[ 4.0095e-02,  5.0104e-03, -1.9115e-02],\n",
      "          [ 6.0775e-02, -1.6596e-02, -3.1525e-02],\n",
      "          [ 1.5399e-01,  7.2151e-02,  3.4304e-03]],\n",
      "\n",
      "         [[ 2.3073e-02,  2.2196e-02,  9.9484e-04],\n",
      "          [ 1.3061e-02,  1.1321e-02, -1.9006e-02],\n",
      "          [-4.4206e-02, -1.1823e-02, -7.5213e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6327e-02,  6.3210e-02,  3.7560e-02],\n",
      "          [ 4.9647e-03,  3.6890e-02,  2.3300e-02],\n",
      "          [ 4.9588e-03,  8.7494e-03, -1.7472e-02]],\n",
      "\n",
      "         [[-1.2197e-02, -4.3892e-02,  3.9930e-02],\n",
      "          [-4.5361e-02, -6.1564e-02, -3.3994e-02],\n",
      "          [-6.6724e-02, -1.9995e-03, -6.0808e-03]],\n",
      "\n",
      "         [[-3.5189e-02,  1.0991e-02,  5.9669e-02],\n",
      "          [-4.1440e-02, -1.7766e-02, -3.8171e-03],\n",
      "          [-4.7351e-02,  1.3913e-02,  1.8684e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.1005e-03,  3.4596e-03, -9.4191e-02],\n",
      "          [ 4.9207e-02,  4.8698e-02, -2.5359e-03],\n",
      "          [ 7.6198e-02,  8.9009e-02,  5.4700e-03]],\n",
      "\n",
      "         [[ 2.0500e-01,  1.5396e-01,  1.1882e-02],\n",
      "          [ 1.4858e-01,  1.8624e-01,  6.7380e-02],\n",
      "          [ 1.0893e-01,  1.4191e-01,  9.8576e-02]],\n",
      "\n",
      "         [[-2.9021e-02, -2.9042e-02, -1.7396e-03],\n",
      "          [-2.2408e-02, -3.5486e-02, -4.1294e-02],\n",
      "          [ 2.9058e-02,  2.1148e-03,  6.2922e-03]]]], device='cuda:0')), ('layer2.1.bn2.weight', tensor([0.4114, 0.5200, 0.2427, 0.3733, 0.3852, 0.4380, 0.4010, 0.3798, 0.3601,\n",
      "        0.3144, 0.2482, 0.2413, 0.3098, 0.3414, 0.4545, 0.3456, 0.1861, 0.3497,\n",
      "        0.4370, 0.3907, 0.5619, 0.3228, 0.2851, 0.3034, 0.3791, 0.3422, 0.4267,\n",
      "        0.3658, 0.2793, 0.5514, 0.3579, 0.3211], device='cuda:0')), ('layer2.1.bn2.bias', tensor([-0.1341,  0.1137, -0.0020, -0.2214,  0.0450, -0.2071, -0.1139, -0.2101,\n",
      "        -0.0135, -0.0816, -0.0412,  0.0459,  0.0054,  0.0365, -0.0614, -0.0215,\n",
      "         0.0060,  0.1389, -0.0312,  0.0588,  0.1918,  0.0367,  0.1166, -0.0740,\n",
      "        -0.0448, -0.0132,  0.0515, -0.0811,  0.1280, -0.0768,  0.0313,  0.1414],\n",
      "       device='cuda:0')), ('layer2.1.bn2.running_mean', tensor([-0.1660,  0.0641, -0.0757, -0.1005,  0.4888, -0.1004, -0.2452, -0.1688,\n",
      "        -0.0720,  0.0059, -0.0965, -0.0208, -0.4692, -0.0901,  0.0139,  0.0455,\n",
      "        -0.2798,  0.1061, -0.2107, -0.2150, -0.4252, -0.2199,  0.3043,  0.0185,\n",
      "        -0.2447, -0.0614, -0.2424,  0.0458, -0.0519, -0.0609, -0.0646,  0.0281],\n",
      "       device='cuda:0')), ('layer2.1.bn2.running_var', tensor([0.0808, 0.0820, 0.0601, 0.0591, 0.0819, 0.0843, 0.0621, 0.0719, 0.0757,\n",
      "        0.0690, 0.0567, 0.0730, 0.0949, 0.0879, 0.0948, 0.0607, 0.0622, 0.0799,\n",
      "        0.0851, 0.0860, 0.1573, 0.0878, 0.0671, 0.0438, 0.0813, 0.0750, 0.0999,\n",
      "        0.0882, 0.0731, 0.1379, 0.0723, 0.0757], device='cuda:0')), ('layer2.1.bn2.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer3.0.conv1.weight', tensor([[[[ 0.0091,  0.0609,  0.0653],\n",
      "          [ 0.0571,  0.0724,  0.0101],\n",
      "          [ 0.0908,  0.0869, -0.0148]],\n",
      "\n",
      "         [[-0.0893, -0.0824, -0.0584],\n",
      "          [-0.0318, -0.0410, -0.0176],\n",
      "          [ 0.0606,  0.0123,  0.0331]],\n",
      "\n",
      "         [[ 0.0058, -0.0213, -0.0153],\n",
      "          [-0.0200, -0.0177, -0.0657],\n",
      "          [-0.0446, -0.0326, -0.0273]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0294,  0.0470,  0.0425],\n",
      "          [-0.0209,  0.0273, -0.0173],\n",
      "          [ 0.0417,  0.0350,  0.0150]],\n",
      "\n",
      "         [[-0.0365, -0.0011, -0.0112],\n",
      "          [-0.0215, -0.0650, -0.0451],\n",
      "          [-0.0014, -0.0626, -0.0155]],\n",
      "\n",
      "         [[ 0.0397,  0.0680, -0.0081],\n",
      "          [ 0.0002,  0.0337,  0.0779],\n",
      "          [-0.0101,  0.0139,  0.1459]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0582,  0.0665,  0.0330],\n",
      "          [ 0.0302,  0.0339, -0.0042],\n",
      "          [ 0.0209, -0.0554, -0.0582]],\n",
      "\n",
      "         [[ 0.0107, -0.0197, -0.0508],\n",
      "          [-0.0093, -0.0586, -0.0683],\n",
      "          [-0.0216, -0.0723, -0.0197]],\n",
      "\n",
      "         [[ 0.0907,  0.0237, -0.0234],\n",
      "          [ 0.0494,  0.0407,  0.0077],\n",
      "          [ 0.0662,  0.0440,  0.0157]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0681, -0.0337,  0.0075],\n",
      "          [-0.0454, -0.0152,  0.0032],\n",
      "          [ 0.0071, -0.0653, -0.0223]],\n",
      "\n",
      "         [[ 0.0165,  0.0332,  0.1065],\n",
      "          [-0.0305, -0.0461, -0.0173],\n",
      "          [-0.0608, -0.0922, -0.0800]],\n",
      "\n",
      "         [[ 0.1159,  0.0300, -0.0247],\n",
      "          [ 0.0556, -0.0116, -0.0313],\n",
      "          [ 0.0294,  0.0019, -0.0035]]],\n",
      "\n",
      "\n",
      "        [[[-0.1025, -0.0915, -0.1044],\n",
      "          [-0.0918, -0.0536, -0.0612],\n",
      "          [-0.0525, -0.0163, -0.0524]],\n",
      "\n",
      "         [[-0.0957, -0.0272,  0.1090],\n",
      "          [-0.0567,  0.0283,  0.1170],\n",
      "          [-0.0114,  0.0433,  0.1593]],\n",
      "\n",
      "         [[-0.0200,  0.0193, -0.0264],\n",
      "          [ 0.0828,  0.0728, -0.0299],\n",
      "          [-0.0024, -0.0189, -0.0673]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0303,  0.0552,  0.0570],\n",
      "          [ 0.0434,  0.0672,  0.1436],\n",
      "          [ 0.0474,  0.0912,  0.0923]],\n",
      "\n",
      "         [[-0.0107,  0.0284,  0.0435],\n",
      "          [-0.0707, -0.0509, -0.0108],\n",
      "          [-0.0707, -0.1073, -0.0210]],\n",
      "\n",
      "         [[-0.0153, -0.1008, -0.0689],\n",
      "          [-0.0693, -0.0512, -0.0333],\n",
      "          [-0.0416, -0.0441, -0.0318]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1189,  0.0749,  0.0243],\n",
      "          [ 0.1127,  0.0045, -0.0477],\n",
      "          [ 0.0623, -0.0037, -0.0337]],\n",
      "\n",
      "         [[-0.0649, -0.0909, -0.0211],\n",
      "          [-0.0446, -0.0875, -0.0481],\n",
      "          [-0.0379, -0.0568, -0.0689]],\n",
      "\n",
      "         [[-0.0281, -0.0177, -0.0281],\n",
      "          [-0.0916, -0.0773, -0.0895],\n",
      "          [-0.1264, -0.1707, -0.1139]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0406,  0.0459,  0.0601],\n",
      "          [ 0.0562,  0.1087,  0.1579],\n",
      "          [ 0.0303,  0.0855,  0.1135]],\n",
      "\n",
      "         [[ 0.0055,  0.0301,  0.0236],\n",
      "          [ 0.0115,  0.0191,  0.0359],\n",
      "          [-0.0249,  0.0283,  0.0732]],\n",
      "\n",
      "         [[-0.0340,  0.0062,  0.0042],\n",
      "          [ 0.0349,  0.0748,  0.0893],\n",
      "          [-0.0635,  0.0036,  0.0176]]],\n",
      "\n",
      "\n",
      "        [[[-0.0599,  0.0086,  0.0206],\n",
      "          [-0.1060, -0.0745, -0.0759],\n",
      "          [-0.1406, -0.0912, -0.0621]],\n",
      "\n",
      "         [[-0.0553, -0.0949, -0.0237],\n",
      "          [-0.0885, -0.0607, -0.0336],\n",
      "          [-0.0570, -0.0298,  0.0426]],\n",
      "\n",
      "         [[ 0.0050,  0.0403, -0.0188],\n",
      "          [-0.0023,  0.0464, -0.0020],\n",
      "          [-0.0330, -0.0520, -0.0401]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0808, -0.0594, -0.0931],\n",
      "          [-0.0882, -0.0820, -0.0739],\n",
      "          [-0.0439, -0.0072, -0.0155]],\n",
      "\n",
      "         [[ 0.0350,  0.0243,  0.0311],\n",
      "          [ 0.0294,  0.0384,  0.0060],\n",
      "          [ 0.0069,  0.0365,  0.0111]],\n",
      "\n",
      "         [[ 0.0326,  0.0458,  0.0243],\n",
      "          [ 0.0335,  0.0766,  0.0475],\n",
      "          [-0.0279,  0.0149,  0.0253]]],\n",
      "\n",
      "\n",
      "        [[[-0.0340, -0.0891, -0.0428],\n",
      "          [-0.0231, -0.0449,  0.0168],\n",
      "          [ 0.0104,  0.0521,  0.0548]],\n",
      "\n",
      "         [[ 0.0312,  0.0494,  0.0489],\n",
      "          [-0.0099,  0.0163, -0.0064],\n",
      "          [ 0.0871,  0.0360, -0.0440]],\n",
      "\n",
      "         [[-0.0256, -0.0149,  0.0271],\n",
      "          [-0.0890,  0.0222,  0.0801],\n",
      "          [-0.0289,  0.0740,  0.0499]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0930,  0.0072, -0.0339],\n",
      "          [-0.0135, -0.0523, -0.0572],\n",
      "          [-0.0356,  0.0320,  0.0346]],\n",
      "\n",
      "         [[ 0.0326, -0.0197, -0.0697],\n",
      "          [-0.0476, -0.0782, -0.0840],\n",
      "          [-0.0788, -0.0434, -0.0036]],\n",
      "\n",
      "         [[-0.0622, -0.0552, -0.0211],\n",
      "          [-0.0209, -0.0133, -0.0002],\n",
      "          [ 0.0720,  0.0375, -0.0802]]]], device='cuda:0')), ('layer3.0.bn1.weight', tensor([0.3824, 0.3642, 0.4293, 0.4237, 0.3949, 0.4873, 0.4083, 0.4698, 0.3925,\n",
      "        0.3674, 0.4130, 0.4791, 0.4078, 0.3831, 0.4199, 0.4457, 0.3558, 0.3228,\n",
      "        0.3661, 0.3760, 0.3594, 0.3765, 0.3778, 0.3980, 0.5386, 0.3359, 0.4004,\n",
      "        0.3596, 0.3758, 0.3463, 0.3173, 0.3756, 0.3514, 0.3763, 0.3746, 0.3175,\n",
      "        0.4802, 0.3504, 0.4418, 0.3994, 0.4693, 0.3385, 0.3468, 0.3941, 0.4255,\n",
      "        0.3488, 0.4042, 0.4342, 0.4060, 0.3329, 0.3197, 0.3845, 0.4022, 0.3875,\n",
      "        0.3997, 0.4251, 0.3475, 0.3944, 0.4077, 0.4026, 0.4338, 0.4070, 0.4052,\n",
      "        0.4062], device='cuda:0')), ('layer3.0.bn1.bias', tensor([-0.2409, -0.1663, -0.0168, -0.1750, -0.2341, -0.1091, -0.2306, -0.1519,\n",
      "        -0.1768, -0.1852, -0.1607, -0.2113, -0.2369,  0.0051, -0.2890, -0.2518,\n",
      "        -0.0332, -0.1018, -0.2344, -0.2430, -0.1019, -0.0903, -0.3386, -0.2609,\n",
      "        -0.0946, -0.1403, -0.1101, -0.1858, -0.1575, -0.0477, -0.1002, -0.0324,\n",
      "        -0.1553, -0.1617, -0.2049, -0.1106, -0.2834, -0.0733, -0.2636, -0.2030,\n",
      "        -0.1828, -0.1470, -0.0917, -0.1594, -0.2414, -0.1353, -0.0300, -0.2006,\n",
      "        -0.2058, -0.1638, -0.2047, -0.1718, -0.2140, -0.0858, -0.1986, -0.2290,\n",
      "        -0.2643, -0.1531, -0.2034, -0.3763, -0.1551, -0.0144, -0.3095, -0.1165],\n",
      "       device='cuda:0')), ('layer3.0.bn1.running_mean', tensor([-0.2294, -1.3725, -1.4829, -0.5562, -0.4492, -0.6821,  0.5431, -0.0678,\n",
      "         0.8727, -0.6297, -0.1357, -1.0939,  0.5848, -0.1005, -0.3685, -0.8644,\n",
      "        -0.8371, -1.3806, -0.4703,  0.0604, -1.1698, -1.2545,  0.2212, -1.1427,\n",
      "        -2.0359, -0.9505,  0.2367, -0.5545, -0.8553, -2.0282, -0.6644, -0.0609,\n",
      "        -1.1317, -0.5647,  0.1829, -0.4652, -0.7362,  1.1754, -0.2195,  0.0332,\n",
      "        -1.5110, -0.5004,  0.1245, -0.9113, -0.6675, -0.1753,  0.2882, -1.1577,\n",
      "        -0.0276, -1.0212, -0.4432, -0.6567,  1.1493, -1.1242, -0.9423, -0.1155,\n",
      "         0.4113, -1.0463, -1.1955, -0.7417, -1.3565, -0.3235,  0.1153, -0.5021],\n",
      "       device='cuda:0')), ('layer3.0.bn1.running_var', tensor([0.5814, 0.6284, 0.8524, 0.5063, 0.4943, 0.9026, 0.7014, 0.8297, 0.4626,\n",
      "        0.5175, 0.5409, 0.8770, 0.5615, 0.6528, 0.4387, 0.6637, 0.5854, 0.4918,\n",
      "        0.4732, 0.4909, 0.7094, 0.7863, 0.4144, 0.6495, 0.9562, 0.6459, 0.7323,\n",
      "        0.5218, 0.4590, 0.5810, 0.5375, 0.5287, 0.4925, 0.5940, 0.8184, 1.0042,\n",
      "        0.6870, 0.5532, 0.7372, 0.5334, 0.8035, 0.6505, 0.7195, 0.6567, 0.6947,\n",
      "        0.4007, 0.4423, 0.4891, 0.6228, 0.5308, 0.4270, 0.6195, 0.7894, 0.6294,\n",
      "        0.7858, 0.6546, 0.7485, 0.5935, 0.9581, 0.6323, 0.7245, 0.5315, 0.5630,\n",
      "        0.4024], device='cuda:0')), ('layer3.0.bn1.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer3.0.conv2.weight', tensor([[[[-0.0721, -0.0182,  0.0113],\n",
      "          [-0.0234, -0.0118,  0.0203],\n",
      "          [-0.0577, -0.0741, -0.0178]],\n",
      "\n",
      "         [[ 0.1041,  0.1078,  0.0047],\n",
      "          [ 0.0248,  0.0885,  0.0449],\n",
      "          [-0.0846,  0.0371, -0.0541]],\n",
      "\n",
      "         [[-0.0071,  0.1145,  0.0409],\n",
      "          [ 0.0050,  0.0977, -0.0235],\n",
      "          [-0.0244, -0.0529, -0.0903]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0373, -0.0426, -0.0370],\n",
      "          [ 0.0376, -0.0038,  0.0464],\n",
      "          [ 0.0952,  0.0886,  0.0753]],\n",
      "\n",
      "         [[ 0.0614, -0.0273,  0.0179],\n",
      "          [ 0.0405, -0.0495, -0.0227],\n",
      "          [ 0.0186, -0.0413,  0.0260]],\n",
      "\n",
      "         [[ 0.0603,  0.0496,  0.0346],\n",
      "          [-0.0468,  0.0237,  0.0774],\n",
      "          [-0.0187,  0.0628,  0.0074]]],\n",
      "\n",
      "\n",
      "        [[[-0.0089, -0.1134, -0.0451],\n",
      "          [ 0.0689,  0.0103, -0.0206],\n",
      "          [-0.0097,  0.1068, -0.1024]],\n",
      "\n",
      "         [[ 0.0454,  0.0640,  0.0207],\n",
      "          [ 0.0777,  0.0065, -0.0055],\n",
      "          [-0.0325, -0.0145, -0.0016]],\n",
      "\n",
      "         [[-0.0235,  0.0181, -0.0463],\n",
      "          [-0.0570, -0.0387,  0.0511],\n",
      "          [-0.0258, -0.0638,  0.0627]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0206,  0.0189, -0.0239],\n",
      "          [-0.0217, -0.0575, -0.0450],\n",
      "          [ 0.0249, -0.0563, -0.0337]],\n",
      "\n",
      "         [[-0.0407, -0.1038,  0.0561],\n",
      "          [-0.0416, -0.0674, -0.0342],\n",
      "          [-0.0070, -0.0610,  0.0022]],\n",
      "\n",
      "         [[ 0.0811,  0.0750,  0.0191],\n",
      "          [-0.0439, -0.0158,  0.0123],\n",
      "          [-0.0226, -0.0346,  0.0091]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0931, -0.0676, -0.0095],\n",
      "          [ 0.0238, -0.0306, -0.0074],\n",
      "          [ 0.0053,  0.0356, -0.0131]],\n",
      "\n",
      "         [[ 0.0147,  0.0073,  0.0069],\n",
      "          [ 0.0338,  0.0207,  0.0301],\n",
      "          [ 0.0493,  0.0408,  0.0242]],\n",
      "\n",
      "         [[-0.0612,  0.0168,  0.0180],\n",
      "          [-0.0468, -0.0391, -0.0245],\n",
      "          [-0.0503, -0.0613, -0.0335]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0578,  0.0076, -0.0233],\n",
      "          [-0.0225, -0.0092, -0.0186],\n",
      "          [ 0.0253, -0.0302, -0.0160]],\n",
      "\n",
      "         [[-0.0165, -0.0389, -0.0138],\n",
      "          [-0.0733, -0.0540, -0.0679],\n",
      "          [-0.0165, -0.0642,  0.0389]],\n",
      "\n",
      "         [[ 0.0224,  0.0153, -0.0140],\n",
      "          [-0.0180, -0.0389, -0.0579],\n",
      "          [-0.0111, -0.0072, -0.0107]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0728, -0.0732, -0.0141],\n",
      "          [-0.0611, -0.0723,  0.0195],\n",
      "          [-0.0298,  0.0177,  0.0878]],\n",
      "\n",
      "         [[ 0.0653,  0.0599,  0.0678],\n",
      "          [-0.0237,  0.0948, -0.0044],\n",
      "          [ 0.0548,  0.0687,  0.0072]],\n",
      "\n",
      "         [[ 0.0109,  0.0326, -0.0046],\n",
      "          [-0.0276,  0.0280, -0.0024],\n",
      "          [-0.0830, -0.0263,  0.0437]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0228, -0.0445, -0.0157],\n",
      "          [ 0.0088, -0.0406, -0.0144],\n",
      "          [-0.0335, -0.0756, -0.0251]],\n",
      "\n",
      "         [[ 0.0080, -0.0232,  0.0629],\n",
      "          [-0.0268,  0.0443,  0.0672],\n",
      "          [-0.0640, -0.0904, -0.0965]],\n",
      "\n",
      "         [[ 0.0362,  0.0264, -0.0248],\n",
      "          [-0.0294, -0.0674,  0.0160],\n",
      "          [-0.0237, -0.0592, -0.0065]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0658, -0.1095, -0.1107],\n",
      "          [ 0.0730,  0.0948,  0.0355],\n",
      "          [-0.0495,  0.0563,  0.0163]],\n",
      "\n",
      "         [[ 0.1028,  0.0724, -0.0774],\n",
      "          [-0.0021,  0.0718, -0.0357],\n",
      "          [ 0.0483, -0.0048, -0.0796]],\n",
      "\n",
      "         [[-0.0293, -0.0594, -0.0378],\n",
      "          [ 0.0514, -0.0403, -0.0988],\n",
      "          [ 0.0543,  0.0399,  0.0155]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133, -0.0465, -0.0341],\n",
      "          [-0.0282, -0.0265, -0.0651],\n",
      "          [-0.0837, -0.0632, -0.0662]],\n",
      "\n",
      "         [[ 0.0194, -0.0361, -0.0815],\n",
      "          [ 0.0096, -0.0086,  0.0003],\n",
      "          [ 0.0512,  0.0200,  0.0004]],\n",
      "\n",
      "         [[ 0.0737,  0.0271, -0.0487],\n",
      "          [ 0.1234, -0.0224, -0.0836],\n",
      "          [ 0.0129,  0.0012, -0.0234]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0455, -0.0235, -0.0268],\n",
      "          [ 0.0279, -0.0350,  0.0054],\n",
      "          [-0.0309, -0.0105,  0.0531]],\n",
      "\n",
      "         [[-0.0439,  0.0029,  0.1184],\n",
      "          [-0.1062, -0.0342,  0.1585],\n",
      "          [-0.0182, -0.0533, -0.0353]],\n",
      "\n",
      "         [[-0.0221,  0.1198,  0.0546],\n",
      "          [-0.0069,  0.0368, -0.0457],\n",
      "          [-0.0882, -0.0556, -0.0007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0390, -0.0947, -0.0432],\n",
      "          [ 0.0221, -0.0160, -0.1189],\n",
      "          [ 0.0944,  0.0340, -0.0159]],\n",
      "\n",
      "         [[ 0.0948, -0.0247, -0.0682],\n",
      "          [ 0.1810, -0.0364, -0.0668],\n",
      "          [ 0.0357, -0.0358, -0.0104]],\n",
      "\n",
      "         [[ 0.0560, -0.0060, -0.0191],\n",
      "          [-0.0556, -0.0329,  0.0312],\n",
      "          [-0.0795,  0.0475,  0.0550]]]], device='cuda:0')), ('layer3.0.bn2.weight', tensor([0.5168, 0.4054, 0.3897, 0.5104, 0.4879, 0.4311, 0.5002, 0.3989, 0.5380,\n",
      "        0.4877, 0.3918, 0.4387, 0.3888, 0.3922, 0.4819, 0.4825, 0.5322, 0.4802,\n",
      "        0.5097, 0.4993, 0.5122, 0.4294, 0.4702, 0.4604, 0.5105, 0.5538, 0.4695,\n",
      "        0.5580, 0.5384, 0.4475, 0.4552, 0.5436, 0.4452, 0.3351, 0.4386, 0.3893,\n",
      "        0.4770, 0.4597, 0.4159, 0.4846, 0.4297, 0.4667, 0.4738, 0.5198, 0.4679,\n",
      "        0.4696, 0.4354, 0.5135, 0.4471, 0.5734, 0.4886, 0.5297, 0.5289, 0.4792,\n",
      "        0.4081, 0.3564, 0.5314, 0.4968, 0.4494, 0.3955, 0.4823, 0.3632, 0.4657,\n",
      "        0.5037], device='cuda:0')), ('layer3.0.bn2.bias', tensor([-0.0871, -0.1250, -0.1115, -0.2109, -0.1291, -0.1270, -0.1749, -0.0640,\n",
      "        -0.1891, -0.0615, -0.1046, -0.0604, -0.0699, -0.1431, -0.1743, -0.2581,\n",
      "        -0.2756, -0.1833, -0.1907, -0.0284, -0.2527, -0.0551, -0.1752, -0.1713,\n",
      "        -0.0928, -0.1272, -0.1815, -0.1919, -0.2187, -0.1424, -0.0706, -0.2684,\n",
      "        -0.1411,  0.0147, -0.1313, -0.1113, -0.1005, -0.0950, -0.1260, -0.2075,\n",
      "        -0.2571, -0.1950, -0.2119, -0.2541, -0.1855, -0.1547, -0.1885, -0.1409,\n",
      "        -0.0920, -0.1710, -0.1626, -0.2031, -0.1028, -0.2926, -0.0681, -0.1267,\n",
      "        -0.1809, -0.2090, -0.1155,  0.0121, -0.2093, -0.1398, -0.1503, -0.0810],\n",
      "       device='cuda:0')), ('layer3.0.bn2.running_mean', tensor([-0.2664, -0.1468, -0.2074, -0.0070, -0.0194, -0.0164, -0.4477, -0.3408,\n",
      "        -0.1385, -0.1777, -0.2004, -0.0501, -0.1946, -0.3948, -0.0139,  0.0534,\n",
      "         0.0865, -0.2207, -0.0727, -0.2053, -0.2644, -0.4407, -0.2994, -0.0090,\n",
      "        -0.2397, -0.1379, -0.2248, -0.0941,  0.1990, -0.3500, -0.1113, -0.0513,\n",
      "        -0.3315, -0.4721,  0.1872, -0.1216, -0.1824,  0.0248, -0.2092,  0.0788,\n",
      "        -0.3397, -0.1428, -0.0287, -0.0297, -0.2563, -0.0207, -0.0766,  0.1295,\n",
      "         0.0481, -0.1117, -0.2255, -0.2667, -0.1673, -0.0618, -0.2918, -0.0893,\n",
      "        -0.1314,  0.0908, -0.1672, -0.2434, -0.2602, -0.0620, -0.1284, -0.1795],\n",
      "       device='cuda:0')), ('layer3.0.bn2.running_var', tensor([0.1446, 0.0866, 0.0863, 0.1238, 0.1198, 0.1363, 0.1280, 0.1045, 0.1220,\n",
      "        0.1307, 0.0962, 0.1250, 0.1009, 0.1347, 0.0932, 0.1368, 0.1327, 0.0910,\n",
      "        0.1326, 0.1471, 0.1282, 0.1262, 0.1018, 0.0967, 0.1152, 0.1337, 0.1201,\n",
      "        0.1737, 0.1563, 0.1030, 0.1229, 0.1140, 0.1323, 0.1159, 0.1076, 0.1082,\n",
      "        0.1173, 0.1208, 0.1132, 0.0922, 0.1327, 0.1075, 0.1216, 0.1017, 0.1258,\n",
      "        0.1074, 0.0937, 0.0923, 0.1104, 0.1724, 0.1315, 0.1055, 0.1328, 0.1175,\n",
      "        0.1312, 0.0856, 0.1470, 0.1180, 0.1005, 0.1011, 0.1300, 0.0932, 0.1200,\n",
      "        0.1219], device='cuda:0')), ('layer3.0.bn2.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer3.0.shortcut.0.weight', tensor([[[[ 0.1297]],\n",
      "\n",
      "         [[-0.0503]],\n",
      "\n",
      "         [[ 0.0732]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0464]],\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         [[-0.1003]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0836]],\n",
      "\n",
      "         [[ 0.0503]],\n",
      "\n",
      "         [[ 0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0794]],\n",
      "\n",
      "         [[-0.0319]],\n",
      "\n",
      "         [[-0.0419]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1382]],\n",
      "\n",
      "         [[-0.0135]],\n",
      "\n",
      "         [[-0.0530]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0392]],\n",
      "\n",
      "         [[-0.0449]],\n",
      "\n",
      "         [[-0.0860]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0330]],\n",
      "\n",
      "         [[ 0.0504]],\n",
      "\n",
      "         [[-0.0046]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0728]],\n",
      "\n",
      "         [[ 0.0237]],\n",
      "\n",
      "         [[ 0.0311]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0013]],\n",
      "\n",
      "         [[ 0.0134]],\n",
      "\n",
      "         [[ 0.0131]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0392]],\n",
      "\n",
      "         [[-0.0147]],\n",
      "\n",
      "         [[ 0.0529]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0319]],\n",
      "\n",
      "         [[ 0.0071]],\n",
      "\n",
      "         [[-0.0233]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0430]],\n",
      "\n",
      "         [[-0.0402]],\n",
      "\n",
      "         [[-0.1568]]]], device='cuda:0')), ('layer3.0.shortcut.1.weight', tensor([0.1895, 0.1803, 0.1545, 0.1980, 0.1690, 0.1479, 0.1700, 0.1971, 0.1668,\n",
      "        0.1834, 0.2412, 0.1560, 0.1363, 0.2324, 0.1742, 0.1672, 0.1480, 0.1128,\n",
      "        0.1511, 0.2133, 0.1369, 0.1565, 0.1700, 0.2367, 0.1834, 0.1959, 0.0803,\n",
      "        0.1351, 0.0446, 0.1723, 0.1231, 0.1073, 0.2483, 0.1986, 0.1908, 0.1695,\n",
      "        0.1085, 0.0877, 0.2255, 0.1058, 0.1818, 0.1946, 0.1381, 0.1098, 0.1412,\n",
      "        0.2355, 0.2636, 0.1105, 0.0948, 0.0636, 0.1750, 0.1423, 0.1350, 0.1253,\n",
      "        0.1390, 0.2502, 0.1237, 0.1481, 0.1255, 0.1739, 0.1743, 0.1768, 0.0640,\n",
      "        0.1499], device='cuda:0')), ('layer3.0.shortcut.1.bias', tensor([-0.0871, -0.1250, -0.1115, -0.2109, -0.1291, -0.1270, -0.1749, -0.0640,\n",
      "        -0.1891, -0.0615, -0.1046, -0.0604, -0.0699, -0.1431, -0.1743, -0.2581,\n",
      "        -0.2756, -0.1833, -0.1907, -0.0284, -0.2527, -0.0551, -0.1752, -0.1713,\n",
      "        -0.0928, -0.1272, -0.1815, -0.1919, -0.2187, -0.1424, -0.0706, -0.2684,\n",
      "        -0.1411,  0.0147, -0.1313, -0.1113, -0.1005, -0.0950, -0.1260, -0.2075,\n",
      "        -0.2571, -0.1950, -0.2119, -0.2541, -0.1855, -0.1547, -0.1885, -0.1409,\n",
      "        -0.0920, -0.1710, -0.1626, -0.2031, -0.1028, -0.2926, -0.0681, -0.1267,\n",
      "        -0.1809, -0.2090, -0.1155,  0.0121, -0.2093, -0.1398, -0.1503, -0.0810],\n",
      "       device='cuda:0')), ('layer3.0.shortcut.1.running_mean', tensor([-0.1102, -0.0479, -0.1229, -0.1148,  0.1415,  0.0560,  0.0903, -0.0447,\n",
      "        -0.0688, -0.3130, -0.1351,  0.0637, -0.2629, -0.2620, -0.1084, -0.1530,\n",
      "         0.3816, -0.2034, -0.2560,  0.0889, -0.0275, -0.1106,  0.1028, -0.0094,\n",
      "        -0.3324, -0.3082, -0.0464, -0.0923, -0.0108,  0.1004, -0.1265, -0.1671,\n",
      "        -0.1448, -0.1277,  0.3749, -0.1314,  0.1031,  0.0396, -0.1929, -0.1099,\n",
      "        -0.1149, -0.0119, -0.2717, -0.0547, -0.3112, -0.0446, -0.1581, -0.4962,\n",
      "         0.0585, -0.1655, -0.1590, -0.0234, -0.0332,  0.0513, -0.1050, -0.1136,\n",
      "        -0.0471,  0.0016, -0.0624,  0.1170, -0.1961, -0.3439, -0.0133, -0.0672],\n",
      "       device='cuda:0')), ('layer3.0.shortcut.1.running_var', tensor([0.0489, 0.0471, 0.0447, 0.0424, 0.0412, 0.0369, 0.0415, 0.0478, 0.0306,\n",
      "        0.0457, 0.0637, 0.0513, 0.0298, 0.0743, 0.0335, 0.0534, 0.0403, 0.0345,\n",
      "        0.0422, 0.0607, 0.0322, 0.0576, 0.0535, 0.0526, 0.0425, 0.0575, 0.0261,\n",
      "        0.0269, 0.0181, 0.0475, 0.0297, 0.0254, 0.0443, 0.0691, 0.0487, 0.0407,\n",
      "        0.0398, 0.0201, 0.0443, 0.0157, 0.0476, 0.0326, 0.0217, 0.0212, 0.0301,\n",
      "        0.0582, 0.0505, 0.0316, 0.0309, 0.0221, 0.0510, 0.0493, 0.0266, 0.0359,\n",
      "        0.0413, 0.0483, 0.0280, 0.0529, 0.0364, 0.0591, 0.0408, 0.0412, 0.0275,\n",
      "        0.0288], device='cuda:0')), ('layer3.0.shortcut.1.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer3.1.conv1.weight', tensor([[[[-4.6230e-02,  3.3937e-02,  5.6618e-02],\n",
      "          [-2.8259e-02, -2.9764e-02, -5.3492e-03],\n",
      "          [-3.4122e-02, -7.3619e-02,  3.4536e-02]],\n",
      "\n",
      "         [[-1.8774e-02,  9.4729e-03,  2.9403e-02],\n",
      "          [ 1.3146e-04,  5.4501e-02, -9.7260e-03],\n",
      "          [ 2.2651e-02,  4.3873e-02,  1.0969e-02]],\n",
      "\n",
      "         [[-5.6701e-02, -7.8919e-02, -6.7534e-02],\n",
      "          [-2.0810e-03, -7.8209e-02, -1.8669e-02],\n",
      "          [ 1.5204e-02,  3.3374e-02,  1.0789e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6563e-02,  9.0722e-02,  9.2675e-02],\n",
      "          [ 4.4192e-02,  8.5079e-02,  1.1563e-02],\n",
      "          [ 3.4261e-02, -1.8415e-02,  7.6028e-03]],\n",
      "\n",
      "         [[ 6.1306e-02, -2.6721e-02,  7.4914e-03],\n",
      "          [ 9.7430e-02,  5.3833e-02,  3.5221e-02],\n",
      "          [ 4.5883e-02,  1.1541e-02,  4.0148e-02]],\n",
      "\n",
      "         [[-4.4665e-03,  2.0598e-03, -9.5789e-02],\n",
      "          [ 2.3469e-03, -6.9708e-02, -2.5941e-02],\n",
      "          [-5.9998e-02,  8.9809e-03,  5.5987e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.4656e-02, -5.1876e-02,  1.5902e-02],\n",
      "          [-6.2703e-02, -6.0784e-02, -1.0196e-02],\n",
      "          [-7.6098e-03, -4.8748e-02, -7.8671e-03]],\n",
      "\n",
      "         [[ 2.4285e-02,  4.7308e-02, -6.9751e-02],\n",
      "          [ 7.4321e-02,  7.3539e-02, -2.6073e-02],\n",
      "          [-1.1673e-03,  3.6588e-02,  8.4526e-03]],\n",
      "\n",
      "         [[-4.3933e-02, -6.5739e-02, -8.8432e-02],\n",
      "          [-3.5347e-02, -1.0436e-01, -3.0850e-02],\n",
      "          [-5.2560e-02, -1.7198e-02,  8.7331e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8309e-02,  3.2718e-03,  5.9824e-02],\n",
      "          [-3.2840e-02, -7.9032e-03,  3.4260e-02],\n",
      "          [-9.5191e-02, -6.4717e-02, -5.5878e-02]],\n",
      "\n",
      "         [[-2.9909e-02, -8.1422e-02, -3.0432e-02],\n",
      "          [ 7.1054e-02,  6.1870e-02,  5.8599e-02],\n",
      "          [-1.7159e-02,  8.0267e-02,  6.8082e-02]],\n",
      "\n",
      "         [[-7.9791e-03, -3.4146e-02,  1.8091e-02],\n",
      "          [ 7.4701e-03, -5.5225e-02, -2.5424e-02],\n",
      "          [-3.1974e-02, -5.9826e-02, -2.7595e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.8682e-02, -7.8503e-02, -2.6317e-02],\n",
      "          [-2.9392e-02, -4.7220e-02, -2.1380e-02],\n",
      "          [ 1.3777e-02, -3.6891e-02,  3.1328e-02]],\n",
      "\n",
      "         [[ 7.9294e-02,  1.5156e-01,  8.7132e-02],\n",
      "          [ 7.3686e-02, -3.3485e-02, -5.5974e-03],\n",
      "          [ 4.0553e-02, -3.7124e-02, -1.1123e-02]],\n",
      "\n",
      "         [[ 5.9321e-02, -1.4664e-02,  5.2788e-02],\n",
      "          [-2.8011e-02, -6.6480e-02, -2.8244e-02],\n",
      "          [-2.9802e-02,  9.7372e-03,  2.4960e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7060e-02,  4.7328e-02, -4.0856e-02],\n",
      "          [ 2.3381e-02, -1.9934e-02, -5.0060e-02],\n",
      "          [-6.3965e-02, -6.5802e-02, -1.0371e-01]],\n",
      "\n",
      "         [[ 4.6491e-02,  1.8508e-02,  5.0514e-02],\n",
      "          [ 8.0446e-02,  6.5228e-02,  4.8021e-02],\n",
      "          [-4.7388e-02, -5.1689e-03, -4.2068e-02]],\n",
      "\n",
      "         [[ 2.9896e-02, -1.5980e-03, -6.1789e-02],\n",
      "          [ 2.7490e-02, -3.1328e-03,  1.0967e-02],\n",
      "          [-4.1629e-02, -1.7013e-03,  6.8787e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7839e-02, -3.2428e-02, -4.7536e-02],\n",
      "          [ 2.1315e-02,  3.1737e-03, -4.3759e-02],\n",
      "          [ 8.1040e-03,  1.1745e-02,  1.5111e-02]],\n",
      "\n",
      "         [[ 8.2955e-03,  5.1206e-02,  2.6889e-02],\n",
      "          [ 6.1817e-03,  1.8261e-02,  1.9682e-02],\n",
      "          [ 3.3221e-02,  6.4657e-02,  4.2206e-02]],\n",
      "\n",
      "         [[ 6.8655e-02, -6.3681e-02, -5.8968e-02],\n",
      "          [-4.2651e-02, -8.8114e-02, -9.1064e-02],\n",
      "          [-7.8811e-02, -6.6962e-02, -4.8804e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2334e-02, -4.2621e-02, -4.6480e-02],\n",
      "          [ 7.8597e-03,  4.9001e-02,  3.1359e-02],\n",
      "          [-1.1557e-01, -2.3657e-02, -4.2192e-02]],\n",
      "\n",
      "         [[ 4.8721e-02,  3.7503e-02, -1.9763e-02],\n",
      "          [-6.7292e-03,  6.9098e-03, -3.1165e-02],\n",
      "          [ 3.2125e-02, -1.5881e-02, -5.8036e-02]],\n",
      "\n",
      "         [[-2.3797e-02,  2.8433e-02,  5.2886e-02],\n",
      "          [ 1.3720e-01,  1.9406e-02, -3.2358e-02],\n",
      "          [ 1.4308e-01,  5.8800e-02,  7.1236e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.6967e-02,  2.0484e-02,  1.5551e-02],\n",
      "          [ 4.2031e-02, -3.2500e-02, -1.0456e-02],\n",
      "          [ 2.1438e-02, -1.0241e-01, -5.8026e-02]],\n",
      "\n",
      "         [[-1.5104e-02, -7.9687e-02, -3.1100e-02],\n",
      "          [-1.9923e-02,  3.0561e-02,  9.9679e-03],\n",
      "          [ 1.4334e-02,  4.7002e-02,  8.2759e-02]],\n",
      "\n",
      "         [[-7.6175e-02, -1.1987e-01, -6.2014e-02],\n",
      "          [-2.8206e-02, -9.4964e-02, -4.4387e-02],\n",
      "          [-3.7848e-02, -9.7265e-03, -5.9998e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6902e-02,  7.0720e-02, -1.5147e-02],\n",
      "          [-3.3647e-02, -1.1167e-01, -1.3319e-01],\n",
      "          [-1.4527e-02, -1.2112e-01, -1.2021e-01]],\n",
      "\n",
      "         [[-2.6292e-02, -3.5558e-03,  1.7165e-02],\n",
      "          [-5.4525e-02, -5.5172e-02, -5.4858e-02],\n",
      "          [-2.6525e-02,  1.1150e-02,  6.4352e-02]],\n",
      "\n",
      "         [[ 9.3451e-02,  7.7273e-02, -3.5748e-02],\n",
      "          [-1.5653e-02, -2.4399e-02, -2.8165e-02],\n",
      "          [-1.5690e-01, -1.0738e-01, -1.1916e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0259e-02,  3.3551e-04, -2.8877e-02],\n",
      "          [-5.4537e-02,  2.0045e-03, -2.7589e-02],\n",
      "          [-1.1925e-01, -9.2087e-02, -5.0707e-02]],\n",
      "\n",
      "         [[-6.5540e-03, -1.7781e-03, -9.0270e-03],\n",
      "          [-2.0316e-02,  1.1310e-02,  2.1472e-02],\n",
      "          [-7.9052e-02,  6.6929e-02,  4.1922e-02]],\n",
      "\n",
      "         [[ 1.1111e-01,  4.2743e-02, -1.0879e-01],\n",
      "          [ 1.1592e-01,  5.9372e-02, -7.1435e-02],\n",
      "          [ 1.1818e-01,  3.8472e-02,  2.3115e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.4044e-02, -1.3099e-01, -3.0822e-02],\n",
      "          [-5.1435e-02, -3.6343e-02,  5.0758e-03],\n",
      "          [ 1.8437e-02,  1.1942e-02,  1.8607e-02]],\n",
      "\n",
      "         [[-4.7084e-02, -2.4934e-02, -7.8882e-02],\n",
      "          [ 9.2718e-02,  3.7366e-02, -3.0581e-02],\n",
      "          [ 3.3471e-02,  6.7156e-02,  6.4432e-02]],\n",
      "\n",
      "         [[-4.2659e-02, -4.1427e-02,  1.4115e-02],\n",
      "          [-3.1176e-02, -3.4068e-02, -2.9860e-02],\n",
      "          [ 5.3265e-02,  1.7119e-02, -1.2068e-02]]]], device='cuda:0')), ('layer3.1.bn1.weight', tensor([0.3828, 0.3846, 0.3451, 0.3741, 0.3454, 0.4120, 0.3113, 0.4410, 0.4977,\n",
      "        0.3663, 0.4477, 0.4666, 0.4610, 0.3427, 0.3742, 0.4539, 0.3913, 0.2893,\n",
      "        0.3890, 0.3511, 0.3574, 0.3787, 0.4049, 0.3676, 0.4057, 0.3503, 0.3241,\n",
      "        0.3501, 0.2692, 0.3883, 0.3791, 0.4018, 0.3285, 0.4662, 0.4073, 0.3675,\n",
      "        0.4014, 0.4425, 0.3228, 0.3304, 0.3344, 0.3404, 0.3314, 0.4032, 0.3710,\n",
      "        0.3607, 0.3306, 0.3861, 0.3607, 0.4260, 0.2997, 0.3072, 0.3522, 0.3538,\n",
      "        0.3873, 0.3663, 0.4699, 0.3622, 0.3784, 0.4347, 0.3482, 0.3720, 0.3823,\n",
      "        0.3603], device='cuda:0')), ('layer3.1.bn1.bias', tensor([-0.3554, -0.2209, -0.2298, -0.3572, -0.5019, -0.4894, -0.2108, -0.4613,\n",
      "        -0.5917, -0.2815, -0.4009, -0.3847, -0.6101, -0.3436, -0.5200, -0.5475,\n",
      "        -0.4802, -0.0047, -0.2719, -0.2453, -0.2182, -0.2399, -0.3708, -0.3509,\n",
      "        -0.2250, -0.2892, -0.2606, -0.3637, -0.1285, -0.3945, -0.3471, -0.2797,\n",
      "        -0.4180, -0.4017, -0.4403, -0.5384, -0.3311, -0.4529, -0.3234, -0.1184,\n",
      "        -0.2208, -0.3285, -0.3246, -0.3975,  0.0310, -0.3102, -0.2927, -0.2820,\n",
      "        -0.2907, -0.3638, -0.2150, -0.1839, -0.4318, -0.1572, -0.2905, -0.2767,\n",
      "        -0.6605, -0.5000, -0.4188, -0.2927, -0.2369, -0.4235, -0.2437, -0.3195],\n",
      "       device='cuda:0')), ('layer3.1.bn1.running_mean', tensor([-3.4072e-01, -3.9317e-01, -4.4579e-01, -1.1784e-01, -3.8739e-01,\n",
      "        -1.5498e-01,  3.3345e-02, -3.0153e-01, -3.3065e-01, -1.7684e-01,\n",
      "        -3.5580e-01, -4.5938e-01,  2.7865e-02, -2.4893e-01, -2.9819e-01,\n",
      "        -5.1516e-01, -3.3393e-01, -7.2654e-01, -1.6804e-01, -2.1779e-01,\n",
      "        -3.6346e-01, -2.4420e-01, -2.0991e-01, -3.5845e-01, -2.2208e-01,\n",
      "        -2.4913e-01,  4.7550e-04, -3.9589e-01, -2.1609e-02, -1.2370e-01,\n",
      "        -3.2678e-01, -2.4028e-01, -1.6974e-01, -4.6348e-01, -2.6342e-01,\n",
      "        -3.6846e-02, -2.4031e-01, -3.6201e-01, -2.9041e-01, -5.5414e-01,\n",
      "        -2.6982e-01,  5.2970e-03, -6.1095e-02, -3.1883e-01, -8.4877e-01,\n",
      "        -3.7412e-01, -2.8093e-01, -4.6975e-01, -2.4054e-01, -6.7881e-02,\n",
      "        -2.9777e-01, -3.4163e-01, -1.0217e-01, -1.9810e-01, -2.1191e-01,\n",
      "        -6.2929e-02, -2.6583e-01, -1.5732e-01, -5.8851e-01, -1.4899e-01,\n",
      "         1.0257e-01, -9.3109e-02, -5.9897e-01, -7.3534e-02], device='cuda:0')), ('layer3.1.bn1.running_var', tensor([0.1800, 0.1988, 0.2655, 0.1680, 0.1770, 0.1430, 0.1430, 0.2024, 0.2174,\n",
      "        0.2075, 0.2028, 0.2112, 0.1886, 0.1835, 0.1993, 0.2084, 0.2259, 0.2335,\n",
      "        0.1629, 0.1362, 0.2034, 0.1991, 0.1924, 0.1694, 0.2222, 0.1534, 0.1295,\n",
      "        0.1741, 0.1571, 0.1705, 0.1814, 0.2429, 0.1592, 0.2478, 0.1929, 0.1484,\n",
      "        0.1761, 0.1875, 0.1546, 0.2100, 0.1979, 0.1509, 0.1449, 0.1907, 0.2534,\n",
      "        0.2090, 0.1682, 0.1623, 0.1697, 0.2236, 0.1979, 0.1828, 0.1348, 0.1812,\n",
      "        0.1766, 0.2322, 0.2234, 0.1404, 0.2068, 0.2055, 0.1733, 0.2029, 0.2102,\n",
      "        0.1584], device='cuda:0')), ('layer3.1.bn1.num_batches_tracked', tensor(78200, device='cuda:0')), ('layer3.1.conv2.weight', tensor([[[[ 0.0320,  0.0196,  0.0343],\n",
      "          [ 0.0370,  0.0227,  0.0334],\n",
      "          [ 0.0411,  0.0235,  0.0453]],\n",
      "\n",
      "         [[ 0.0291,  0.0282,  0.0255],\n",
      "          [ 0.0140,  0.0164,  0.0205],\n",
      "          [ 0.0173,  0.0251,  0.0274]],\n",
      "\n",
      "         [[ 0.0045,  0.0020,  0.0024],\n",
      "          [ 0.0077,  0.0027,  0.0061],\n",
      "          [ 0.0154,  0.0094,  0.0106]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0323, -0.0186, -0.0235],\n",
      "          [-0.0225, -0.0175, -0.0102],\n",
      "          [-0.0197, -0.0119, -0.0105]],\n",
      "\n",
      "         [[ 0.0214,  0.0075,  0.0029],\n",
      "          [ 0.0151,  0.0036,  0.0058],\n",
      "          [ 0.0121, -0.0105,  0.0084]],\n",
      "\n",
      "         [[-0.0115, -0.0048, -0.0080],\n",
      "          [-0.0252, -0.0176, -0.0225],\n",
      "          [-0.0344, -0.0293, -0.0321]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0099,  0.0093,  0.0205],\n",
      "          [ 0.0070,  0.0040,  0.0180],\n",
      "          [ 0.0161,  0.0171,  0.0268]],\n",
      "\n",
      "         [[ 0.0184,  0.0012,  0.0203],\n",
      "          [ 0.0222,  0.0002,  0.0132],\n",
      "          [ 0.0166,  0.0005,  0.0118]],\n",
      "\n",
      "         [[ 0.0473,  0.0486,  0.0448],\n",
      "          [ 0.0492,  0.0324,  0.0401],\n",
      "          [ 0.0438,  0.0314,  0.0403]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0062, -0.0099, -0.0114],\n",
      "          [-0.0056, -0.0066, -0.0084],\n",
      "          [-0.0098, -0.0067, -0.0074]],\n",
      "\n",
      "         [[ 0.0065,  0.0081,  0.0108],\n",
      "          [ 0.0006, -0.0034,  0.0066],\n",
      "          [ 0.0030,  0.0077,  0.0089]],\n",
      "\n",
      "         [[ 0.0212,  0.0179,  0.0207],\n",
      "          [ 0.0020,  0.0001,  0.0015],\n",
      "          [ 0.0065,  0.0077,  0.0037]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0393,  0.0272,  0.0190],\n",
      "          [ 0.0418,  0.0243,  0.0369],\n",
      "          [ 0.0528,  0.0350,  0.0559]],\n",
      "\n",
      "         [[-0.0292, -0.0142,  0.0024],\n",
      "          [-0.0049,  0.0082,  0.0278],\n",
      "          [ 0.0188,  0.0152,  0.0335]],\n",
      "\n",
      "         [[ 0.0093,  0.0059, -0.0028],\n",
      "          [ 0.0080, -0.0033, -0.0053],\n",
      "          [ 0.0167,  0.0055,  0.0086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0020,  0.0128,  0.0070],\n",
      "          [ 0.0079,  0.0150,  0.0143],\n",
      "          [ 0.0004,  0.0144,  0.0198]],\n",
      "\n",
      "         [[ 0.0285,  0.0011,  0.0072],\n",
      "          [ 0.0100, -0.0236, -0.0150],\n",
      "          [ 0.0003, -0.0234, -0.0209]],\n",
      "\n",
      "         [[ 0.0160,  0.0145,  0.0160],\n",
      "          [-0.0021, -0.0095, -0.0112],\n",
      "          [-0.0061, -0.0103, -0.0197]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0476, -0.0243, -0.0405],\n",
      "          [-0.0440, -0.0267, -0.0355],\n",
      "          [-0.0348, -0.0185, -0.0251]],\n",
      "\n",
      "         [[-0.0105, -0.0147, -0.0204],\n",
      "          [-0.0083, -0.0127, -0.0197],\n",
      "          [ 0.0113,  0.0095, -0.0003]],\n",
      "\n",
      "         [[-0.0086, -0.0039, -0.0068],\n",
      "          [-0.0059, -0.0037, -0.0094],\n",
      "          [ 0.0023, -0.0030, -0.0139]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0105,  0.0025,  0.0096],\n",
      "          [ 0.0129,  0.0004,  0.0076],\n",
      "          [ 0.0186,  0.0058,  0.0131]],\n",
      "\n",
      "         [[ 0.0003,  0.0050,  0.0096],\n",
      "          [-0.0155, -0.0153, -0.0134],\n",
      "          [-0.0031, -0.0240, -0.0102]],\n",
      "\n",
      "         [[-0.0098,  0.0015, -0.0056],\n",
      "          [-0.0087, -0.0017, -0.0008],\n",
      "          [-0.0261, -0.0123, -0.0136]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0096,  0.0004, -0.0132],\n",
      "          [-0.0016, -0.0126, -0.0311],\n",
      "          [-0.0200, -0.0222, -0.0293]],\n",
      "\n",
      "         [[-0.0270, -0.0163, -0.0193],\n",
      "          [-0.0408, -0.0342, -0.0415],\n",
      "          [-0.0260, -0.0167, -0.0266]],\n",
      "\n",
      "         [[-0.0114, -0.0060, -0.0054],\n",
      "          [ 0.0333,  0.0275,  0.0330],\n",
      "          [ 0.0140,  0.0084,  0.0131]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0091,  0.0019, -0.0018],\n",
      "          [-0.0069, -0.0080, -0.0054],\n",
      "          [ 0.0068,  0.0039,  0.0088]],\n",
      "\n",
      "         [[ 0.0127,  0.0098,  0.0046],\n",
      "          [ 0.0028, -0.0016, -0.0066],\n",
      "          [ 0.0051,  0.0033,  0.0018]],\n",
      "\n",
      "         [[-0.0021,  0.0109,  0.0086],\n",
      "          [-0.0023,  0.0082,  0.0105],\n",
      "          [-0.0019,  0.0084,  0.0136]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0217,  0.0030,  0.0205],\n",
      "          [ 0.0364,  0.0152,  0.0383],\n",
      "          [ 0.0532,  0.0262,  0.0449]],\n",
      "\n",
      "         [[-0.0030,  0.0051,  0.0117],\n",
      "          [ 0.0079,  0.0030,  0.0114],\n",
      "          [ 0.0235,  0.0230,  0.0408]],\n",
      "\n",
      "         [[-0.0375, -0.0278, -0.0248],\n",
      "          [-0.0182, -0.0155, -0.0202],\n",
      "          [-0.0081, -0.0131, -0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0160, -0.0094, -0.0212],\n",
      "          [-0.0100, -0.0024, -0.0034],\n",
      "          [-0.0174, -0.0012,  0.0089]],\n",
      "\n",
      "         [[ 0.0386,  0.0310,  0.0325],\n",
      "          [ 0.0352,  0.0129,  0.0200],\n",
      "          [ 0.0233,  0.0037,  0.0092]],\n",
      "\n",
      "         [[ 0.0122,  0.0143,  0.0136],\n",
      "          [-0.0015,  0.0027,  0.0059],\n",
      "          [-0.0057,  0.0079,  0.0033]]]], device='cuda:0')), ('layer3.1.bn2.weight', tensor([0.8355, 1.0626, 1.0744, 0.8898, 0.9829, 0.9687, 0.8804, 1.0889, 1.0147,\n",
      "        0.8282, 1.2067, 0.9115, 0.9530, 0.9770, 1.0065, 0.9564, 0.9390, 1.0999,\n",
      "        1.1145, 0.9115, 0.8591, 0.9302, 0.9586, 1.0531, 0.9479, 0.7557, 0.9902,\n",
      "        1.2446, 1.0162, 0.8918, 1.0228, 1.1687, 1.1428, 0.9819, 1.0690, 0.9973,\n",
      "        0.9385, 1.2060, 1.1995, 0.9956, 1.2224, 1.0724, 1.1316, 1.2203, 1.0273,\n",
      "        1.3593, 1.0385, 0.9861, 0.8993, 0.9150, 0.9251, 1.0534, 1.0438, 1.0613,\n",
      "        0.9158, 0.9830, 0.8103, 0.9877, 0.9525, 0.9403, 1.0338, 1.0590, 1.0484,\n",
      "        0.9732], device='cuda:0')), ('layer3.1.bn2.bias', tensor([0.2377, 0.3111, 0.1674, 0.1814, 0.1718, 0.2235, 0.2083, 0.3194, 0.2657,\n",
      "        0.2119, 0.3939, 0.2376, 0.2262, 0.1945, 0.2569, 0.2444, 0.1220, 0.1933,\n",
      "        0.2251, 0.2086, 0.2353, 0.2095, 0.1443, 0.2174, 0.3801, 0.1509, 0.1967,\n",
      "        0.3612, 0.2454, 0.2403, 0.3279, 0.3697, 0.2874, 0.2570, 0.2655, 0.2275,\n",
      "        0.2133, 0.3470, 0.2687, 0.2351, 0.3493, 0.2888, 0.2055, 0.2860, 0.2139,\n",
      "        0.4492, 0.2390, 0.2608, 0.2307, 0.1940, 0.2827, 0.2339, 0.2838, 0.2869,\n",
      "        0.1935, 0.3001, 0.1527, 0.0759, 0.2146, 0.1284, 0.2657, 0.3774, 0.2718,\n",
      "        0.2683], device='cuda:0')), ('layer3.1.bn2.running_mean', tensor([ 0.0183,  0.0140, -0.0300, -0.0542, -0.0660, -0.0597,  0.0039,  0.0175,\n",
      "        -0.0303, -0.0387, -0.0341, -0.0026, -0.0550, -0.0251,  0.0294,  0.0167,\n",
      "        -0.0369, -0.1297, -0.0494,  0.0128, -0.0839, -0.0276, -0.0768, -0.0235,\n",
      "        -0.0297,  0.0113, -0.0613,  0.0227, -0.1291, -0.0279, -0.0575, -0.0622,\n",
      "         0.0059, -0.0439, -0.0727, -0.0632, -0.0422, -0.0383,  0.0172, -0.0090,\n",
      "        -0.0793, -0.0136, -0.0462, -0.0352,  0.0063,  0.0223, -0.0884, -0.0530,\n",
      "        -0.0295, -0.0006, -0.1028, -0.0722, -0.0586, -0.0322,  0.0013,  0.0193,\n",
      "        -0.0169, -0.0671, -0.0231, -0.0055, -0.0261, -0.0437,  0.0219, -0.0351],\n",
      "       device='cuda:0')), ('layer3.1.bn2.running_var', tensor([0.0140, 0.0158, 0.0208, 0.0142, 0.0163, 0.0151, 0.0137, 0.0231, 0.0169,\n",
      "        0.0112, 0.0243, 0.0157, 0.0136, 0.0149, 0.0169, 0.0200, 0.0147, 0.0218,\n",
      "        0.0222, 0.0196, 0.0115, 0.0151, 0.0145, 0.0204, 0.0171, 0.0103, 0.0174,\n",
      "        0.0211, 0.0151, 0.0184, 0.0184, 0.0211, 0.0217, 0.0147, 0.0182, 0.0141,\n",
      "        0.0139, 0.0244, 0.0217, 0.0230, 0.0224, 0.0224, 0.0195, 0.0214, 0.0183,\n",
      "        0.0326, 0.0179, 0.0151, 0.0126, 0.0203, 0.0126, 0.0181, 0.0205, 0.0168,\n",
      "        0.0131, 0.0176, 0.0103, 0.0118, 0.0171, 0.0215, 0.0155, 0.0208, 0.0199,\n",
      "        0.0166], device='cuda:0')), ('layer3.1.bn2.num_batches_tracked', tensor(78200, device='cuda:0')), ('linear.weight', tensor([[ 0.3771,  0.5143,  0.7035,  0.2119, -0.3700,  0.3489, -0.2704, -0.0966,\n",
      "          0.4386, -0.4105, -0.3805,  0.4961, -0.2054, -0.2680, -0.4785, -0.3499,\n",
      "          0.1781, -0.1138, -0.0859, -0.1730, -0.2885, -0.2352,  0.1335, -0.3575,\n",
      "          0.5232, -0.2191, -0.0872, -0.0982,  0.2568, -0.2971,  0.5039, -0.6235,\n",
      "          0.5995, -0.4316,  0.6305, -0.0895, -0.1045,  0.2331, -0.2546,  0.4138,\n",
      "         -0.4152, -0.4314, -0.2758, -0.1769, -0.3756,  0.7387, -0.3129, -0.2110,\n",
      "         -0.1894, -0.3388,  0.0744, -0.2505,  0.3511,  0.1160,  0.5533,  0.3311,\n",
      "         -0.1509, -0.3735,  0.1875,  0.1739, -0.1747, -0.2887, -0.3357,  0.3828],\n",
      "        [-0.2956,  0.5843, -0.2876, -0.2195, -0.2051, -0.3131,  0.5620,  0.6828,\n",
      "          0.5301, -0.2392, -0.4111, -0.2416, -0.2544,  0.0104,  0.4730,  0.4536,\n",
      "         -0.1057, -0.2262,  0.1421,  0.3501, -0.2998, -0.2478, -0.1371, -0.1757,\n",
      "         -0.2933, -0.1150, -0.1960,  0.6988, -0.3619,  0.4749, -0.2815, -0.3753,\n",
      "          0.7251, -0.3100, -0.1355,  0.2714, -0.3090, -0.4457,  0.7630,  0.3133,\n",
      "         -0.3000,  0.5163, -0.2187, -0.2699,  0.4361, -0.3122, -0.2618, -0.2930,\n",
      "          0.4281,  0.6149, -0.2831, -0.2910, -0.3192, -0.0961,  0.4039,  0.2924,\n",
      "         -0.0230, -0.0057, -0.2001,  0.1553, -0.3122, -0.3460,  0.5160, -0.2804],\n",
      "        [ 0.1785, -0.3252, -0.0330,  0.5034,  0.6148, -0.3172,  0.4957, -0.3140,\n",
      "         -0.2783,  0.5084,  0.5284, -0.1020, -0.3345,  0.3536, -0.1114,  0.3253,\n",
      "          0.5377, -0.0369, -0.5150,  0.3741, -0.1315, -0.1474,  0.4887, -0.0988,\n",
      "          0.1442, -0.1882, -0.3338, -0.3702,  0.4748, -0.2070,  0.2823,  0.5454,\n",
      "         -0.2184,  0.4873,  0.2206,  0.2060,  0.0372, -0.1794, -0.1549, -0.2330,\n",
      "         -0.4664, -0.0944, -0.2696, -0.3017, -0.3043,  0.6853,  0.0690, -0.3116,\n",
      "         -0.2297, -0.1011,  0.1508, -0.3060, -0.2845, -0.3897, -0.2326, -0.4491,\n",
      "         -0.3703,  0.5622, -0.4359,  0.5759, -0.3605,  0.6184, -0.1055,  0.4006],\n",
      "        [-0.3098, -0.2136, -0.0540, -0.1487,  0.3160,  0.2369,  0.1845,  0.4238,\n",
      "          0.0756,  0.0377, -0.1245, -0.1663,  0.3557, -0.2370, -0.0951, -0.5202,\n",
      "         -0.3416,  0.1964, -0.3715, -0.2650,  0.2937,  0.4114, -0.3303, -0.3221,\n",
      "          0.3815, -0.3751, -0.1640, -0.0938,  0.2304,  0.4651,  0.4722,  0.3709,\n",
      "         -0.1739,  0.4292,  0.1657, -0.3262, -0.2646, -0.4883, -0.2196, -0.4222,\n",
      "          0.5717,  0.4561,  0.1501, -0.0686, -0.2617, -0.4203, -0.1751,  0.3105,\n",
      "         -0.1735,  0.4533,  0.1918,  0.0760,  0.4675,  0.7137, -0.1503, -0.3471,\n",
      "          0.1192, -0.1076,  0.0405, -0.1832,  0.4157,  0.5715, -0.0714,  0.0515],\n",
      "        [ 0.3591, -0.2529,  0.5973, -0.1512, -0.0037,  0.4496, -0.1864, -0.2519,\n",
      "         -0.3607,  0.5055,  0.7222,  0.4481,  0.3494, -0.2104,  0.4733,  0.2950,\n",
      "         -0.3124, -0.3936,  0.5165,  0.1942, -0.1465,  0.1909, -0.5322,  0.6281,\n",
      "         -0.2911,  0.1770, -0.3480, -0.3688, -0.4812, -0.2314, -0.2845,  0.3697,\n",
      "         -0.3053,  0.2938, -0.4739, -0.4368, -0.2399,  0.5601, -0.2465,  0.1998,\n",
      "          0.5180,  0.0109, -0.2000,  0.5311, -0.2581, -0.2772, -0.3965,  0.0360,\n",
      "         -0.3870, -0.2732, -0.4790, -0.3340, -0.4138,  0.1898, -0.1846, -0.3554,\n",
      "          0.4476, -0.4160,  0.1821,  0.5120, -0.3010,  0.2408, -0.3241,  0.3078],\n",
      "        [ 0.2254, -0.2787, -0.3943, -0.1491, -0.2460, -0.0706,  0.0883,  0.5931,\n",
      "         -0.1943, -0.2009, -0.3100, -0.2275, -0.1382, -0.2830, -0.2667, -0.0978,\n",
      "         -0.2940, -0.5085, -0.2538, -0.0714,  0.4461, -0.2614,  0.3775,  0.4786,\n",
      "         -0.1300,  0.3850,  0.1844, -0.3426,  0.2696, -0.0223,  0.3974,  0.5167,\n",
      "         -0.2843,  0.3679, -0.1087,  0.1059,  0.2381, -0.4457, -0.0050, -0.2221,\n",
      "          0.2899, -0.1547,  0.6556,  0.5961,  0.3249, -0.5343,  0.0367,  0.5614,\n",
      "         -0.2589, -0.2667,  0.2510, -0.3582, -0.4247,  0.3852, -0.2577, -0.2181,\n",
      "         -0.0961,  0.3749,  0.6347, -0.2829,  0.5120, -0.1256,  0.5158,  0.4638],\n",
      "        [-0.2333, -0.3055,  0.0706, -0.0535, -0.4718, -0.4057, -0.2920, -0.1438,\n",
      "         -0.2083, -0.1895,  0.6572, -0.2529, -0.3274,  0.5702, -0.1698,  0.0097,\n",
      "          0.5536,  0.5675,  0.5890, -0.3375,  0.1583,  0.5221,  0.3259, -0.2641,\n",
      "         -0.1532, -0.2684,  0.8303, -0.3046, -0.2610,  0.2308, -0.4195, -0.3302,\n",
      "         -0.1093,  0.0843,  0.5939,  0.0547, -0.2270, -0.4442, -0.2601, -0.2204,\n",
      "         -0.0835, -0.2855, -0.1977,  0.7413,  0.5991, -0.3977, -0.3375, -0.4588,\n",
      "          0.4592, -0.0588,  0.2139,  0.4326, -0.2898,  0.2536, -0.0569, -0.2448,\n",
      "         -0.1119,  0.3861, -0.2064, -0.2097,  0.1536,  0.3694, -0.2497, -0.2402],\n",
      "        [-0.3292, -0.3966, -0.3480,  0.5804,  0.4210,  0.0120, -0.1975, -0.3214,\n",
      "         -0.0684,  0.2016, -0.4120, -0.2124,  0.5446, -0.2217, -0.3678,  0.3900,\n",
      "          0.0230,  0.6594,  0.4778,  0.5195, -0.2810, -0.3583, -0.0586,  0.5347,\n",
      "         -0.3341,  0.1093,  0.1295, -0.3734, -0.2261,  0.2509,  0.0956,  0.2071,\n",
      "         -0.2629, -0.4326, -0.3065, -0.2681, -0.1987,  0.3843, -0.2242,  0.5808,\n",
      "          0.6516, -0.3267,  0.8217, -0.4225, -0.3333, -0.2529,  0.7212,  0.1776,\n",
      "         -0.2010, -0.0398,  0.5974, -0.0186,  0.1070, -0.4214, -0.2765,  0.5868,\n",
      "         -0.1984, -0.1668,  0.4131, -0.2765, -0.2205, -0.3785, -0.1145, -0.2751],\n",
      "        [ 0.3126,  0.2450, -0.2575, -0.2720,  0.0641, -0.3739, -0.2073, -0.4189,\n",
      "         -0.4484, -0.0937, -0.3201,  0.5222,  0.3080,  0.5478,  0.0608, -0.2693,\n",
      "         -0.0458, -0.2282, -0.2695, -0.2126, -0.2581,  0.3709, -0.3370, -0.2220,\n",
      "          0.5898,  0.3761, -0.2236,  0.6898, -0.3565, -0.2992, -0.3710, -0.3257,\n",
      "          0.4300, -0.1830, -0.4569, -0.2918,  0.7054,  0.3424, -0.2656, -0.4453,\n",
      "         -0.4227, -0.3358, -0.1726, -0.2838,  0.2423,  0.7383,  0.1700, -0.2911,\n",
      "          0.3453,  0.2230, -0.3956,  0.4227,  0.2954, -0.4048, -0.2266,  0.3202,\n",
      "          0.5232,  0.0356, -0.3122, -0.3001,  0.6026, -0.2970,  0.5413, -0.4630],\n",
      "        [-0.2776,  0.4338, -0.0016, -0.3042, -0.1154,  0.4331, -0.1870, -0.1484,\n",
      "          0.5203, -0.1205,  0.0459, -0.2537, -0.3011, -0.2523,  0.4897, -0.2370,\n",
      "         -0.1987,  0.0881, -0.2302, -0.3716,  0.5027, -0.2422,  0.0755, -0.2003,\n",
      "         -0.4361,  0.1112,  0.2020,  0.5647,  0.4509, -0.3552, -0.3843, -0.3534,\n",
      "         -0.4014, -0.3052, -0.1264,  0.7764,  0.3604,  0.4866,  0.8667,  0.0335,\n",
      "         -0.3441,  0.6471, -0.2878, -0.3484, -0.0596,  0.0277,  0.4875,  0.4800,\n",
      "          0.2072, -0.2236, -0.3258,  0.6257,  0.5109, -0.3515,  0.4280,  0.0800,\n",
      "         -0.1406, -0.2880, -0.3076, -0.1675, -0.3163, -0.3725, -0.3692, -0.3532]],\n",
      "       device='cuda:0')), ('linear.bias', tensor([ 0.0749, -0.1064,  0.1098,  0.1116,  0.0748, -0.0961, -0.0115, -0.0363,\n",
      "        -0.0253, -0.0952], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './save_weights/resnet_aug.pt')\n",
    "print('state_dict format of the model: {}'.format(model.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = ResNet().to(DEVICE)\n",
    "load_model.load_state_dict(torch.load('./save_weights/resnet_aug.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
